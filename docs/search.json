[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The first half of the course is built around The Handbook of Regression Modeling in People Analytics: With Examples in R, Python, and Julia by Keith McNulty [Global Director of Talent Sciences at McKinsey and Company] that covers models for discrete data types [binary, ordered, nominal choices, counts of events, and survival/duration analysis]. This website provides my solution sets for the chapter exercises in the text."
  },
  {
    "objectID": "about.html#instructor",
    "href": "about.html#instructor",
    "title": "About",
    "section": "Instructor",
    "text": "Instructor\nRobert W. Walker is Associate Professor of Quantitative Methods in the Atkinson Graduate School of Management at Willamette University. He earned a Ph. D. in political science from the University of Rochester in 2005 and has previously held teaching positions at Dartmouth College, Rice University, Texas A&M University, and Washington University in Saint Louis. His current research develops and applies semi-Markov processes to time-series, cross-section data in international relations and international/comparative political economy. He teaches courses in quantitative methods/applied statistics and microeconomic strategy and previously taught four iterations in the U. S. National Science Foundation funded Empirical Implications of Theoretical Models sequence at Washington University in Saint Louis. His work with Curt Signorino and Muhammet Bas was awarded the Miller Prize for the best article in Political Analysis in 2009."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HRMPA Chapter Exercise Solutions",
    "section": "",
    "text": "Chapter 8\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nOct 1, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 7\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 28, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 6\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 26, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 5\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 4\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 24, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 3\n\n\n\nR\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 23, 2022\n\n\n\n\n\n\n\n\n\n\n\nChapter 2\n\n\n\nR\n\n\n\n\n\n\n\nRWW\n\n\nSep 22, 2022\n\n\n\n\n\n\n\n\n\n\n\nHRMPA Solutions\n\n\n\nnews\n\n\n\n\n\n\n\nRobert W. Walker\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/chapter-4/index.html",
    "href": "posts/chapter-4/index.html",
    "title": "Chapter 4",
    "section": "",
    "text": "Load the sociological_data data set via the peopleanalyticsdata package or download it from the internet. This data represents a sample of information obtained from individuals who participated in a global research study and contains the following fields:\n\nlibrary(tidyverse); library(magrittr); library(skimr)\nsoc_data <- read.csv(\"http://peopleanalytics-regression-book.org/data/sociological_data.csv\")\n\n\nannual_income_ppp: The annual income of the individual in PPP adjusted US dollars\naverage_wk_hrs: The average number of hours per week worked by the individual\neducation_months: The total number of months spent by the individual in formal primary, secondary and tertiary education\nregion: The region of the world where the individual lives\njob_type: Whether the individual works in a skilled or unskilled profession\ngender: The gender of the individual\nfamily_size: The size of the individual’s family of dependents\nwork_distance: The distance between the individual’s residence and workplace in kilometers\nlanguages: The number of languages spoken fluently by the individual\n\nConduct some exploratory data analysis on this data set. Including:\n\nIdentify the extent to which missing data is an issue.\n\n\nsummary(soc_data)\n\n annual_income_ppp average_wk_hrs  education_months    region         \n Min.   :  2863    Min.   :30.00   Min.   : 40.0    Length:2618       \n 1st Qu.: 62653    1st Qu.:39.00   1st Qu.:157.0    Class :character  \n Median : 82140    Median :43.00   Median :184.0    Mode  :character  \n Mean   : 76040    Mean   :44.19   Mean   :179.3                      \n 3rd Qu.: 90112    3rd Qu.:50.00   3rd Qu.:207.0                      \n Max.   :119564    Max.   :55.00   Max.   :280.0                      \n NA's   :10        NA's   :34      NA's   :19                         \n   job_type            gender           family_size    work_distance    \n Length:2618        Length:2618        Min.   : 0.00   Min.   :  0.000  \n Class :character   Class :character   1st Qu.: 2.00   1st Qu.:  0.000  \n Mode  :character   Mode  :character   Median : 3.00   Median :  0.000  \n                                       Mean   : 3.26   Mean   :  0.985  \n                                       3rd Qu.: 4.00   3rd Qu.:  1.000  \n                                       Max.   :10.00   Max.   :105.000  \n                                       NA's   :191     NA's   :412      \n   languages    \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :1.000  \n Mean   :1.018  \n 3rd Qu.:1.000  \n Max.   :5.000  \n NA's   :412    \n\n\nThe answer very much depends on the variable under examination. languages and work_distance are missing 15.737204% of the data. That is quite a bit. The good news, such that it is, is that it is the same 412 observations that are missing both. How much an issue is it? One way to examine this would be to estimate the model with those data and without. There are also 119 observations without family_size, of those 41 are missing. This means that 490 are missing via patterns in these three variables; that’s 0.1871658\n\nsoc_data %>% janitor::tabyl(languages, work_distance)\n\n languages    0   1 10 105 11 12 13 14 15 16 18 19  2 20 21  3  4  5  6  7 8 9\n         1 1582 343  8   0  5  3  2  0  0  0  0  0 92  0  0 58 38 20 12 11 5 1\n         2    0   0  0   0  0  0  0  5  6  3  1  2  0  2  2  0  0  0  0  0 0 0\n         4    0   0  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n         5    0   0  0   1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n        NA    0   0  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n 91 93 94 96 NA_\n  0  0  0  0   0\n  0  0  0  0   0\n  1  0  0  0   0\n  0  1  1  1   0\n  0  0  0  0 412\n\nsoc_data %>% dplyr::filter(is.na(languages) & is.na(work_distance)) %>% skim(family_size)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n412\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfamily_size\n41\n0.9\n2.79\n1.54\n0\n2\n3\n3\n10\n▇▇▁▁▁\n\n\n\n\n\n\nlibrary(naniar)\nnaniar::gg_miss_var(soc_data)\n\n\n\n\n\nDetermine if the data types are appropriate for analysis.\n\nTo be honest, I am not entirely sure what this means. Yes, we can analyse them in the current form.\n\nUsing a correlation matrix, pairplot or alternative method, identify whether collinearity is present in the data.\n\nregion is categorical with too many categories so it has to be dropped from plots. work_distance and languages are very highly correlated.\n\nsoc_data %>% dplyr::select(-region) %>% GGally::ggpairs()\n\n\n\n\n\nIdentify and discuss anything else interesting that you see in the data.\n\nwork_distance is messy and highly correlated with languages.\nPrepare to build a linear regression model to explain the variation in annual_income_ppp using the other data in the data set.\n\nAre there any fields which you believe should not be included in the model? If so, why?\n\nI think there are principled reasons to ignore work_distance and languages as they have so much missing data. Not exactly sure why family_size would be relevant but that can be included and excluded.\n\nWould you consider imputing missing data for some or all fields where it is an issue? If so, what might be some simple ways to impute the missing data?\n\nI would not but largely because I am not sure what would necessarily predict work distance, languages, and family size. Were I to impute it, I prefer multiple imputation to represent the full data correlation structure in the imputation process.\n\nWhich variables are categorical? Convert these variables to dummy variables using a convenient function or using your own approach.\n\nThe fastDummies package is amazing for this.\n\nsummary(soc_data)\n\n annual_income_ppp average_wk_hrs  education_months    region         \n Min.   :  2863    Min.   :30.00   Min.   : 40.0    Length:2618       \n 1st Qu.: 62653    1st Qu.:39.00   1st Qu.:157.0    Class :character  \n Median : 82140    Median :43.00   Median :184.0    Mode  :character  \n Mean   : 76040    Mean   :44.19   Mean   :179.3                      \n 3rd Qu.: 90112    3rd Qu.:50.00   3rd Qu.:207.0                      \n Max.   :119564    Max.   :55.00   Max.   :280.0                      \n NA's   :10        NA's   :34      NA's   :19                         \n   job_type            gender           family_size    work_distance    \n Length:2618        Length:2618        Min.   : 0.00   Min.   :  0.000  \n Class :character   Class :character   1st Qu.: 2.00   1st Qu.:  0.000  \n Mode  :character   Mode  :character   Median : 3.00   Median :  0.000  \n                                       Mean   : 3.26   Mean   :  0.985  \n                                       3rd Qu.: 4.00   3rd Qu.:  1.000  \n                                       Max.   :10.00   Max.   :105.000  \n                                       NA's   :191     NA's   :412      \n   languages    \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :1.000  \n Mean   :1.018  \n 3rd Qu.:1.000  \n Max.   :5.000  \n NA's   :412    \n\n\nregion, job_type, and gender need such treatment.\n\nlibrary(fastDummies)\nsoc_data.dum <- soc_data %>% fastDummies::dummy_columns(., select_columns = c(\"region\",\"job_type\",\"gender\"))\n\nRun and interpret the model. For convenience, and to avoid long formula strings, you can use the formula notation annual_income_ppp ~ . which means ‘regress annual_income against everything else’. You can also remove fields this way, for example annual_income_ppp ~ . - family_size.\n\nMod1 <- soc_data %>% dplyr::select(-c(work_distance, languages, family_size)) %>% lm(annual_income_ppp ~ ., data=.)\nsummary(Mod1)\n\n\nCall:\nlm(formula = annual_income_ppp ~ ., data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-66558  -5076     32   4886  34054 \n\nCoefficients:\n                                        Estimate Std. Error t value   Pr(>|t|)\n(Intercept)                            61013.833   3547.587  17.199    < 2e-16\naverage_wk_hrs                           -94.381     49.614  -1.902   0.057245\neducation_months                         135.854      8.919  15.232    < 2e-16\nregionCentral Asia                     -9950.611   2219.350  -4.484 0.00000767\nregionEastern Asia                       -11.119   2306.359  -0.005   0.996154\nregionEastern Europe                   -8868.991   1957.127  -4.532 0.00000612\nregionLatin America and the Caribbean   1520.957   1974.732   0.770   0.441247\nregionMelanesia                        -4341.571   2290.646  -1.895   0.058160\nregionMicronesia                       -9862.966   2590.009  -3.808   0.000143\nregionNorthern Africa                   -571.361   2198.879  -0.260   0.795007\nregionNorthern America                 14003.282   2999.688   4.668 0.00000320\nregionNorthern Europe                   -295.495   1863.336  -0.159   0.874010\nregionPolynesia                        -1463.552   2539.825  -0.576   0.564503\nregionSouth-eastern Asia               -2932.501   2106.504  -1.392   0.164009\nregionSouthern Asia                    -3410.363   2195.464  -1.553   0.120460\nregionSouthern Europe                   4555.134   1903.801   2.393   0.016799\nregionSub-Saharan Africa              -20719.828   2066.605 -10.026    < 2e-16\nregionWestern Asia                      2658.151   1995.651   1.332   0.182989\nregionWestern Europe                    6625.710   1922.203   3.447   0.000576\njob_typeUnskilled                      -8074.631    803.987 -10.043    < 2e-16\ngenderM                                 9715.197    665.656  14.595    < 2e-16\n                                         \n(Intercept)                           ***\naverage_wk_hrs                        .  \neducation_months                      ***\nregionCentral Asia                    ***\nregionEastern Asia                       \nregionEastern Europe                  ***\nregionLatin America and the Caribbean    \nregionMelanesia                       .  \nregionMicronesia                      ***\nregionNorthern Africa                    \nregionNorthern America                ***\nregionNorthern Europe                    \nregionPolynesia                          \nregionSouth-eastern Asia                 \nregionSouthern Asia                      \nregionSouthern Europe                 *  \nregionSub-Saharan Africa              ***\nregionWestern Asia                       \nregionWestern Europe                  ***\njob_typeUnskilled                     ***\ngenderM                               ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9407 on 2539 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.7962,    Adjusted R-squared:  0.7946 \nF-statistic: 495.8 on 20 and 2539 DF,  p-value: < 2.2e-16\n\n\n\nDetermine what variables are significant predictors of annual income and what is the effect of each on the outcome.\n\n\nsoc_data %>% dplyr::select(-c(work_distance, languages, family_size)) %>% lm(annual_income_ppp ~ ., data=.) %>% summary %$% coefficients %>% data.frame %>% filter(`Pr...t..` < 0.05)\n\n                            Estimate  Std..Error    t.value     Pr...t..\n(Intercept)               61013.8327 3547.587273  17.198684 8.550317e-63\neducation_months            135.8542    8.918884  15.232193 3.346444e-50\nregionCentral Asia        -9950.6108 2219.350223  -4.483569 7.666478e-06\nregionEastern Europe      -8868.9906 1957.126882  -4.531638 6.123784e-06\nregionMicronesia          -9862.9659 2590.008578  -3.808082 1.433663e-04\nregionNorthern America    14003.2817 2999.687867   4.668246 3.195797e-06\nregionSouthern Europe      4555.1337 1903.800748   2.392653 1.679935e-02\nregionSub-Saharan Africa -20719.8283 2066.605062 -10.026022 3.148593e-23\nregionWestern Europe       6625.7095 1922.203143   3.446935 5.762064e-04\njob_typeUnskilled         -8074.6311  803.987070 -10.043235 2.662334e-23\ngenderM                    9715.1966  665.656089  14.594919 2.169990e-46\n\n\nMonths of education, region, job type, and gender are predictors of annual income. Each month of education begets about 136 dollars, unskilled labor is lower by 8075 dollars than skilled labor, and Males have annual incomes about 9715 dollars higher. A number of regions have higher and lower average annual incomes, also.\n\nDetermine the overall fit of the model.\n\nThe model accounts for almost 80 percent of the variation in annual incomes and the model \\(F\\) statistic is enormous.\n\nDo some simple analysis on the residuals of the model to determine if the model is safe to interpret.\n\n\ngvlma::gvlma(Mod1)\n\n\nCall:\nlm(formula = annual_income_ppp ~ ., data = .)\n\nCoefficients:\n                          (Intercept)                         average_wk_hrs  \n                             61013.83                                 -94.38  \n                     education_months                     regionCentral Asia  \n                               135.85                               -9950.61  \n                   regionEastern Asia                   regionEastern Europe  \n                               -11.12                               -8868.99  \nregionLatin America and the Caribbean                        regionMelanesia  \n                              1520.96                               -4341.57  \n                     regionMicronesia                  regionNorthern Africa  \n                             -9862.97                                -571.36  \n               regionNorthern America                  regionNorthern Europe  \n                             14003.28                                -295.49  \n                      regionPolynesia               regionSouth-eastern Asia  \n                             -1463.55                               -2932.50  \n                  regionSouthern Asia                  regionSouthern Europe  \n                             -3410.36                                4555.13  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                            -20719.83                                2658.15  \n                 regionWestern Europe                      job_typeUnskilled  \n                              6625.71                               -8074.63  \n                              genderM  \n                              9715.20  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod1) \n\n                      Value    p-value                   Decision\nGlobal Stat        517.2979 0.00000000 Assumptions NOT satisfied!\nSkewness             3.9341 0.04731624 Assumptions NOT satisfied!\nKurtosis           497.9156 0.00000000 Assumptions NOT satisfied!\nLink Function       15.1844 0.00009751 Assumptions NOT satisfied!\nHeteroscedasticity   0.2639 0.60748142    Assumptions acceptable.\n\n\nProbably not. The middle 50 percent of residuals are reasonably well balanced but they have a very long left tail in addition to failing the diagnostics above.\n\nExperiment with improving the model fit through possible interaction terms or non-linear extensions.\n\n\nMod2 <- soc_data %>% mutate(ln_income = log(annual_income_ppp)) %>% dplyr::select(-c(work_distance, languages, family_size,annual_income_ppp))  %>% lm(ln_income ~ ., data=.)\nsummary(Mod2)\n\n\nCall:\nlm(formula = ln_income ~ ., data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.11453 -0.06136  0.00394  0.07564  0.59898 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(>|t|)\n(Intercept)                           10.9156109  0.0706493 154.504  < 2e-16\naverage_wk_hrs                        -0.0009693  0.0009881  -0.981  0.32669\neducation_months                       0.0017640  0.0001776   9.932  < 2e-16\nregionCentral Asia                    -0.0984659  0.0441978  -2.228  0.02598\nregionEastern Asia                     0.0088410  0.0459306   0.192  0.84738\nregionEastern Europe                  -0.0797522  0.0389757  -2.046  0.04084\nregionLatin America and the Caribbean  0.0379392  0.0393263   0.965  0.33477\nregionMelanesia                       -0.0067090  0.0456176  -0.147  0.88309\nregionMicronesia                      -0.0895268  0.0515794  -1.736  0.08274\nregionNorthern Africa                  0.0145632  0.0437901   0.333  0.73949\nregionNorthern America                 0.1609234  0.0597380   2.694  0.00711\nregionNorthern Europe                  0.0063751  0.0371079   0.172  0.86361\nregionPolynesia                        0.0045840  0.0505800   0.091  0.92779\nregionSouth-eastern Asia              -0.0141714  0.0419505  -0.338  0.73553\nregionSouthern Asia                   -0.0089686  0.0437221  -0.205  0.83749\nregionSouthern Europe                  0.0698175  0.0379137   1.841  0.06567\nregionSub-Saharan Africa              -0.3306967  0.0411559  -8.035 1.42e-15\nregionWestern Asia                     0.0571853  0.0397429   1.439  0.15031\nregionWestern Europe                   0.0833153  0.0382802   2.176  0.02961\njob_typeUnskilled                     -0.0846780  0.0160112  -5.289 1.34e-07\ngenderM                                0.1962831  0.0132564  14.807  < 2e-16\n                                         \n(Intercept)                           ***\naverage_wk_hrs                           \neducation_months                      ***\nregionCentral Asia                    *  \nregionEastern Asia                       \nregionEastern Europe                  *  \nregionLatin America and the Caribbean    \nregionMelanesia                          \nregionMicronesia                      .  \nregionNorthern Africa                    \nregionNorthern America                ** \nregionNorthern Europe                    \nregionPolynesia                          \nregionSouth-eastern Asia                 \nregionSouthern Asia                      \nregionSouthern Europe                 .  \nregionSub-Saharan Africa              ***\nregionWestern Asia                       \nregionWestern Europe                  *  \njob_typeUnskilled                     ***\ngenderM                               ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1873 on 2539 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.7041,    Adjusted R-squared:  0.7018 \nF-statistic: 302.1 on 20 and 2539 DF,  p-value: < 2.2e-16\n\ngvlma::gvlma(Mod2)\n\n\nCall:\nlm(formula = ln_income ~ ., data = .)\n\nCoefficients:\n                          (Intercept)                         average_wk_hrs  \n                           10.9156109                             -0.0009693  \n                     education_months                     regionCentral Asia  \n                            0.0017640                             -0.0984659  \n                   regionEastern Asia                   regionEastern Europe  \n                            0.0088410                             -0.0797522  \nregionLatin America and the Caribbean                        regionMelanesia  \n                            0.0379392                             -0.0067090  \n                     regionMicronesia                  regionNorthern Africa  \n                           -0.0895268                              0.0145632  \n               regionNorthern America                  regionNorthern Europe  \n                            0.1609234                              0.0063751  \n                      regionPolynesia               regionSouth-eastern Asia  \n                            0.0045840                             -0.0141714  \n                  regionSouthern Asia                  regionSouthern Europe  \n                           -0.0089686                              0.0698175  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                           -0.3306967                              0.0571853  \n                 regionWestern Europe                      job_typeUnskilled  \n                            0.0833153                             -0.0846780  \n                              genderM  \n                            0.1962831  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod2) \n\n                        Value  p-value                   Decision\nGlobal Stat        143804.115 0.000000 Assumptions NOT satisfied!\nSkewness             3716.416 0.000000 Assumptions NOT satisfied!\nKurtosis           140075.937 0.000000 Assumptions NOT satisfied!\nLink Function           2.550 0.110312    Assumptions acceptable.\nHeteroscedasticity      9.212 0.002404 Assumptions NOT satisfied!\n\n\n\nMod2 <- soc_data %>%  dplyr::select(-c(work_distance, languages, family_size))  %>% lm(annual_income_ppp ~ region + job_type*average_wk_hrs+education_months+region+gender*education_months, data=.)\nsummary(Mod2)\n\n\nCall:\nlm(formula = annual_income_ppp ~ region + job_type * average_wk_hrs + \n    education_months + region + gender * education_months, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-65530  -5157      3   5146  33350 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                            54829.60    4376.12  12.529  < 2e-16 ***\nregionCentral Asia                     -3609.73    2274.42  -1.587 0.112616    \nregionEastern Asia                      4834.25    2346.28   2.060 0.039464 *  \nregionEastern Europe                   -4394.43    1977.73  -2.222 0.026374 *  \nregionLatin America and the Caribbean   6933.59    2030.08   3.415 0.000647 ***\nregionMelanesia                         1897.75    2351.66   0.807 0.419752    \nregionMicronesia                       -3031.98    2685.54  -1.129 0.259005    \nregionNorthern Africa                   4816.64    2245.49   2.145 0.032046 *  \nregionNorthern America                 16160.99    2956.92   5.465 5.07e-08 ***\nregionNorthern Europe                   1849.26    1843.39   1.003 0.315869    \nregionPolynesia                         3128.26    2567.06   1.219 0.223103    \nregionSouth-eastern Asia                2998.16    2149.16   1.395 0.163126    \nregionSouthern Asia                     3517.06    2247.88   1.565 0.117798    \nregionSouthern Europe                   8416.08    1913.55   4.398 1.14e-05 ***\nregionSub-Saharan Africa              -14561.47    2112.30  -6.894 6.84e-12 ***\nregionWestern Asia                      8247.65    2063.91   3.996 6.62e-05 ***\nregionWestern Europe                    9742.39    1919.92   5.074 4.17e-07 ***\njob_typeUnskilled                       5374.35    4251.07   1.264 0.206262    \naverage_wk_hrs                           188.67      88.89   2.123 0.033883 *  \neducation_months                          44.78      12.15   3.685 0.000233 ***\ngenderM                               -18683.40    2797.28  -6.679 2.94e-11 ***\njob_typeUnskilled:average_wk_hrs        -305.25     101.63  -3.004 0.002695 ** \neducation_months:genderM                 179.74      17.29  10.398  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9190 on 2537 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.8056,    Adjusted R-squared:  0.8039 \nF-statistic:   478 on 22 and 2537 DF,  p-value: < 2.2e-16\n\n\n\ngvlma::gvlma(Mod2)\n\n\nCall:\nlm(formula = annual_income_ppp ~ region + job_type * average_wk_hrs + \n    education_months + region + gender * education_months, data = .)\n\nCoefficients:\n                          (Intercept)                     regionCentral Asia  \n                             54829.60                               -3609.73  \n                   regionEastern Asia                   regionEastern Europe  \n                              4834.25                               -4394.43  \nregionLatin America and the Caribbean                        regionMelanesia  \n                              6933.59                                1897.75  \n                     regionMicronesia                  regionNorthern Africa  \n                             -3031.98                                4816.64  \n               regionNorthern America                  regionNorthern Europe  \n                             16160.99                                1849.26  \n                      regionPolynesia               regionSouth-eastern Asia  \n                              3128.26                                2998.16  \n                  regionSouthern Asia                  regionSouthern Europe  \n                              3517.06                                8416.08  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                            -14561.47                                8247.65  \n                 regionWestern Europe                      job_typeUnskilled  \n                              9742.39                                5374.35  \n                       average_wk_hrs                       education_months  \n                               188.67                                  44.78  \n                              genderM       job_typeUnskilled:average_wk_hrs  \n                            -18683.40                                -305.25  \n             education_months:genderM  \n                               179.74  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod2) \n\n                     Value     p-value                   Decision\nGlobal Stat        471.098 0.000000000 Assumptions NOT satisfied!\nSkewness            11.605 0.000657878 Assumptions NOT satisfied!\nKurtosis           435.190 0.000000000 Assumptions NOT satisfied!\nLink Function       24.150 0.000000891 Assumptions NOT satisfied!\nHeteroscedasticity   0.153 0.695654693    Assumptions acceptable.\n\n\nMaybe I am missing something but I cannot really make this work.\n\nComment on your results. Did anything in the results surprise you? If so, what might be possible explanations for this.\n\nOriginally, the negative sign on Males but, when thought of in the context of the interaction term for education_months, it does not take all that many months to make up that difference. That the education premium as so large for males is discouraging but not surprising.\n\nExplain why you would or would not be comfortable using a model like this in a predictive setting—for example to help employers determine the right pay for employees.\n\nI would not. The reason largely stems from the need for an actual job description which, at least to me, is a far more important predictor of the salary/pay band than simple skilled/unskilled and education."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "HRMPA Solutions",
    "section": "",
    "text": "The solutions are organized by Chapter as posts.\nYou can find any of the original quarto markdown files on the github repository under posts."
  },
  {
    "objectID": "posts/chapter-2/index.html",
    "href": "posts/chapter-2/index.html",
    "title": "Chapter 2: HRMPA",
    "section": "",
    "text": "Create a character vector called my_names that contains all your first, middle and last names as elements. Calculate the length of my_names.\n\n\nmy_names <- c(\"Robert\",\"Wayne\",\"Walker\")\nlength(my_names)\n\n[1] 3\n\n\n\nCreate a second numeric vector called which which corresponds to my_names. The entries should be the position of each name in the order of your full name. Verify that it has the same length as my_names.\n\n\nwhich <- c(1,2,3)\nlength(which)\n\n[1] 3\n\n\n\nCreate a dataframe called names, which consists of the two vectors my_names and which as columns. Calculate the dimensions of names.\n\n\nnames <- data.frame(my_names,which)\ndim(names)\n\n[1] 3 2\n\n# str(names)\n\n3 rows and 2 columns\n\nCreate a new dataframe new_names with the which column converted to character type. Verify that your command worked using str().\n\n\nnew_names <- data.frame(my_names, as.character(which))\nstr(new_names)\n\n'data.frame':   3 obs. of  2 variables:\n $ my_names           : chr  \"Robert\" \"Wayne\" \"Walker\"\n $ as.character.which.: chr  \"1\" \"2\" \"3\"\n\n\n\nLoad the ugtests data set via the peopleanalyticsdata package or download it from the internet. Calculate the dimensions of ugtests and view the first three rows only.\n\n\nugtests <- read.csv(\"http://peopleanalytics-regression-book.org/data/ugtests.csv\")\ndim(ugtests)\n\n[1] 975   4\n\nhead(ugtests, 3)\n\n  Yr1 Yr2 Yr3 Final\n1  27  50  52    93\n2  70 104 126   207\n3  27  36 148   175\n\n\n975 rows and 4 columns\n\nView a statistical summary of all of the columns of ugtests. Determine if there are any missing values.\n\n\nsummary(ugtests)\n\n      Yr1             Yr2             Yr3            Final    \n Min.   : 3.00   Min.   :  6.0   Min.   :  8.0   Min.   :  8  \n 1st Qu.:42.00   1st Qu.: 73.0   1st Qu.: 81.0   1st Qu.:118  \n Median :53.00   Median : 94.0   Median :105.0   Median :147  \n Mean   :52.15   Mean   : 92.4   Mean   :105.1   Mean   :149  \n 3rd Qu.:62.00   3rd Qu.:112.0   3rd Qu.:130.0   3rd Qu.:175  \n Max.   :99.00   Max.   :188.0   Max.   :198.0   Max.   :295  \n\n# Personally I prefer skim from skimr\n# install.packages(\"skimr\")\nlibrary(skimr)\nskim(ugtests)\n\n\nData summary\n\n\nName\nugtests\n\n\nNumber of rows\n975\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nYr1\n0\n1\n52.15\n14.92\n3\n42\n53\n62\n99\n▁▃▇▅▁\n\n\nYr2\n0\n1\n92.40\n30.04\n6\n73\n94\n112\n188\n▁▅▇▃▁\n\n\nYr3\n0\n1\n105.12\n33.51\n8\n81\n105\n130\n198\n▁▅▇▅▁\n\n\nFinal\n0\n1\n148.96\n44.34\n8\n118\n147\n175\n295\n▁▅▇▃▁\n\n\n\n\n\nThere is no missing data.\n\nView the subset of ugtests for values of Yr1 greater than 50.\n\n\nlibrary(kableExtra)\nsubset(ugtests, subset = Yr1 > 50) %>% kable() %>% scroll_box(height=\"400px\")\n\n\n\n \n  \n      \n    Yr1 \n    Yr2 \n    Yr3 \n    Final \n  \n \n\n  \n    2 \n    70 \n    104 \n    126 \n    207 \n  \n  \n    6 \n    86 \n    122 \n    119 \n    159 \n  \n  \n    8 \n    60 \n    92 \n    78 \n    84 \n  \n  \n    10 \n    80 \n    127 \n    67 \n    80 \n  \n  \n    13 \n    64 \n    123 \n    110 \n    175 \n  \n  \n    14 \n    62 \n    84 \n    142 \n    182 \n  \n  \n    15 \n    61 \n    65 \n    134 \n    155 \n  \n  \n    16 \n    60 \n    150 \n    116 \n    198 \n  \n  \n    17 \n    58 \n    76 \n    107 \n    161 \n  \n  \n    19 \n    64 \n    87 \n    106 \n    100 \n  \n  \n    20 \n    55 \n    111 \n    135 \n    179 \n  \n  \n    21 \n    77 \n    97 \n    111 \n    164 \n  \n  \n    24 \n    65 \n    72 \n    148 \n    152 \n  \n  \n    25 \n    57 \n    180 \n    112 \n    216 \n  \n  \n    28 \n    93 \n    102 \n    136 \n    168 \n  \n  \n    30 \n    53 \n    73 \n    63 \n    88 \n  \n  \n    32 \n    75 \n    125 \n    98 \n    134 \n  \n  \n    35 \n    55 \n    97 \n    101 \n    170 \n  \n  \n    36 \n    68 \n    109 \n    141 \n    229 \n  \n  \n    37 \n    73 \n    52 \n    124 \n    132 \n  \n  \n    40 \n    63 \n    107 \n    165 \n    213 \n  \n  \n    47 \n    76 \n    95 \n    52 \n    123 \n  \n  \n    48 \n    52 \n    106 \n    144 \n    166 \n  \n  \n    50 \n    54 \n    27 \n    111 \n    90 \n  \n  \n    52 \n    73 \n    22 \n    146 \n    160 \n  \n  \n    53 \n    60 \n    68 \n    54 \n    125 \n  \n  \n    54 \n    67 \n    45 \n    80 \n    145 \n  \n  \n    57 \n    75 \n    103 \n    91 \n    152 \n  \n  \n    58 \n    60 \n    80 \n    43 \n    125 \n  \n  \n    59 \n    54 \n    13 \n    106 \n    143 \n  \n  \n    60 \n    69 \n    64 \n    161 \n    161 \n  \n  \n    61 \n    54 \n    125 \n    107 \n    98 \n  \n  \n    62 \n    52 \n    65 \n    157 \n    183 \n  \n  \n    67 \n    55 \n    110 \n    106 \n    133 \n  \n  \n    69 \n    52 \n    68 \n    135 \n    138 \n  \n  \n    70 \n    59 \n    97 \n    105 \n    132 \n  \n  \n    74 \n    55 \n    71 \n    111 \n    139 \n  \n  \n    75 \n    69 \n    55 \n    82 \n    119 \n  \n  \n    76 \n    72 \n    62 \n    104 \n    171 \n  \n  \n    77 \n    61 \n    108 \n    98 \n    160 \n  \n  \n    78 \n    55 \n    90 \n    49 \n    117 \n  \n  \n    80 \n    59 \n    36 \n    95 \n    122 \n  \n  \n    83 \n    66 \n    142 \n    101 \n    244 \n  \n  \n    85 \n    62 \n    96 \n    147 \n    248 \n  \n  \n    87 \n    59 \n    105 \n    157 \n    198 \n  \n  \n    88 \n    68 \n    72 \n    111 \n    160 \n  \n  \n    89 \n    54 \n    86 \n    79 \n    124 \n  \n  \n    93 \n    52 \n    88 \n    107 \n    93 \n  \n  \n    94 \n    53 \n    92 \n    118 \n    182 \n  \n  \n    95 \n    54 \n    71 \n    107 \n    114 \n  \n  \n    96 \n    75 \n    71 \n    108 \n    147 \n  \n  \n    97 \n    52 \n    54 \n    98 \n    122 \n  \n  \n    99 \n    52 \n    74 \n    128 \n    108 \n  \n  \n    100 \n    64 \n    95 \n    125 \n    158 \n  \n  \n    101 \n    64 \n    122 \n    78 \n    168 \n  \n  \n    104 \n    62 \n    98 \n    171 \n    197 \n  \n  \n    107 \n    70 \n    37 \n    76 \n    137 \n  \n  \n    110 \n    53 \n    66 \n    60 \n    126 \n  \n  \n    111 \n    70 \n    110 \n    44 \n    105 \n  \n  \n    112 \n    65 \n    37 \n    101 \n    102 \n  \n  \n    113 \n    79 \n    122 \n    69 \n    92 \n  \n  \n    114 \n    60 \n    63 \n    103 \n    131 \n  \n  \n    116 \n    66 \n    94 \n    112 \n    101 \n  \n  \n    119 \n    82 \n    99 \n    184 \n    211 \n  \n  \n    120 \n    63 \n    71 \n    102 \n    172 \n  \n  \n    124 \n    59 \n    67 \n    50 \n    86 \n  \n  \n    125 \n    60 \n    128 \n    94 \n    171 \n  \n  \n    126 \n    60 \n    121 \n    174 \n    263 \n  \n  \n    129 \n    63 \n    83 \n    115 \n    144 \n  \n  \n    134 \n    54 \n    79 \n    103 \n    150 \n  \n  \n    135 \n    70 \n    95 \n    102 \n    136 \n  \n  \n    138 \n    62 \n    97 \n    61 \n    168 \n  \n  \n    143 \n    74 \n    126 \n    84 \n    110 \n  \n  \n    146 \n    70 \n    102 \n    67 \n    136 \n  \n  \n    149 \n    56 \n    26 \n    90 \n    97 \n  \n  \n    152 \n    70 \n    86 \n    32 \n    88 \n  \n  \n    156 \n    73 \n    105 \n    146 \n    204 \n  \n  \n    157 \n    59 \n    78 \n    47 \n    79 \n  \n  \n    161 \n    53 \n    18 \n    96 \n    70 \n  \n  \n    165 \n    71 \n    136 \n    156 \n    171 \n  \n  \n    167 \n    61 \n    106 \n    108 \n    110 \n  \n  \n    169 \n    66 \n    104 \n    91 \n    124 \n  \n  \n    171 \n    58 \n    116 \n    116 \n    174 \n  \n  \n    173 \n    80 \n    143 \n    137 \n    247 \n  \n  \n    174 \n    52 \n    133 \n    87 \n    159 \n  \n  \n    178 \n    60 \n    101 \n    68 \n    100 \n  \n  \n    179 \n    64 \n    97 \n    64 \n    150 \n  \n  \n    182 \n    57 \n    116 \n    88 \n    134 \n  \n  \n    183 \n    76 \n    163 \n    60 \n    100 \n  \n  \n    185 \n    74 \n    39 \n    55 \n    104 \n  \n  \n    186 \n    54 \n    46 \n    100 \n    125 \n  \n  \n    188 \n    57 \n    111 \n    133 \n    166 \n  \n  \n    189 \n    56 \n    89 \n    146 \n    210 \n  \n  \n    191 \n    73 \n    26 \n    91 \n    79 \n  \n  \n    192 \n    64 \n    63 \n    119 \n    105 \n  \n  \n    193 \n    67 \n    64 \n    118 \n    135 \n  \n  \n    196 \n    57 \n    107 \n    54 \n    118 \n  \n  \n    199 \n    54 \n    116 \n    127 \n    144 \n  \n  \n    200 \n    76 \n    137 \n    97 \n    139 \n  \n  \n    203 \n    70 \n    57 \n    95 \n    116 \n  \n  \n    204 \n    60 \n    123 \n    143 \n    206 \n  \n  \n    205 \n    76 \n    122 \n    57 \n    164 \n  \n  \n    206 \n    55 \n    87 \n    138 \n    171 \n  \n  \n    208 \n    59 \n    129 \n    63 \n    93 \n  \n  \n    209 \n    64 \n    90 \n    115 \n    123 \n  \n  \n    210 \n    54 \n    106 \n    93 \n    118 \n  \n  \n    212 \n    71 \n    109 \n    105 \n    148 \n  \n  \n    213 \n    54 \n    86 \n    41 \n    125 \n  \n  \n    214 \n    59 \n    42 \n    102 \n    156 \n  \n  \n    217 \n    57 \n    65 \n    111 \n    89 \n  \n  \n    218 \n    58 \n    99 \n    104 \n    188 \n  \n  \n    220 \n    78 \n    120 \n    93 \n    185 \n  \n  \n    222 \n    56 \n    112 \n    79 \n    128 \n  \n  \n    224 \n    76 \n    83 \n    122 \n    147 \n  \n  \n    225 \n    65 \n    71 \n    117 \n    171 \n  \n  \n    227 \n    56 \n    59 \n    68 \n    105 \n  \n  \n    228 \n    56 \n    103 \n    55 \n    105 \n  \n  \n    229 \n    81 \n    100 \n    111 \n    153 \n  \n  \n    231 \n    57 \n    124 \n    100 \n    174 \n  \n  \n    232 \n    58 \n    52 \n    168 \n    133 \n  \n  \n    236 \n    65 \n    107 \n    154 \n    196 \n  \n  \n    237 \n    60 \n    75 \n    84 \n    129 \n  \n  \n    240 \n    55 \n    83 \n    65 \n    106 \n  \n  \n    241 \n    73 \n    135 \n    71 \n    115 \n  \n  \n    243 \n    52 \n    105 \n    119 \n    167 \n  \n  \n    244 \n    56 \n    95 \n    185 \n    237 \n  \n  \n    250 \n    61 \n    60 \n    151 \n    146 \n  \n  \n    251 \n    61 \n    123 \n    94 \n    162 \n  \n  \n    252 \n    65 \n    126 \n    139 \n    198 \n  \n  \n    256 \n    59 \n    61 \n    54 \n    135 \n  \n  \n    257 \n    62 \n    90 \n    140 \n    201 \n  \n  \n    258 \n    85 \n    156 \n    88 \n    102 \n  \n  \n    259 \n    72 \n    131 \n    105 \n    152 \n  \n  \n    260 \n    53 \n    132 \n    113 \n    203 \n  \n  \n    263 \n    59 \n    95 \n    67 \n    101 \n  \n  \n    264 \n    76 \n    91 \n    61 \n    86 \n  \n  \n    265 \n    53 \n    110 \n    109 \n    179 \n  \n  \n    266 \n    71 \n    46 \n    147 \n    74 \n  \n  \n    267 \n    69 \n    110 \n    123 \n    138 \n  \n  \n    270 \n    56 \n    83 \n    94 \n    97 \n  \n  \n    271 \n    68 \n    100 \n    132 \n    181 \n  \n  \n    272 \n    94 \n    120 \n    112 \n    141 \n  \n  \n    275 \n    62 \n    68 \n    98 \n    135 \n  \n  \n    276 \n    77 \n    124 \n    84 \n    161 \n  \n  \n    279 \n    63 \n    124 \n    97 \n    127 \n  \n  \n    285 \n    79 \n    108 \n    84 \n    152 \n  \n  \n    286 \n    71 \n    84 \n    57 \n    140 \n  \n  \n    287 \n    75 \n    30 \n    54 \n    170 \n  \n  \n    288 \n    65 \n    74 \n    81 \n    116 \n  \n  \n    289 \n    52 \n    97 \n    58 \n    118 \n  \n  \n    290 \n    67 \n    72 \n    148 \n    181 \n  \n  \n    291 \n    67 \n    38 \n    142 \n    135 \n  \n  \n    292 \n    56 \n    88 \n    144 \n    141 \n  \n  \n    293 \n    61 \n    123 \n    152 \n    221 \n  \n  \n    296 \n    71 \n    89 \n    133 \n    167 \n  \n  \n    297 \n    52 \n    82 \n    107 \n    111 \n  \n  \n    298 \n    63 \n    106 \n    74 \n    160 \n  \n  \n    299 \n    72 \n    97 \n    64 \n    135 \n  \n  \n    300 \n    56 \n    128 \n    165 \n    206 \n  \n  \n    301 \n    64 \n    68 \n    140 \n    214 \n  \n  \n    302 \n    62 \n    85 \n    80 \n    99 \n  \n  \n    303 \n    73 \n    114 \n    111 \n    182 \n  \n  \n    305 \n    57 \n    144 \n    56 \n    127 \n  \n  \n    307 \n    53 \n    25 \n    77 \n    128 \n  \n  \n    308 \n    56 \n    65 \n    144 \n    124 \n  \n  \n    311 \n    77 \n    80 \n    73 \n    166 \n  \n  \n    314 \n    63 \n    85 \n    118 \n    164 \n  \n  \n    315 \n    64 \n    161 \n    95 \n    164 \n  \n  \n    316 \n    59 \n    65 \n    85 \n    119 \n  \n  \n    318 \n    71 \n    73 \n    131 \n    126 \n  \n  \n    319 \n    65 \n    106 \n    128 \n    146 \n  \n  \n    321 \n    71 \n    73 \n    151 \n    190 \n  \n  \n    324 \n    99 \n    87 \n    158 \n    238 \n  \n  \n    328 \n    65 \n    103 \n    72 \n    93 \n  \n  \n    329 \n    57 \n    94 \n    147 \n    234 \n  \n  \n    340 \n    56 \n    83 \n    49 \n    162 \n  \n  \n    341 \n    60 \n    73 \n    117 \n    162 \n  \n  \n    342 \n    61 \n    100 \n    90 \n    151 \n  \n  \n    345 \n    54 \n    92 \n    56 \n    66 \n  \n  \n    346 \n    84 \n    98 \n    111 \n    182 \n  \n  \n    347 \n    77 \n    126 \n    121 \n    195 \n  \n  \n    348 \n    53 \n    62 \n    120 \n    141 \n  \n  \n    349 \n    58 \n    98 \n    95 \n    132 \n  \n  \n    351 \n    64 \n    82 \n    93 \n    114 \n  \n  \n    353 \n    55 \n    108 \n    60 \n    109 \n  \n  \n    355 \n    56 \n    140 \n    114 \n    178 \n  \n  \n    356 \n    54 \n    90 \n    99 \n    105 \n  \n  \n    357 \n    65 \n    84 \n    125 \n    160 \n  \n  \n    359 \n    54 \n    92 \n    138 \n    155 \n  \n  \n    360 \n    69 \n    133 \n    158 \n    228 \n  \n  \n    361 \n    55 \n    92 \n    119 \n    152 \n  \n  \n    364 \n    72 \n    79 \n    124 \n    146 \n  \n  \n    365 \n    57 \n    88 \n    93 \n    91 \n  \n  \n    366 \n    59 \n    45 \n    103 \n    122 \n  \n  \n    368 \n    61 \n    119 \n    95 \n    158 \n  \n  \n    369 \n    58 \n    120 \n    136 \n    184 \n  \n  \n    370 \n    57 \n    105 \n    146 \n    210 \n  \n  \n    371 \n    62 \n    114 \n    131 \n    227 \n  \n  \n    373 \n    56 \n    86 \n    129 \n    200 \n  \n  \n    375 \n    78 \n    133 \n    142 \n    209 \n  \n  \n    378 \n    60 \n    125 \n    127 \n    230 \n  \n  \n    379 \n    66 \n    77 \n    133 \n    138 \n  \n  \n    383 \n    52 \n    97 \n    56 \n    132 \n  \n  \n    384 \n    69 \n    71 \n    140 \n    167 \n  \n  \n    387 \n    55 \n    73 \n    114 \n    152 \n  \n  \n    388 \n    57 \n    42 \n    84 \n    124 \n  \n  \n    390 \n    52 \n    23 \n    174 \n    153 \n  \n  \n    393 \n    65 \n    87 \n    116 \n    148 \n  \n  \n    394 \n    79 \n    87 \n    119 \n    138 \n  \n  \n    395 \n    58 \n    104 \n    156 \n    159 \n  \n  \n    396 \n    82 \n    97 \n    67 \n    111 \n  \n  \n    397 \n    58 \n    110 \n    95 \n    123 \n  \n  \n    399 \n    56 \n    81 \n    133 \n    182 \n  \n  \n    400 \n    77 \n    103 \n    125 \n    179 \n  \n  \n    402 \n    54 \n    92 \n    105 \n    139 \n  \n  \n    403 \n    59 \n    81 \n    67 \n    114 \n  \n  \n    411 \n    70 \n    134 \n    138 \n    191 \n  \n  \n    413 \n    60 \n    103 \n    52 \n    94 \n  \n  \n    414 \n    57 \n    65 \n    109 \n    175 \n  \n  \n    415 \n    82 \n    40 \n    77 \n    85 \n  \n  \n    419 \n    64 \n    87 \n    109 \n    162 \n  \n  \n    420 \n    57 \n    96 \n    116 \n    114 \n  \n  \n    423 \n    59 \n    89 \n    125 \n    174 \n  \n  \n    428 \n    54 \n    136 \n    71 \n    167 \n  \n  \n    429 \n    63 \n    108 \n    143 \n    187 \n  \n  \n    433 \n    69 \n    93 \n    116 \n    172 \n  \n  \n    437 \n    61 \n    133 \n    144 \n    279 \n  \n  \n    438 \n    70 \n    57 \n    55 \n    85 \n  \n  \n    439 \n    71 \n    84 \n    175 \n    219 \n  \n  \n    440 \n    59 \n    143 \n    47 \n    81 \n  \n  \n    441 \n    72 \n    102 \n    82 \n    143 \n  \n  \n    442 \n    72 \n    128 \n    129 \n    180 \n  \n  \n    443 \n    52 \n    46 \n    101 \n    147 \n  \n  \n    445 \n    56 \n    171 \n    143 \n    220 \n  \n  \n    446 \n    52 \n    130 \n    45 \n    48 \n  \n  \n    447 \n    62 \n    132 \n    75 \n    109 \n  \n  \n    450 \n    86 \n    89 \n    102 \n    171 \n  \n  \n    455 \n    66 \n    141 \n    102 \n    178 \n  \n  \n    456 \n    84 \n    101 \n    106 \n    110 \n  \n  \n    461 \n    80 \n    100 \n    58 \n    128 \n  \n  \n    462 \n    55 \n    103 \n    70 \n    91 \n  \n  \n    463 \n    60 \n    105 \n    84 \n    151 \n  \n  \n    464 \n    62 \n    76 \n    106 \n    123 \n  \n  \n    466 \n    57 \n    71 \n    57 \n    83 \n  \n  \n    467 \n    62 \n    104 \n    117 \n    212 \n  \n  \n    468 \n    53 \n    187 \n    75 \n    108 \n  \n  \n    469 \n    71 \n    95 \n    113 \n    151 \n  \n  \n    472 \n    76 \n    76 \n    112 \n    193 \n  \n  \n    474 \n    57 \n    129 \n    100 \n    172 \n  \n  \n    476 \n    58 \n    82 \n    108 \n    106 \n  \n  \n    478 \n    65 \n    110 \n    144 \n    164 \n  \n  \n    481 \n    64 \n    123 \n    85 \n    126 \n  \n  \n    483 \n    61 \n    60 \n    112 \n    106 \n  \n  \n    484 \n    52 \n    108 \n    98 \n    174 \n  \n  \n    485 \n    75 \n    44 \n    108 \n    130 \n  \n  \n    486 \n    67 \n    123 \n    110 \n    226 \n  \n  \n    488 \n    52 \n    102 \n    81 \n    156 \n  \n  \n    490 \n    76 \n    97 \n    138 \n    154 \n  \n  \n    491 \n    52 \n    65 \n    108 \n    169 \n  \n  \n    495 \n    68 \n    90 \n    117 \n    135 \n  \n  \n    496 \n    56 \n    138 \n    141 \n    256 \n  \n  \n    497 \n    61 \n    76 \n    77 \n    110 \n  \n  \n    498 \n    88 \n    85 \n    81 \n    123 \n  \n  \n    500 \n    91 \n    103 \n    110 \n    159 \n  \n  \n    505 \n    54 \n    78 \n    150 \n    220 \n  \n  \n    508 \n    63 \n    63 \n    96 \n    89 \n  \n  \n    509 \n    67 \n    79 \n    86 \n    182 \n  \n  \n    512 \n    55 \n    96 \n    72 \n    157 \n  \n  \n    513 \n    65 \n    50 \n    104 \n    129 \n  \n  \n    514 \n    58 \n    96 \n    125 \n    171 \n  \n  \n    515 \n    63 \n    89 \n    111 \n    198 \n  \n  \n    518 \n    62 \n    53 \n    139 \n    163 \n  \n  \n    519 \n    57 \n    133 \n    41 \n    76 \n  \n  \n    522 \n    72 \n    97 \n    69 \n    114 \n  \n  \n    523 \n    65 \n    123 \n    89 \n    207 \n  \n  \n    525 \n    54 \n    87 \n    147 \n    192 \n  \n  \n    526 \n    81 \n    64 \n    107 \n    159 \n  \n  \n    527 \n    59 \n    120 \n    88 \n    149 \n  \n  \n    531 \n    56 \n    60 \n    123 \n    153 \n  \n  \n    533 \n    55 \n    63 \n    47 \n    106 \n  \n  \n    534 \n    56 \n    98 \n    48 \n    115 \n  \n  \n    536 \n    57 \n    112 \n    94 \n    142 \n  \n  \n    537 \n    62 \n    146 \n    78 \n    153 \n  \n  \n    538 \n    61 \n    80 \n    183 \n    189 \n  \n  \n    539 \n    81 \n    89 \n    125 \n    157 \n  \n  \n    540 \n    59 \n    116 \n    109 \n    165 \n  \n  \n    544 \n    72 \n    142 \n    64 \n    96 \n  \n  \n    546 \n    52 \n    162 \n    140 \n    269 \n  \n  \n    547 \n    61 \n    100 \n    72 \n    134 \n  \n  \n    549 \n    71 \n    127 \n    66 \n    85 \n  \n  \n    550 \n    56 \n    117 \n    152 \n    265 \n  \n  \n    551 \n    62 \n    97 \n    117 \n    157 \n  \n  \n    552 \n    56 \n    81 \n    183 \n    194 \n  \n  \n    554 \n    56 \n    129 \n    98 \n    105 \n  \n  \n    557 \n    63 \n    69 \n    53 \n    109 \n  \n  \n    558 \n    81 \n    57 \n    99 \n    120 \n  \n  \n    559 \n    67 \n    156 \n    154 \n    232 \n  \n  \n    561 \n    52 \n    85 \n    56 \n    173 \n  \n  \n    562 \n    56 \n    78 \n    100 \n    124 \n  \n  \n    566 \n    63 \n    123 \n    85 \n    164 \n  \n  \n    567 \n    75 \n    177 \n    100 \n    151 \n  \n  \n    568 \n    69 \n    53 \n    49 \n    130 \n  \n  \n    570 \n    55 \n    73 \n    70 \n    172 \n  \n  \n    571 \n    57 \n    95 \n    95 \n    151 \n  \n  \n    572 \n    54 \n    84 \n    110 \n    125 \n  \n  \n    573 \n    57 \n    122 \n    98 \n    202 \n  \n  \n    574 \n    65 \n    106 \n    96 \n    95 \n  \n  \n    576 \n    75 \n    85 \n    105 \n    113 \n  \n  \n    577 \n    53 \n    114 \n    112 \n    176 \n  \n  \n    578 \n    75 \n    49 \n    70 \n    139 \n  \n  \n    580 \n    66 \n    71 \n    91 \n    135 \n  \n  \n    581 \n    52 \n    92 \n    142 \n    188 \n  \n  \n    582 \n    54 \n    48 \n    131 \n    165 \n  \n  \n    583 \n    57 \n    54 \n    65 \n    86 \n  \n  \n    585 \n    66 \n    147 \n    94 \n    120 \n  \n  \n    586 \n    61 \n    68 \n    64 \n    159 \n  \n  \n    588 \n    60 \n    102 \n    139 \n    114 \n  \n  \n    590 \n    73 \n    100 \n    74 \n    140 \n  \n  \n    591 \n    57 \n    48 \n    90 \n    175 \n  \n  \n    594 \n    53 \n    72 \n    174 \n    202 \n  \n  \n    598 \n    69 \n    101 \n    112 \n    145 \n  \n  \n    599 \n    55 \n    97 \n    40 \n    24 \n  \n  \n    600 \n    71 \n    112 \n    91 \n    150 \n  \n  \n    602 \n    54 \n    105 \n    165 \n    245 \n  \n  \n    603 \n    66 \n    60 \n    146 \n    208 \n  \n  \n    605 \n    74 \n    98 \n    55 \n    155 \n  \n  \n    607 \n    74 \n    78 \n    93 \n    170 \n  \n  \n    608 \n    61 \n    60 \n    86 \n    142 \n  \n  \n    609 \n    59 \n    130 \n    68 \n    124 \n  \n  \n    611 \n    67 \n    126 \n    164 \n    287 \n  \n  \n    613 \n    54 \n    133 \n    72 \n    114 \n  \n  \n    614 \n    70 \n    59 \n    82 \n    137 \n  \n  \n    616 \n    64 \n    22 \n    111 \n    110 \n  \n  \n    619 \n    71 \n    91 \n    67 \n    96 \n  \n  \n    620 \n    63 \n    24 \n    105 \n    152 \n  \n  \n    623 \n    59 \n    85 \n    132 \n    191 \n  \n  \n    625 \n    71 \n    118 \n    149 \n    235 \n  \n  \n    627 \n    53 \n    106 \n    134 \n    140 \n  \n  \n    628 \n    68 \n    75 \n    88 \n    150 \n  \n  \n    630 \n    61 \n    100 \n    125 \n    176 \n  \n  \n    631 \n    96 \n    124 \n    115 \n    182 \n  \n  \n    632 \n    73 \n    110 \n    164 \n    247 \n  \n  \n    633 \n    69 \n    74 \n    115 \n    144 \n  \n  \n    634 \n    64 \n    69 \n    58 \n    102 \n  \n  \n    635 \n    64 \n    116 \n    113 \n    116 \n  \n  \n    637 \n    55 \n    131 \n    96 \n    146 \n  \n  \n    638 \n    62 \n    100 \n    83 \n    137 \n  \n  \n    642 \n    57 \n    53 \n    101 \n    147 \n  \n  \n    644 \n    72 \n    73 \n    103 \n    133 \n  \n  \n    646 \n    58 \n    123 \n    101 \n    174 \n  \n  \n    647 \n    68 \n    83 \n    44 \n    108 \n  \n  \n    656 \n    53 \n    110 \n    59 \n    65 \n  \n  \n    657 \n    61 \n    68 \n    103 \n    149 \n  \n  \n    660 \n    58 \n    152 \n    104 \n    199 \n  \n  \n    661 \n    79 \n    70 \n    100 \n    144 \n  \n  \n    662 \n    58 \n    56 \n    102 \n    146 \n  \n  \n    663 \n    60 \n    78 \n    122 \n    137 \n  \n  \n    664 \n    72 \n    106 \n    91 \n    134 \n  \n  \n    665 \n    63 \n    85 \n    109 \n    170 \n  \n  \n    666 \n    69 \n    33 \n    74 \n    147 \n  \n  \n    671 \n    58 \n    84 \n    166 \n    186 \n  \n  \n    672 \n    84 \n    86 \n    97 \n    171 \n  \n  \n    673 \n    58 \n    70 \n    85 \n    114 \n  \n  \n    674 \n    55 \n    53 \n    106 \n    136 \n  \n  \n    675 \n    58 \n    83 \n    156 \n    155 \n  \n  \n    676 \n    83 \n    109 \n    146 \n    172 \n  \n  \n    678 \n    54 \n    51 \n    102 \n    117 \n  \n  \n    683 \n    54 \n    139 \n    74 \n    110 \n  \n  \n    685 \n    69 \n    143 \n    84 \n    178 \n  \n  \n    686 \n    59 \n    109 \n    137 \n    184 \n  \n  \n    687 \n    66 \n    72 \n    138 \n    140 \n  \n  \n    689 \n    53 \n    52 \n    130 \n    146 \n  \n  \n    693 \n    65 \n    108 \n    144 \n    224 \n  \n  \n    695 \n    72 \n    76 \n    92 \n    151 \n  \n  \n    698 \n    53 \n    73 \n    119 \n    132 \n  \n  \n    699 \n    80 \n    97 \n    101 \n    73 \n  \n  \n    703 \n    70 \n    139 \n    90 \n    141 \n  \n  \n    706 \n    55 \n    114 \n    94 \n    140 \n  \n  \n    709 \n    59 \n    58 \n    113 \n    154 \n  \n  \n    713 \n    54 \n    74 \n    51 \n    103 \n  \n  \n    714 \n    73 \n    119 \n    119 \n    224 \n  \n  \n    716 \n    52 \n    85 \n    80 \n    113 \n  \n  \n    717 \n    61 \n    47 \n    158 \n    137 \n  \n  \n    718 \n    56 \n    70 \n    61 \n    127 \n  \n  \n    719 \n    70 \n    79 \n    108 \n    106 \n  \n  \n    722 \n    66 \n    97 \n    115 \n    145 \n  \n  \n    724 \n    70 \n    130 \n    120 \n    186 \n  \n  \n    725 \n    71 \n    93 \n    118 \n    111 \n  \n  \n    730 \n    58 \n    100 \n    55 \n    117 \n  \n  \n    732 \n    54 \n    16 \n    95 \n    138 \n  \n  \n    733 \n    64 \n    123 \n    90 \n    198 \n  \n  \n    736 \n    67 \n    79 \n    68 \n    134 \n  \n  \n    737 \n    52 \n    124 \n    104 \n    193 \n  \n  \n    739 \n    58 \n    46 \n    74 \n    121 \n  \n  \n    742 \n    59 \n    74 \n    62 \n    162 \n  \n  \n    743 \n    58 \n    113 \n    40 \n    89 \n  \n  \n    744 \n    79 \n    94 \n    51 \n    166 \n  \n  \n    745 \n    57 \n    125 \n    101 \n    156 \n  \n  \n    746 \n    99 \n    76 \n    105 \n    110 \n  \n  \n    747 \n    59 \n    110 \n    137 \n    218 \n  \n  \n    749 \n    54 \n    76 \n    177 \n    205 \n  \n  \n    750 \n    61 \n    132 \n    60 \n    140 \n  \n  \n    752 \n    63 \n    146 \n    123 \n    186 \n  \n  \n    753 \n    53 \n    125 \n    45 \n    96 \n  \n  \n    758 \n    53 \n    124 \n    69 \n    110 \n  \n  \n    759 \n    58 \n    137 \n    137 \n    211 \n  \n  \n    760 \n    69 \n    68 \n    127 \n    184 \n  \n  \n    762 \n    74 \n    104 \n    60 \n    104 \n  \n  \n    763 \n    58 \n    69 \n    55 \n    131 \n  \n  \n    764 \n    75 \n    124 \n    152 \n    208 \n  \n  \n    767 \n    52 \n    55 \n    145 \n    149 \n  \n  \n    768 \n    52 \n    71 \n    79 \n    106 \n  \n  \n    769 \n    53 \n    124 \n    110 \n    150 \n  \n  \n    770 \n    61 \n    100 \n    131 \n    170 \n  \n  \n    772 \n    62 \n    84 \n    91 \n    116 \n  \n  \n    776 \n    75 \n    121 \n    138 \n    171 \n  \n  \n    777 \n    52 \n    62 \n    130 \n    130 \n  \n  \n    779 \n    55 \n    97 \n    116 \n    101 \n  \n  \n    781 \n    57 \n    110 \n    103 \n    149 \n  \n  \n    782 \n    61 \n    100 \n    111 \n    187 \n  \n  \n    785 \n    71 \n    57 \n    85 \n    111 \n  \n  \n    787 \n    54 \n    78 \n    74 \n    99 \n  \n  \n    790 \n    61 \n    75 \n    123 \n    145 \n  \n  \n    792 \n    58 \n    90 \n    173 \n    243 \n  \n  \n    794 \n    60 \n    117 \n    75 \n    120 \n  \n  \n    797 \n    63 \n    102 \n    138 \n    198 \n  \n  \n    798 \n    59 \n    46 \n    98 \n    139 \n  \n  \n    800 \n    60 \n    96 \n    115 \n    114 \n  \n  \n    801 \n    53 \n    89 \n    94 \n    108 \n  \n  \n    802 \n    57 \n    144 \n    79 \n    163 \n  \n  \n    808 \n    56 \n    57 \n    84 \n    186 \n  \n  \n    809 \n    65 \n    87 \n    78 \n    134 \n  \n  \n    813 \n    75 \n    69 \n    116 \n    141 \n  \n  \n    815 \n    90 \n    97 \n    52 \n    122 \n  \n  \n    816 \n    60 \n    112 \n    164 \n    243 \n  \n  \n    818 \n    71 \n    83 \n    89 \n    162 \n  \n  \n    819 \n    57 \n    121 \n    72 \n    124 \n  \n  \n    820 \n    58 \n    139 \n    53 \n    86 \n  \n  \n    821 \n    66 \n    118 \n    139 \n    174 \n  \n  \n    822 \n    53 \n    81 \n    133 \n    151 \n  \n  \n    823 \n    64 \n    42 \n    124 \n    111 \n  \n  \n    824 \n    59 \n    110 \n    139 \n    179 \n  \n  \n    825 \n    62 \n    132 \n    136 \n    242 \n  \n  \n    827 \n    70 \n    60 \n    166 \n    165 \n  \n  \n    828 \n    56 \n    124 \n    108 \n    148 \n  \n  \n    830 \n    69 \n    87 \n    144 \n    182 \n  \n  \n    831 \n    56 \n    105 \n    151 \n    164 \n  \n  \n    832 \n    68 \n    42 \n    89 \n    128 \n  \n  \n    833 \n    68 \n    97 \n    76 \n    111 \n  \n  \n    836 \n    66 \n    81 \n    37 \n    119 \n  \n  \n    838 \n    68 \n    116 \n    104 \n    131 \n  \n  \n    839 \n    56 \n    77 \n    73 \n    89 \n  \n  \n    841 \n    74 \n    100 \n    81 \n    126 \n  \n  \n    844 \n    68 \n    96 \n    84 \n    108 \n  \n  \n    848 \n    68 \n    149 \n    152 \n    190 \n  \n  \n    849 \n    64 \n    6 \n    108 \n    67 \n  \n  \n    851 \n    72 \n    125 \n    88 \n    155 \n  \n  \n    852 \n    56 \n    48 \n    69 \n    119 \n  \n  \n    855 \n    70 \n    92 \n    141 \n    203 \n  \n  \n    857 \n    57 \n    65 \n    103 \n    151 \n  \n  \n    858 \n    62 \n    92 \n    120 \n    169 \n  \n  \n    859 \n    62 \n    64 \n    88 \n    129 \n  \n  \n    860 \n    55 \n    64 \n    139 \n    94 \n  \n  \n    865 \n    61 \n    59 \n    89 \n    142 \n  \n  \n    867 \n    67 \n    110 \n    41 \n    98 \n  \n  \n    868 \n    54 \n    83 \n    67 \n    69 \n  \n  \n    870 \n    64 \n    46 \n    124 \n    162 \n  \n  \n    873 \n    61 \n    75 \n    113 \n    159 \n  \n  \n    875 \n    52 \n    79 \n    107 \n    118 \n  \n  \n    877 \n    66 \n    137 \n    164 \n    257 \n  \n  \n    880 \n    57 \n    86 \n    91 \n    128 \n  \n  \n    881 \n    60 \n    41 \n    120 \n    128 \n  \n  \n    883 \n    68 \n    137 \n    119 \n    175 \n  \n  \n    884 \n    58 \n    70 \n    159 \n    159 \n  \n  \n    886 \n    58 \n    84 \n    95 \n    142 \n  \n  \n    887 \n    72 \n    124 \n    89 \n    136 \n  \n  \n    890 \n    66 \n    93 \n    136 \n    178 \n  \n  \n    891 \n    53 \n    59 \n    62 \n    87 \n  \n  \n    893 \n    70 \n    65 \n    71 \n    101 \n  \n  \n    895 \n    59 \n    47 \n    82 \n    141 \n  \n  \n    896 \n    54 \n    99 \n    89 \n    125 \n  \n  \n    897 \n    52 \n    80 \n    165 \n    136 \n  \n  \n    899 \n    58 \n    115 \n    112 \n    147 \n  \n  \n    901 \n    80 \n    89 \n    51 \n    85 \n  \n  \n    902 \n    62 \n    103 \n    139 \n    220 \n  \n  \n    906 \n    52 \n    75 \n    37 \n    56 \n  \n  \n    907 \n    63 \n    80 \n    171 \n    176 \n  \n  \n    908 \n    66 \n    45 \n    130 \n    139 \n  \n  \n    910 \n    58 \n    94 \n    39 \n    50 \n  \n  \n    911 \n    53 \n    50 \n    96 \n    169 \n  \n  \n    917 \n    56 \n    90 \n    79 \n    81 \n  \n  \n    920 \n    70 \n    102 \n    119 \n    150 \n  \n  \n    923 \n    53 \n    21 \n    93 \n    130 \n  \n  \n    926 \n    64 \n    60 \n    97 \n    111 \n  \n  \n    927 \n    67 \n    129 \n    114 \n    183 \n  \n  \n    928 \n    72 \n    46 \n    99 \n    178 \n  \n  \n    929 \n    67 \n    96 \n    37 \n    86 \n  \n  \n    932 \n    54 \n    89 \n    151 \n    172 \n  \n  \n    933 \n    56 \n    64 \n    137 \n    125 \n  \n  \n    935 \n    57 \n    81 \n    87 \n    98 \n  \n  \n    936 \n    59 \n    134 \n    107 \n    169 \n  \n  \n    937 \n    75 \n    33 \n    110 \n    118 \n  \n  \n    940 \n    55 \n    108 \n    95 \n    181 \n  \n  \n    947 \n    62 \n    94 \n    62 \n    150 \n  \n  \n    948 \n    71 \n    81 \n    137 \n    213 \n  \n  \n    949 \n    78 \n    89 \n    45 \n    28 \n  \n  \n    952 \n    84 \n    136 \n    115 \n    199 \n  \n  \n    957 \n    55 \n    58 \n    44 \n    92 \n  \n  \n    958 \n    64 \n    115 \n    61 \n    97 \n  \n  \n    960 \n    54 \n    80 \n    74 \n    136 \n  \n  \n    961 \n    66 \n    81 \n    125 \n    99 \n  \n  \n    962 \n    56 \n    44 \n    105 \n    110 \n  \n  \n    965 \n    66 \n    188 \n    119 \n    260 \n  \n  \n    968 \n    64 \n    139 \n    92 \n    165 \n  \n  \n    971 \n    78 \n    68 \n    166 \n    176 \n  \n  \n    973 \n    80 \n    97 \n    121 \n    148 \n  \n  \n    975 \n    58 \n    135 \n    125 \n    172 \n  \n\n\n\n\n\n\nInstall and load the package dplyr. Look up the help for the filter() function in this package and try to use it to repeat the task in the previous question.\n\n\n# install.packages(\"dplyr\")\nlibrary(dplyr)\nfilter(ugtests, Yr1 > 50) %>% kable() %>% scroll_box(height=\"400px\")\n\n\n\n \n  \n    Yr1 \n    Yr2 \n    Yr3 \n    Final \n  \n \n\n  \n    70 \n    104 \n    126 \n    207 \n  \n  \n    86 \n    122 \n    119 \n    159 \n  \n  \n    60 \n    92 \n    78 \n    84 \n  \n  \n    80 \n    127 \n    67 \n    80 \n  \n  \n    64 \n    123 \n    110 \n    175 \n  \n  \n    62 \n    84 \n    142 \n    182 \n  \n  \n    61 \n    65 \n    134 \n    155 \n  \n  \n    60 \n    150 \n    116 \n    198 \n  \n  \n    58 \n    76 \n    107 \n    161 \n  \n  \n    64 \n    87 \n    106 \n    100 \n  \n  \n    55 \n    111 \n    135 \n    179 \n  \n  \n    77 \n    97 \n    111 \n    164 \n  \n  \n    65 \n    72 \n    148 \n    152 \n  \n  \n    57 \n    180 \n    112 \n    216 \n  \n  \n    93 \n    102 \n    136 \n    168 \n  \n  \n    53 \n    73 \n    63 \n    88 \n  \n  \n    75 \n    125 \n    98 \n    134 \n  \n  \n    55 \n    97 \n    101 \n    170 \n  \n  \n    68 \n    109 \n    141 \n    229 \n  \n  \n    73 \n    52 \n    124 \n    132 \n  \n  \n    63 \n    107 \n    165 \n    213 \n  \n  \n    76 \n    95 \n    52 \n    123 \n  \n  \n    52 \n    106 \n    144 \n    166 \n  \n  \n    54 \n    27 \n    111 \n    90 \n  \n  \n    73 \n    22 \n    146 \n    160 \n  \n  \n    60 \n    68 \n    54 \n    125 \n  \n  \n    67 \n    45 \n    80 \n    145 \n  \n  \n    75 \n    103 \n    91 \n    152 \n  \n  \n    60 \n    80 \n    43 \n    125 \n  \n  \n    54 \n    13 \n    106 \n    143 \n  \n  \n    69 \n    64 \n    161 \n    161 \n  \n  \n    54 \n    125 \n    107 \n    98 \n  \n  \n    52 \n    65 \n    157 \n    183 \n  \n  \n    55 \n    110 \n    106 \n    133 \n  \n  \n    52 \n    68 \n    135 \n    138 \n  \n  \n    59 \n    97 \n    105 \n    132 \n  \n  \n    55 \n    71 \n    111 \n    139 \n  \n  \n    69 \n    55 \n    82 \n    119 \n  \n  \n    72 \n    62 \n    104 \n    171 \n  \n  \n    61 \n    108 \n    98 \n    160 \n  \n  \n    55 \n    90 \n    49 \n    117 \n  \n  \n    59 \n    36 \n    95 \n    122 \n  \n  \n    66 \n    142 \n    101 \n    244 \n  \n  \n    62 \n    96 \n    147 \n    248 \n  \n  \n    59 \n    105 \n    157 \n    198 \n  \n  \n    68 \n    72 \n    111 \n    160 \n  \n  \n    54 \n    86 \n    79 \n    124 \n  \n  \n    52 \n    88 \n    107 \n    93 \n  \n  \n    53 \n    92 \n    118 \n    182 \n  \n  \n    54 \n    71 \n    107 \n    114 \n  \n  \n    75 \n    71 \n    108 \n    147 \n  \n  \n    52 \n    54 \n    98 \n    122 \n  \n  \n    52 \n    74 \n    128 \n    108 \n  \n  \n    64 \n    95 \n    125 \n    158 \n  \n  \n    64 \n    122 \n    78 \n    168 \n  \n  \n    62 \n    98 \n    171 \n    197 \n  \n  \n    70 \n    37 \n    76 \n    137 \n  \n  \n    53 \n    66 \n    60 \n    126 \n  \n  \n    70 \n    110 \n    44 \n    105 \n  \n  \n    65 \n    37 \n    101 \n    102 \n  \n  \n    79 \n    122 \n    69 \n    92 \n  \n  \n    60 \n    63 \n    103 \n    131 \n  \n  \n    66 \n    94 \n    112 \n    101 \n  \n  \n    82 \n    99 \n    184 \n    211 \n  \n  \n    63 \n    71 \n    102 \n    172 \n  \n  \n    59 \n    67 \n    50 \n    86 \n  \n  \n    60 \n    128 \n    94 \n    171 \n  \n  \n    60 \n    121 \n    174 \n    263 \n  \n  \n    63 \n    83 \n    115 \n    144 \n  \n  \n    54 \n    79 \n    103 \n    150 \n  \n  \n    70 \n    95 \n    102 \n    136 \n  \n  \n    62 \n    97 \n    61 \n    168 \n  \n  \n    74 \n    126 \n    84 \n    110 \n  \n  \n    70 \n    102 \n    67 \n    136 \n  \n  \n    56 \n    26 \n    90 \n    97 \n  \n  \n    70 \n    86 \n    32 \n    88 \n  \n  \n    73 \n    105 \n    146 \n    204 \n  \n  \n    59 \n    78 \n    47 \n    79 \n  \n  \n    53 \n    18 \n    96 \n    70 \n  \n  \n    71 \n    136 \n    156 \n    171 \n  \n  \n    61 \n    106 \n    108 \n    110 \n  \n  \n    66 \n    104 \n    91 \n    124 \n  \n  \n    58 \n    116 \n    116 \n    174 \n  \n  \n    80 \n    143 \n    137 \n    247 \n  \n  \n    52 \n    133 \n    87 \n    159 \n  \n  \n    60 \n    101 \n    68 \n    100 \n  \n  \n    64 \n    97 \n    64 \n    150 \n  \n  \n    57 \n    116 \n    88 \n    134 \n  \n  \n    76 \n    163 \n    60 \n    100 \n  \n  \n    74 \n    39 \n    55 \n    104 \n  \n  \n    54 \n    46 \n    100 \n    125 \n  \n  \n    57 \n    111 \n    133 \n    166 \n  \n  \n    56 \n    89 \n    146 \n    210 \n  \n  \n    73 \n    26 \n    91 \n    79 \n  \n  \n    64 \n    63 \n    119 \n    105 \n  \n  \n    67 \n    64 \n    118 \n    135 \n  \n  \n    57 \n    107 \n    54 \n    118 \n  \n  \n    54 \n    116 \n    127 \n    144 \n  \n  \n    76 \n    137 \n    97 \n    139 \n  \n  \n    70 \n    57 \n    95 \n    116 \n  \n  \n    60 \n    123 \n    143 \n    206 \n  \n  \n    76 \n    122 \n    57 \n    164 \n  \n  \n    55 \n    87 \n    138 \n    171 \n  \n  \n    59 \n    129 \n    63 \n    93 \n  \n  \n    64 \n    90 \n    115 \n    123 \n  \n  \n    54 \n    106 \n    93 \n    118 \n  \n  \n    71 \n    109 \n    105 \n    148 \n  \n  \n    54 \n    86 \n    41 \n    125 \n  \n  \n    59 \n    42 \n    102 \n    156 \n  \n  \n    57 \n    65 \n    111 \n    89 \n  \n  \n    58 \n    99 \n    104 \n    188 \n  \n  \n    78 \n    120 \n    93 \n    185 \n  \n  \n    56 \n    112 \n    79 \n    128 \n  \n  \n    76 \n    83 \n    122 \n    147 \n  \n  \n    65 \n    71 \n    117 \n    171 \n  \n  \n    56 \n    59 \n    68 \n    105 \n  \n  \n    56 \n    103 \n    55 \n    105 \n  \n  \n    81 \n    100 \n    111 \n    153 \n  \n  \n    57 \n    124 \n    100 \n    174 \n  \n  \n    58 \n    52 \n    168 \n    133 \n  \n  \n    65 \n    107 \n    154 \n    196 \n  \n  \n    60 \n    75 \n    84 \n    129 \n  \n  \n    55 \n    83 \n    65 \n    106 \n  \n  \n    73 \n    135 \n    71 \n    115 \n  \n  \n    52 \n    105 \n    119 \n    167 \n  \n  \n    56 \n    95 \n    185 \n    237 \n  \n  \n    61 \n    60 \n    151 \n    146 \n  \n  \n    61 \n    123 \n    94 \n    162 \n  \n  \n    65 \n    126 \n    139 \n    198 \n  \n  \n    59 \n    61 \n    54 \n    135 \n  \n  \n    62 \n    90 \n    140 \n    201 \n  \n  \n    85 \n    156 \n    88 \n    102 \n  \n  \n    72 \n    131 \n    105 \n    152 \n  \n  \n    53 \n    132 \n    113 \n    203 \n  \n  \n    59 \n    95 \n    67 \n    101 \n  \n  \n    76 \n    91 \n    61 \n    86 \n  \n  \n    53 \n    110 \n    109 \n    179 \n  \n  \n    71 \n    46 \n    147 \n    74 \n  \n  \n    69 \n    110 \n    123 \n    138 \n  \n  \n    56 \n    83 \n    94 \n    97 \n  \n  \n    68 \n    100 \n    132 \n    181 \n  \n  \n    94 \n    120 \n    112 \n    141 \n  \n  \n    62 \n    68 \n    98 \n    135 \n  \n  \n    77 \n    124 \n    84 \n    161 \n  \n  \n    63 \n    124 \n    97 \n    127 \n  \n  \n    79 \n    108 \n    84 \n    152 \n  \n  \n    71 \n    84 \n    57 \n    140 \n  \n  \n    75 \n    30 \n    54 \n    170 \n  \n  \n    65 \n    74 \n    81 \n    116 \n  \n  \n    52 \n    97 \n    58 \n    118 \n  \n  \n    67 \n    72 \n    148 \n    181 \n  \n  \n    67 \n    38 \n    142 \n    135 \n  \n  \n    56 \n    88 \n    144 \n    141 \n  \n  \n    61 \n    123 \n    152 \n    221 \n  \n  \n    71 \n    89 \n    133 \n    167 \n  \n  \n    52 \n    82 \n    107 \n    111 \n  \n  \n    63 \n    106 \n    74 \n    160 \n  \n  \n    72 \n    97 \n    64 \n    135 \n  \n  \n    56 \n    128 \n    165 \n    206 \n  \n  \n    64 \n    68 \n    140 \n    214 \n  \n  \n    62 \n    85 \n    80 \n    99 \n  \n  \n    73 \n    114 \n    111 \n    182 \n  \n  \n    57 \n    144 \n    56 \n    127 \n  \n  \n    53 \n    25 \n    77 \n    128 \n  \n  \n    56 \n    65 \n    144 \n    124 \n  \n  \n    77 \n    80 \n    73 \n    166 \n  \n  \n    63 \n    85 \n    118 \n    164 \n  \n  \n    64 \n    161 \n    95 \n    164 \n  \n  \n    59 \n    65 \n    85 \n    119 \n  \n  \n    71 \n    73 \n    131 \n    126 \n  \n  \n    65 \n    106 \n    128 \n    146 \n  \n  \n    71 \n    73 \n    151 \n    190 \n  \n  \n    99 \n    87 \n    158 \n    238 \n  \n  \n    65 \n    103 \n    72 \n    93 \n  \n  \n    57 \n    94 \n    147 \n    234 \n  \n  \n    56 \n    83 \n    49 \n    162 \n  \n  \n    60 \n    73 \n    117 \n    162 \n  \n  \n    61 \n    100 \n    90 \n    151 \n  \n  \n    54 \n    92 \n    56 \n    66 \n  \n  \n    84 \n    98 \n    111 \n    182 \n  \n  \n    77 \n    126 \n    121 \n    195 \n  \n  \n    53 \n    62 \n    120 \n    141 \n  \n  \n    58 \n    98 \n    95 \n    132 \n  \n  \n    64 \n    82 \n    93 \n    114 \n  \n  \n    55 \n    108 \n    60 \n    109 \n  \n  \n    56 \n    140 \n    114 \n    178 \n  \n  \n    54 \n    90 \n    99 \n    105 \n  \n  \n    65 \n    84 \n    125 \n    160 \n  \n  \n    54 \n    92 \n    138 \n    155 \n  \n  \n    69 \n    133 \n    158 \n    228 \n  \n  \n    55 \n    92 \n    119 \n    152 \n  \n  \n    72 \n    79 \n    124 \n    146 \n  \n  \n    57 \n    88 \n    93 \n    91 \n  \n  \n    59 \n    45 \n    103 \n    122 \n  \n  \n    61 \n    119 \n    95 \n    158 \n  \n  \n    58 \n    120 \n    136 \n    184 \n  \n  \n    57 \n    105 \n    146 \n    210 \n  \n  \n    62 \n    114 \n    131 \n    227 \n  \n  \n    56 \n    86 \n    129 \n    200 \n  \n  \n    78 \n    133 \n    142 \n    209 \n  \n  \n    60 \n    125 \n    127 \n    230 \n  \n  \n    66 \n    77 \n    133 \n    138 \n  \n  \n    52 \n    97 \n    56 \n    132 \n  \n  \n    69 \n    71 \n    140 \n    167 \n  \n  \n    55 \n    73 \n    114 \n    152 \n  \n  \n    57 \n    42 \n    84 \n    124 \n  \n  \n    52 \n    23 \n    174 \n    153 \n  \n  \n    65 \n    87 \n    116 \n    148 \n  \n  \n    79 \n    87 \n    119 \n    138 \n  \n  \n    58 \n    104 \n    156 \n    159 \n  \n  \n    82 \n    97 \n    67 \n    111 \n  \n  \n    58 \n    110 \n    95 \n    123 \n  \n  \n    56 \n    81 \n    133 \n    182 \n  \n  \n    77 \n    103 \n    125 \n    179 \n  \n  \n    54 \n    92 \n    105 \n    139 \n  \n  \n    59 \n    81 \n    67 \n    114 \n  \n  \n    70 \n    134 \n    138 \n    191 \n  \n  \n    60 \n    103 \n    52 \n    94 \n  \n  \n    57 \n    65 \n    109 \n    175 \n  \n  \n    82 \n    40 \n    77 \n    85 \n  \n  \n    64 \n    87 \n    109 \n    162 \n  \n  \n    57 \n    96 \n    116 \n    114 \n  \n  \n    59 \n    89 \n    125 \n    174 \n  \n  \n    54 \n    136 \n    71 \n    167 \n  \n  \n    63 \n    108 \n    143 \n    187 \n  \n  \n    69 \n    93 \n    116 \n    172 \n  \n  \n    61 \n    133 \n    144 \n    279 \n  \n  \n    70 \n    57 \n    55 \n    85 \n  \n  \n    71 \n    84 \n    175 \n    219 \n  \n  \n    59 \n    143 \n    47 \n    81 \n  \n  \n    72 \n    102 \n    82 \n    143 \n  \n  \n    72 \n    128 \n    129 \n    180 \n  \n  \n    52 \n    46 \n    101 \n    147 \n  \n  \n    56 \n    171 \n    143 \n    220 \n  \n  \n    52 \n    130 \n    45 \n    48 \n  \n  \n    62 \n    132 \n    75 \n    109 \n  \n  \n    86 \n    89 \n    102 \n    171 \n  \n  \n    66 \n    141 \n    102 \n    178 \n  \n  \n    84 \n    101 \n    106 \n    110 \n  \n  \n    80 \n    100 \n    58 \n    128 \n  \n  \n    55 \n    103 \n    70 \n    91 \n  \n  \n    60 \n    105 \n    84 \n    151 \n  \n  \n    62 \n    76 \n    106 \n    123 \n  \n  \n    57 \n    71 \n    57 \n    83 \n  \n  \n    62 \n    104 \n    117 \n    212 \n  \n  \n    53 \n    187 \n    75 \n    108 \n  \n  \n    71 \n    95 \n    113 \n    151 \n  \n  \n    76 \n    76 \n    112 \n    193 \n  \n  \n    57 \n    129 \n    100 \n    172 \n  \n  \n    58 \n    82 \n    108 \n    106 \n  \n  \n    65 \n    110 \n    144 \n    164 \n  \n  \n    64 \n    123 \n    85 \n    126 \n  \n  \n    61 \n    60 \n    112 \n    106 \n  \n  \n    52 \n    108 \n    98 \n    174 \n  \n  \n    75 \n    44 \n    108 \n    130 \n  \n  \n    67 \n    123 \n    110 \n    226 \n  \n  \n    52 \n    102 \n    81 \n    156 \n  \n  \n    76 \n    97 \n    138 \n    154 \n  \n  \n    52 \n    65 \n    108 \n    169 \n  \n  \n    68 \n    90 \n    117 \n    135 \n  \n  \n    56 \n    138 \n    141 \n    256 \n  \n  \n    61 \n    76 \n    77 \n    110 \n  \n  \n    88 \n    85 \n    81 \n    123 \n  \n  \n    91 \n    103 \n    110 \n    159 \n  \n  \n    54 \n    78 \n    150 \n    220 \n  \n  \n    63 \n    63 \n    96 \n    89 \n  \n  \n    67 \n    79 \n    86 \n    182 \n  \n  \n    55 \n    96 \n    72 \n    157 \n  \n  \n    65 \n    50 \n    104 \n    129 \n  \n  \n    58 \n    96 \n    125 \n    171 \n  \n  \n    63 \n    89 \n    111 \n    198 \n  \n  \n    62 \n    53 \n    139 \n    163 \n  \n  \n    57 \n    133 \n    41 \n    76 \n  \n  \n    72 \n    97 \n    69 \n    114 \n  \n  \n    65 \n    123 \n    89 \n    207 \n  \n  \n    54 \n    87 \n    147 \n    192 \n  \n  \n    81 \n    64 \n    107 \n    159 \n  \n  \n    59 \n    120 \n    88 \n    149 \n  \n  \n    56 \n    60 \n    123 \n    153 \n  \n  \n    55 \n    63 \n    47 \n    106 \n  \n  \n    56 \n    98 \n    48 \n    115 \n  \n  \n    57 \n    112 \n    94 \n    142 \n  \n  \n    62 \n    146 \n    78 \n    153 \n  \n  \n    61 \n    80 \n    183 \n    189 \n  \n  \n    81 \n    89 \n    125 \n    157 \n  \n  \n    59 \n    116 \n    109 \n    165 \n  \n  \n    72 \n    142 \n    64 \n    96 \n  \n  \n    52 \n    162 \n    140 \n    269 \n  \n  \n    61 \n    100 \n    72 \n    134 \n  \n  \n    71 \n    127 \n    66 \n    85 \n  \n  \n    56 \n    117 \n    152 \n    265 \n  \n  \n    62 \n    97 \n    117 \n    157 \n  \n  \n    56 \n    81 \n    183 \n    194 \n  \n  \n    56 \n    129 \n    98 \n    105 \n  \n  \n    63 \n    69 \n    53 \n    109 \n  \n  \n    81 \n    57 \n    99 \n    120 \n  \n  \n    67 \n    156 \n    154 \n    232 \n  \n  \n    52 \n    85 \n    56 \n    173 \n  \n  \n    56 \n    78 \n    100 \n    124 \n  \n  \n    63 \n    123 \n    85 \n    164 \n  \n  \n    75 \n    177 \n    100 \n    151 \n  \n  \n    69 \n    53 \n    49 \n    130 \n  \n  \n    55 \n    73 \n    70 \n    172 \n  \n  \n    57 \n    95 \n    95 \n    151 \n  \n  \n    54 \n    84 \n    110 \n    125 \n  \n  \n    57 \n    122 \n    98 \n    202 \n  \n  \n    65 \n    106 \n    96 \n    95 \n  \n  \n    75 \n    85 \n    105 \n    113 \n  \n  \n    53 \n    114 \n    112 \n    176 \n  \n  \n    75 \n    49 \n    70 \n    139 \n  \n  \n    66 \n    71 \n    91 \n    135 \n  \n  \n    52 \n    92 \n    142 \n    188 \n  \n  \n    54 \n    48 \n    131 \n    165 \n  \n  \n    57 \n    54 \n    65 \n    86 \n  \n  \n    66 \n    147 \n    94 \n    120 \n  \n  \n    61 \n    68 \n    64 \n    159 \n  \n  \n    60 \n    102 \n    139 \n    114 \n  \n  \n    73 \n    100 \n    74 \n    140 \n  \n  \n    57 \n    48 \n    90 \n    175 \n  \n  \n    53 \n    72 \n    174 \n    202 \n  \n  \n    69 \n    101 \n    112 \n    145 \n  \n  \n    55 \n    97 \n    40 \n    24 \n  \n  \n    71 \n    112 \n    91 \n    150 \n  \n  \n    54 \n    105 \n    165 \n    245 \n  \n  \n    66 \n    60 \n    146 \n    208 \n  \n  \n    74 \n    98 \n    55 \n    155 \n  \n  \n    74 \n    78 \n    93 \n    170 \n  \n  \n    61 \n    60 \n    86 \n    142 \n  \n  \n    59 \n    130 \n    68 \n    124 \n  \n  \n    67 \n    126 \n    164 \n    287 \n  \n  \n    54 \n    133 \n    72 \n    114 \n  \n  \n    70 \n    59 \n    82 \n    137 \n  \n  \n    64 \n    22 \n    111 \n    110 \n  \n  \n    71 \n    91 \n    67 \n    96 \n  \n  \n    63 \n    24 \n    105 \n    152 \n  \n  \n    59 \n    85 \n    132 \n    191 \n  \n  \n    71 \n    118 \n    149 \n    235 \n  \n  \n    53 \n    106 \n    134 \n    140 \n  \n  \n    68 \n    75 \n    88 \n    150 \n  \n  \n    61 \n    100 \n    125 \n    176 \n  \n  \n    96 \n    124 \n    115 \n    182 \n  \n  \n    73 \n    110 \n    164 \n    247 \n  \n  \n    69 \n    74 \n    115 \n    144 \n  \n  \n    64 \n    69 \n    58 \n    102 \n  \n  \n    64 \n    116 \n    113 \n    116 \n  \n  \n    55 \n    131 \n    96 \n    146 \n  \n  \n    62 \n    100 \n    83 \n    137 \n  \n  \n    57 \n    53 \n    101 \n    147 \n  \n  \n    72 \n    73 \n    103 \n    133 \n  \n  \n    58 \n    123 \n    101 \n    174 \n  \n  \n    68 \n    83 \n    44 \n    108 \n  \n  \n    53 \n    110 \n    59 \n    65 \n  \n  \n    61 \n    68 \n    103 \n    149 \n  \n  \n    58 \n    152 \n    104 \n    199 \n  \n  \n    79 \n    70 \n    100 \n    144 \n  \n  \n    58 \n    56 \n    102 \n    146 \n  \n  \n    60 \n    78 \n    122 \n    137 \n  \n  \n    72 \n    106 \n    91 \n    134 \n  \n  \n    63 \n    85 \n    109 \n    170 \n  \n  \n    69 \n    33 \n    74 \n    147 \n  \n  \n    58 \n    84 \n    166 \n    186 \n  \n  \n    84 \n    86 \n    97 \n    171 \n  \n  \n    58 \n    70 \n    85 \n    114 \n  \n  \n    55 \n    53 \n    106 \n    136 \n  \n  \n    58 \n    83 \n    156 \n    155 \n  \n  \n    83 \n    109 \n    146 \n    172 \n  \n  \n    54 \n    51 \n    102 \n    117 \n  \n  \n    54 \n    139 \n    74 \n    110 \n  \n  \n    69 \n    143 \n    84 \n    178 \n  \n  \n    59 \n    109 \n    137 \n    184 \n  \n  \n    66 \n    72 \n    138 \n    140 \n  \n  \n    53 \n    52 \n    130 \n    146 \n  \n  \n    65 \n    108 \n    144 \n    224 \n  \n  \n    72 \n    76 \n    92 \n    151 \n  \n  \n    53 \n    73 \n    119 \n    132 \n  \n  \n    80 \n    97 \n    101 \n    73 \n  \n  \n    70 \n    139 \n    90 \n    141 \n  \n  \n    55 \n    114 \n    94 \n    140 \n  \n  \n    59 \n    58 \n    113 \n    154 \n  \n  \n    54 \n    74 \n    51 \n    103 \n  \n  \n    73 \n    119 \n    119 \n    224 \n  \n  \n    52 \n    85 \n    80 \n    113 \n  \n  \n    61 \n    47 \n    158 \n    137 \n  \n  \n    56 \n    70 \n    61 \n    127 \n  \n  \n    70 \n    79 \n    108 \n    106 \n  \n  \n    66 \n    97 \n    115 \n    145 \n  \n  \n    70 \n    130 \n    120 \n    186 \n  \n  \n    71 \n    93 \n    118 \n    111 \n  \n  \n    58 \n    100 \n    55 \n    117 \n  \n  \n    54 \n    16 \n    95 \n    138 \n  \n  \n    64 \n    123 \n    90 \n    198 \n  \n  \n    67 \n    79 \n    68 \n    134 \n  \n  \n    52 \n    124 \n    104 \n    193 \n  \n  \n    58 \n    46 \n    74 \n    121 \n  \n  \n    59 \n    74 \n    62 \n    162 \n  \n  \n    58 \n    113 \n    40 \n    89 \n  \n  \n    79 \n    94 \n    51 \n    166 \n  \n  \n    57 \n    125 \n    101 \n    156 \n  \n  \n    99 \n    76 \n    105 \n    110 \n  \n  \n    59 \n    110 \n    137 \n    218 \n  \n  \n    54 \n    76 \n    177 \n    205 \n  \n  \n    61 \n    132 \n    60 \n    140 \n  \n  \n    63 \n    146 \n    123 \n    186 \n  \n  \n    53 \n    125 \n    45 \n    96 \n  \n  \n    53 \n    124 \n    69 \n    110 \n  \n  \n    58 \n    137 \n    137 \n    211 \n  \n  \n    69 \n    68 \n    127 \n    184 \n  \n  \n    74 \n    104 \n    60 \n    104 \n  \n  \n    58 \n    69 \n    55 \n    131 \n  \n  \n    75 \n    124 \n    152 \n    208 \n  \n  \n    52 \n    55 \n    145 \n    149 \n  \n  \n    52 \n    71 \n    79 \n    106 \n  \n  \n    53 \n    124 \n    110 \n    150 \n  \n  \n    61 \n    100 \n    131 \n    170 \n  \n  \n    62 \n    84 \n    91 \n    116 \n  \n  \n    75 \n    121 \n    138 \n    171 \n  \n  \n    52 \n    62 \n    130 \n    130 \n  \n  \n    55 \n    97 \n    116 \n    101 \n  \n  \n    57 \n    110 \n    103 \n    149 \n  \n  \n    61 \n    100 \n    111 \n    187 \n  \n  \n    71 \n    57 \n    85 \n    111 \n  \n  \n    54 \n    78 \n    74 \n    99 \n  \n  \n    61 \n    75 \n    123 \n    145 \n  \n  \n    58 \n    90 \n    173 \n    243 \n  \n  \n    60 \n    117 \n    75 \n    120 \n  \n  \n    63 \n    102 \n    138 \n    198 \n  \n  \n    59 \n    46 \n    98 \n    139 \n  \n  \n    60 \n    96 \n    115 \n    114 \n  \n  \n    53 \n    89 \n    94 \n    108 \n  \n  \n    57 \n    144 \n    79 \n    163 \n  \n  \n    56 \n    57 \n    84 \n    186 \n  \n  \n    65 \n    87 \n    78 \n    134 \n  \n  \n    75 \n    69 \n    116 \n    141 \n  \n  \n    90 \n    97 \n    52 \n    122 \n  \n  \n    60 \n    112 \n    164 \n    243 \n  \n  \n    71 \n    83 \n    89 \n    162 \n  \n  \n    57 \n    121 \n    72 \n    124 \n  \n  \n    58 \n    139 \n    53 \n    86 \n  \n  \n    66 \n    118 \n    139 \n    174 \n  \n  \n    53 \n    81 \n    133 \n    151 \n  \n  \n    64 \n    42 \n    124 \n    111 \n  \n  \n    59 \n    110 \n    139 \n    179 \n  \n  \n    62 \n    132 \n    136 \n    242 \n  \n  \n    70 \n    60 \n    166 \n    165 \n  \n  \n    56 \n    124 \n    108 \n    148 \n  \n  \n    69 \n    87 \n    144 \n    182 \n  \n  \n    56 \n    105 \n    151 \n    164 \n  \n  \n    68 \n    42 \n    89 \n    128 \n  \n  \n    68 \n    97 \n    76 \n    111 \n  \n  \n    66 \n    81 \n    37 \n    119 \n  \n  \n    68 \n    116 \n    104 \n    131 \n  \n  \n    56 \n    77 \n    73 \n    89 \n  \n  \n    74 \n    100 \n    81 \n    126 \n  \n  \n    68 \n    96 \n    84 \n    108 \n  \n  \n    68 \n    149 \n    152 \n    190 \n  \n  \n    64 \n    6 \n    108 \n    67 \n  \n  \n    72 \n    125 \n    88 \n    155 \n  \n  \n    56 \n    48 \n    69 \n    119 \n  \n  \n    70 \n    92 \n    141 \n    203 \n  \n  \n    57 \n    65 \n    103 \n    151 \n  \n  \n    62 \n    92 \n    120 \n    169 \n  \n  \n    62 \n    64 \n    88 \n    129 \n  \n  \n    55 \n    64 \n    139 \n    94 \n  \n  \n    61 \n    59 \n    89 \n    142 \n  \n  \n    67 \n    110 \n    41 \n    98 \n  \n  \n    54 \n    83 \n    67 \n    69 \n  \n  \n    64 \n    46 \n    124 \n    162 \n  \n  \n    61 \n    75 \n    113 \n    159 \n  \n  \n    52 \n    79 \n    107 \n    118 \n  \n  \n    66 \n    137 \n    164 \n    257 \n  \n  \n    57 \n    86 \n    91 \n    128 \n  \n  \n    60 \n    41 \n    120 \n    128 \n  \n  \n    68 \n    137 \n    119 \n    175 \n  \n  \n    58 \n    70 \n    159 \n    159 \n  \n  \n    58 \n    84 \n    95 \n    142 \n  \n  \n    72 \n    124 \n    89 \n    136 \n  \n  \n    66 \n    93 \n    136 \n    178 \n  \n  \n    53 \n    59 \n    62 \n    87 \n  \n  \n    70 \n    65 \n    71 \n    101 \n  \n  \n    59 \n    47 \n    82 \n    141 \n  \n  \n    54 \n    99 \n    89 \n    125 \n  \n  \n    52 \n    80 \n    165 \n    136 \n  \n  \n    58 \n    115 \n    112 \n    147 \n  \n  \n    80 \n    89 \n    51 \n    85 \n  \n  \n    62 \n    103 \n    139 \n    220 \n  \n  \n    52 \n    75 \n    37 \n    56 \n  \n  \n    63 \n    80 \n    171 \n    176 \n  \n  \n    66 \n    45 \n    130 \n    139 \n  \n  \n    58 \n    94 \n    39 \n    50 \n  \n  \n    53 \n    50 \n    96 \n    169 \n  \n  \n    56 \n    90 \n    79 \n    81 \n  \n  \n    70 \n    102 \n    119 \n    150 \n  \n  \n    53 \n    21 \n    93 \n    130 \n  \n  \n    64 \n    60 \n    97 \n    111 \n  \n  \n    67 \n    129 \n    114 \n    183 \n  \n  \n    72 \n    46 \n    99 \n    178 \n  \n  \n    67 \n    96 \n    37 \n    86 \n  \n  \n    54 \n    89 \n    151 \n    172 \n  \n  \n    56 \n    64 \n    137 \n    125 \n  \n  \n    57 \n    81 \n    87 \n    98 \n  \n  \n    59 \n    134 \n    107 \n    169 \n  \n  \n    75 \n    33 \n    110 \n    118 \n  \n  \n    55 \n    108 \n    95 \n    181 \n  \n  \n    62 \n    94 \n    62 \n    150 \n  \n  \n    71 \n    81 \n    137 \n    213 \n  \n  \n    78 \n    89 \n    45 \n    28 \n  \n  \n    84 \n    136 \n    115 \n    199 \n  \n  \n    55 \n    58 \n    44 \n    92 \n  \n  \n    64 \n    115 \n    61 \n    97 \n  \n  \n    54 \n    80 \n    74 \n    136 \n  \n  \n    66 \n    81 \n    125 \n    99 \n  \n  \n    56 \n    44 \n    105 \n    110 \n  \n  \n    66 \n    188 \n    119 \n    260 \n  \n  \n    64 \n    139 \n    92 \n    165 \n  \n  \n    78 \n    68 \n    166 \n    176 \n  \n  \n    80 \n    97 \n    121 \n    148 \n  \n  \n    58 \n    135 \n    125 \n    172 \n  \n\n\n\n\n\n\nWrite code to find the mean of the Yr1 test scores for all those who achieved Yr3 test scores greater than 100. Round this mean to the nearest integer.\n\n\nround(mean(ugtests$Yr1[ugtests$Yr3 > 100]), 0)\n\n[1] 52\n\n# with pipes\nugtests %>% filter(Yr3 > 100) %>% summarise(`Mean of Yr1` = round(mean(Yr1), 0))\n\n  Mean of Yr1\n1          52\n\n\n\nFamiliarize yourself with the two functions filter() and pull() from dplyr. Use these functions to try to do the same calculation in the previous question using a single unbroken piped command. Be sure to namespace where necessary.\n\n\nugtests %>% filter(Yr3 > 100) %>% pull(Yr1) %>% mean() %>% round()\n\n[1] 52\n\n\n\nCreate a scatter plot using the ugtests data with Final scores on the y-axis and Yr3 scores on the x axis.\n\n\n# plot(y=ugtests$Final, x=ugtests$Yr3, xlab=\"Yr3\", ylab=\"Final\")\nlibrary(ggplot2)\nggplot(ugtests) + aes(x=Yr3, y=Final) + geom_point()\n\n\n\n\n\nCreate your own 5-level grading logic and use it to create a new finalgrade column in the ugtests data set with grades 1–5 of increasing attainment based on the Final score in ugtests. Generate a histogram of this finalgrade column.\n\n\nugtests$finalgrade <- as.numeric(cut(ugtests$Final, 5))\nhist(ugtests$finalgrade)\n\n\n\n\n\nUsing your new ugtests data with the extra column from the previous exercise, create a box plot of Yr3 scores grouped by finalgrade.\n\n\nboxplot(Yr3~finalgrade, data=ugtests)\n\n\n\n\n\nKnit all of your answers to these exercises into an R Markdown document. Create one version that displays your code and answers, and another that just displays the answers.\n\nI am going to cheat a bit. I did it in quarto and it is one option to code-fold; so that both versions contain code, one hidden and one not with the option for the user to determine what they wish to see.\nOne additional thing, base R graphics are kinda ugly. We can use R’s esquisse package to turn them to ggplots.\n\nlibrary(ggplot2)\nugtests %>% \n  ggplot(.) + \n  aes(x=finalgrade) + \n  geom_histogram() +\n  labs(x=\"Final Grade\") +\n  theme_minimal()\n\n\n\n\n\nugtests %>% \n  ggplot(.) + \n  aes(y=Yr3, x=as.character(finalgrade), color=as.character(finalgrade)) + \n  geom_boxplot() +\n  labs(x=\"Final Grade\", y=\"Year 3\") +\n  theme_minimal() +\n  guides(color=\"none\")"
  },
  {
    "objectID": "posts/chapter-3/index.html",
    "href": "posts/chapter-3/index.html",
    "title": "Chapter 3: HRMPA",
    "section": "",
    "text": "For these exercises, load the charity_donation data set via the peopleanalyticsdata package, or download it from the internet. This data set contains information on a sample of individuals who made donations to a nature charity.\n\nlibrary(tidyverse); library(magrittr)\ncharity_data <- read.csv(\"http://peopleanalytics-regression-book.org/data/charity_donation.csv\")\n\n\nCalculate the mean total_donations from the data set.\n\n\nmean(charity_data$total_donations)\n\n[1] 2350.141\n\ncharity_data$total_donations %>% mean\n\n[1] 2350.141\n\n\nThe mean of total_donations is 2350.14.\n\nCalculate the sample variance for total_donations and convert this to a population variance.\n\n\n# Sample variance\nvar(charity_data$total_donations)\n\n[1] 6232905\n\n# Population variance\n((length(charity_data$total_donations)-1)/length(charity_data$total_donations))*var(charity_data$total_donations)\n\n[1] 6215297\n\n\nThe sample variance for total_donations is 6232904.5125718 while the population variance is slightly smaller: 6215297.4376776.\n\nCalculate the sample standard deviation for total_donations and verify that it is the same as the square root of the sample variance.\n\n\nsd(charity_data$total_donations)\n\n[1] 2496.579\n\nsd(charity_data$total_donations)==sqrt(var(charity_data$total_donations))\n\n[1] TRUE\n\n\n\nCalculate the sample correlation between total_donations and time_donating. By using an appropriate hypothesis test, determine if these two variables are independent in the overall population.\n\n\ncor.test(charity_data$total_donations, charity_data$time_donating)\n\n\n    Pearson's product-moment correlation\n\ndata:  charity_data$total_donations and charity_data$time_donating\nt = 14.69, df = 352, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5474266 0.6772030\nsample estimates:\n      cor \n0.6164845 \n\ncharity_data %$% cor.test(total_donations, time_donating)\n\n\n    Pearson's product-moment correlation\n\ndata:  total_donations and time_donating\nt = 14.69, df = 352, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5474266 0.6772030\nsample estimates:\n      cor \n0.6164845 \n\n\nThese two variables are quite unlikely to be independent in the population. The correlation is 0.616 and, with 95% confidence, ranges from 0.55 to 0.68. There is basically zero probability of finding a correlation that high by chance alone.\n\nCalculate the mean and the standard error of the mean for the first 20 entries of total_donations.\n\n\nmean(charity_data$total_donations[1:20])\n\n[1] 1851\n\nsd(charity_data$total_donations[1:20])/sqrt(length(charity_data$total_donations[1:20]))\n\n[1] 315.0922\n\n\n\nCalculate the mean and the standard error of the mean for the first 50 entries of total_donations. Verify that the standard error is less than in Exercise 5.\n\n\nmean(charity_data$total_donations[1:50])\n\n[1] 2026.4\n\nsd(charity_data$total_donations[1:50])/sqrt(length(charity_data$total_donations[1:50]))\n\n[1] 240.7464\n\n\nThe standard error of the first 50 is 240.7 while the standard error of the first 20 is 315.1. Verified.\n\nBy using an appropriate hypothesis test, determine if the mean age of those who made a recent donation is different from those who did not.\n\n\nt.test(age~recent_donation, data=charity_data)\n\n\n    Welch Two Sample t-test\n\ndata:  age by recent_donation\nt = -10.207, df = 105.15, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -24.47608 -16.51365\nsample estimates:\nmean in group 0 mean in group 1 \n       42.19188        62.68675 \n\ncharity_data %>% t.test(age~recent_donation, data=.)\n\n\n    Welch Two Sample t-test\n\ndata:  age by recent_donation\nt = -10.207, df = 105.15, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -24.47608 -16.51365\nsample estimates:\nmean in group 0 mean in group 1 \n       42.19188        62.68675 \n\n\nThe age of recent donors is between 16.5 and 24.5 years higher than those of non-recent donors with 95% confidence. The probability that such a large difference would be observed by random chance if there was no difference is basically zero.\n\nBy using an appropriate hypothesis test, determine if there is a difference in whether or not a recent donation was made according to where people reside.\n\n\nchisq.test(charity_data$recent_donation, charity_data$reside)\n\n\n    Pearson's Chi-squared test\n\ndata:  charity_data$recent_donation and charity_data$reside\nX-squared = 16.176, df = 2, p-value = 0.0003072\n\n\nBoth variables are categorical, this a chi-square test of independence is indicated. The evidence suggests that likelihood of recent donations depends on where an individual resides.\nFor a bit of detail, I will deploy janitor::tabyl\n\nlibrary(janitor)\ncharity_data %>% tabyl(reside, recent_donation) %>% adorn_percentages(\"row\")\n\n         reside         0         1\n       Overseas 0.8782609 0.1217391\n Rural Domestic 0.6616541 0.3383459\n Urban Domestic 0.7735849 0.2264151\n\n\n\nExtension: By using an appropriate hypothesis test, determine if the age of those who have recently donated is at least 10 years older than those who have not recently donated in the population.\n\nYes. This is fairly clear from the evidence in question 7. Though more formally, as an hypothesis test, we should use evidence only in one tail. It is worth noting that the first group [0] is smaller, so we really mean a difference less than -10 and the evidence suggests that this is true as it is very unlikely to have occurred by chance alone.\n\ncharity_data %>% t.test(age~recent_donation, data=., alt=\"l\", mu=-10)\n\n\n    Welch Two Sample t-test\n\ndata:  age by recent_donation\nt = -5.2268, df = 105.15, p-value = 0.0000004403\nalternative hypothesis: true difference in means between group 0 and group 1 is less than -10\n95 percent confidence interval:\n      -Inf -17.16282\nsample estimates:\nmean in group 0 mean in group 1 \n       42.19188        62.68675 \n\n\n\nExtension: By using an appropriate hypothesis test, determine if the average donation amount is at least 10 dollars higher for those who recently donated versus those who did not. Retest for 20 dollars higher.\n\n\ncharity_data %>% mutate(avg_donation = total_donations/n_donations) %>% t.test(avg_donation~recent_donation, data=., mu=-10, alt=\"l\")\n\n\n    Welch Two Sample t-test\n\ndata:  avg_donation by recent_donation\nt = -2.5035, df = 179.45, p-value = 0.006595\nalternative hypothesis: true difference in means between group 0 and group 1 is less than -10\n95 percent confidence interval:\n     -Inf -19.2951\nsample estimates:\nmean in group 0 mean in group 1 \n       356.2168        393.5902 \n\ncharity_data %>% mutate(avg_donation = total_donations/n_donations) %>% t.test(avg_donation~recent_donation, data=., mu=-20, alt=\"l\")\n\n\n    Welch Two Sample t-test\n\ndata:  avg_donation by recent_donation\nt = -1.5889, df = 179.45, p-value = 0.05692\nalternative hypothesis: true difference in means between group 0 and group 1 is less than -20\n95 percent confidence interval:\n     -Inf -19.2951\nsample estimates:\nmean in group 0 mean in group 1 \n       356.2168        393.5902 \n\n\nIt is at least 10 dollars higher with 95% confidence but it is not quite at least 20 dollars higher with 95% confidence. In the former case, the probability of such a large difference by random chance is 0.007 while in the latter case, it is 0.06."
  },
  {
    "objectID": "posts/chapter-5/index.html",
    "href": "posts/chapter-5/index.html",
    "title": "Chapter 5",
    "section": "",
    "text": "Load the sociological_data data set via the peopleanalyticsdata package or download it from the internet. This data represents a sample of information obtained from individuals who participated in a global research study and contains the following fields:\n\nlibrary(tidyverse); library(magrittr); library(skimr)\nsoc_data <- read.csv(\"http://peopleanalytics-regression-book.org/data/sociological_data.csv\")\n\n\nannual_income_ppp: The annual income of the individual in PPP adjusted US dollars\naverage_wk_hrs: The average number of hours per week worked by the individual\neducation_months: The total number of months spent by the individual in formal primary, secondary and tertiary education\nregion: The region of the world where the individual lives\njob_type: Whether the individual works in a skilled or unskilled profession\ngender: The gender of the individual\nfamily_size: The size of the individual’s family of dependents\nwork_distance: The distance between the individual’s residence and workplace in kilometers\nlanguages: The number of languages spoken fluently by the individual\n\nConduct some exploratory data analysis on this data set. Including:\n\nIdentify the extent to which missing data is an issue.\n\n\nsummary(soc_data)\n\n annual_income_ppp average_wk_hrs  education_months    region         \n Min.   :  2863    Min.   :30.00   Min.   : 40.0    Length:2618       \n 1st Qu.: 62653    1st Qu.:39.00   1st Qu.:157.0    Class :character  \n Median : 82140    Median :43.00   Median :184.0    Mode  :character  \n Mean   : 76040    Mean   :44.19   Mean   :179.3                      \n 3rd Qu.: 90112    3rd Qu.:50.00   3rd Qu.:207.0                      \n Max.   :119564    Max.   :55.00   Max.   :280.0                      \n NA's   :10        NA's   :34      NA's   :19                         \n   job_type            gender           family_size    work_distance    \n Length:2618        Length:2618        Min.   : 0.00   Min.   :  0.000  \n Class :character   Class :character   1st Qu.: 2.00   1st Qu.:  0.000  \n Mode  :character   Mode  :character   Median : 3.00   Median :  0.000  \n                                       Mean   : 3.26   Mean   :  0.985  \n                                       3rd Qu.: 4.00   3rd Qu.:  1.000  \n                                       Max.   :10.00   Max.   :105.000  \n                                       NA's   :191     NA's   :412      \n   languages    \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :1.000  \n Mean   :1.018  \n 3rd Qu.:1.000  \n Max.   :5.000  \n NA's   :412    \n\n\nThe answer very much depends on the variable under examination. languages and work_distance are missing 15.737204% of the data. That is quite a bit. The good news, such that it is, is that it is the same 412 observations that are missing both. How much an issue is it? One way to examine this would be to estimate the model with those data and without. There are also 119 observations without family_size, of those 41 are missing. This means that 490 are missing via patterns in these three variables; that’s 0.1871658\n\nsoc_data %>% janitor::tabyl(languages, work_distance)\n\n languages    0   1 10 105 11 12 13 14 15 16 18 19  2 20 21  3  4  5  6  7 8 9\n         1 1582 343  8   0  5  3  2  0  0  0  0  0 92  0  0 58 38 20 12 11 5 1\n         2    0   0  0   0  0  0  0  5  6  3  1  2  0  2  2  0  0  0  0  0 0 0\n         4    0   0  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n         5    0   0  0   1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n        NA    0   0  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0\n 91 93 94 96 NA_\n  0  0  0  0   0\n  0  0  0  0   0\n  1  0  0  0   0\n  0  1  1  1   0\n  0  0  0  0 412\n\nsoc_data %>% dplyr::filter(is.na(languages) & is.na(work_distance)) %>% skim(family_size)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n412\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfamily_size\n41\n0.9\n2.79\n1.54\n0\n2\n3\n3\n10\n▇▇▁▁▁\n\n\n\n\n\n\nlibrary(naniar)\nnaniar::gg_miss_var(soc_data)\n\n\n\n\n\nDetermine if the data types are appropriate for analysis.\n\nTo be honest, I am not entirely sure what this means. Yes, we can analyse them in the current form.\n\nUsing a correlation matrix, pairplot or alternative method, identify whether collinearity is present in the data.\n\nregion is categorical with too many categories so it has to be dropped from plots. work_distance and languages are very highly correlated.\n\nsoc_data %>% dplyr::select(-region) %>% GGally::ggpairs()\n\n\n\n\n\nIdentify and discuss anything else interesting that you see in the data.\n\nwork_distance is messy and highly correlated with languages.\nPrepare to build a linear regression model to explain the variation in annual_income_ppp using the other data in the data set.\n\nAre there any fields which you believe should not be included in the model? If so, why?\n\nI think there are principled reasons to ignore work_distance and languages as they have so much missing data. Not exactly sure why family_size would be relevant but that can be included and excluded.\n\nWould you consider imputing missing data for some or all fields where it is an issue? If so, what might be some simple ways to impute the missing data?\n\nI would not but largely because I am not sure what would necessarily predict work distance, languages, and family size. Were I to impute it, I prefer multiple imputation to represent the full data correlation structure in the imputation process.\n\nWhich variables are categorical? Convert these variables to dummy variables using a convenient function or using your own approach.\n\nThe fastDummies package is amazing for this.\n\nsummary(soc_data)\n\n annual_income_ppp average_wk_hrs  education_months    region         \n Min.   :  2863    Min.   :30.00   Min.   : 40.0    Length:2618       \n 1st Qu.: 62653    1st Qu.:39.00   1st Qu.:157.0    Class :character  \n Median : 82140    Median :43.00   Median :184.0    Mode  :character  \n Mean   : 76040    Mean   :44.19   Mean   :179.3                      \n 3rd Qu.: 90112    3rd Qu.:50.00   3rd Qu.:207.0                      \n Max.   :119564    Max.   :55.00   Max.   :280.0                      \n NA's   :10        NA's   :34      NA's   :19                         \n   job_type            gender           family_size    work_distance    \n Length:2618        Length:2618        Min.   : 0.00   Min.   :  0.000  \n Class :character   Class :character   1st Qu.: 2.00   1st Qu.:  0.000  \n Mode  :character   Mode  :character   Median : 3.00   Median :  0.000  \n                                       Mean   : 3.26   Mean   :  0.985  \n                                       3rd Qu.: 4.00   3rd Qu.:  1.000  \n                                       Max.   :10.00   Max.   :105.000  \n                                       NA's   :191     NA's   :412      \n   languages    \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :1.000  \n Mean   :1.018  \n 3rd Qu.:1.000  \n Max.   :5.000  \n NA's   :412    \n\n\nregion, job_type, and gender need such treatment.\n\nlibrary(fastDummies)\nsoc_data.dum <- soc_data %>% fastDummies::dummy_columns(., select_columns = c(\"region\",\"job_type\",\"gender\"))\n\nRun and interpret the model. For convenience, and to avoid long formula strings, you can use the formula notation annual_income_ppp ~ . which means ‘regress annual_income against everything else’. You can also remove fields this way, for example annual_income_ppp ~ . - family_size.\n\nMod1 <- soc_data %>% dplyr::select(-c(work_distance, languages, family_size)) %>% lm(annual_income_ppp ~ ., data=.)\nsummary(Mod1)\n\n\nCall:\nlm(formula = annual_income_ppp ~ ., data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-66558  -5076     32   4886  34054 \n\nCoefficients:\n                                        Estimate Std. Error t value   Pr(>|t|)\n(Intercept)                            61013.833   3547.587  17.199    < 2e-16\naverage_wk_hrs                           -94.381     49.614  -1.902   0.057245\neducation_months                         135.854      8.919  15.232    < 2e-16\nregionCentral Asia                     -9950.611   2219.350  -4.484 0.00000767\nregionEastern Asia                       -11.119   2306.359  -0.005   0.996154\nregionEastern Europe                   -8868.991   1957.127  -4.532 0.00000612\nregionLatin America and the Caribbean   1520.957   1974.732   0.770   0.441247\nregionMelanesia                        -4341.571   2290.646  -1.895   0.058160\nregionMicronesia                       -9862.966   2590.009  -3.808   0.000143\nregionNorthern Africa                   -571.361   2198.879  -0.260   0.795007\nregionNorthern America                 14003.282   2999.688   4.668 0.00000320\nregionNorthern Europe                   -295.495   1863.336  -0.159   0.874010\nregionPolynesia                        -1463.552   2539.825  -0.576   0.564503\nregionSouth-eastern Asia               -2932.501   2106.504  -1.392   0.164009\nregionSouthern Asia                    -3410.363   2195.464  -1.553   0.120460\nregionSouthern Europe                   4555.134   1903.801   2.393   0.016799\nregionSub-Saharan Africa              -20719.828   2066.605 -10.026    < 2e-16\nregionWestern Asia                      2658.151   1995.651   1.332   0.182989\nregionWestern Europe                    6625.710   1922.203   3.447   0.000576\njob_typeUnskilled                      -8074.631    803.987 -10.043    < 2e-16\ngenderM                                 9715.197    665.656  14.595    < 2e-16\n                                         \n(Intercept)                           ***\naverage_wk_hrs                        .  \neducation_months                      ***\nregionCentral Asia                    ***\nregionEastern Asia                       \nregionEastern Europe                  ***\nregionLatin America and the Caribbean    \nregionMelanesia                       .  \nregionMicronesia                      ***\nregionNorthern Africa                    \nregionNorthern America                ***\nregionNorthern Europe                    \nregionPolynesia                          \nregionSouth-eastern Asia                 \nregionSouthern Asia                      \nregionSouthern Europe                 *  \nregionSub-Saharan Africa              ***\nregionWestern Asia                       \nregionWestern Europe                  ***\njob_typeUnskilled                     ***\ngenderM                               ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9407 on 2539 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.7962,    Adjusted R-squared:  0.7946 \nF-statistic: 495.8 on 20 and 2539 DF,  p-value: < 2.2e-16\n\n\n\nDetermine what variables are significant predictors of annual income and what is the effect of each on the outcome.\n\n\nsoc_data %>% dplyr::select(-c(work_distance, languages, family_size)) %>% lm(annual_income_ppp ~ ., data=.) %>% summary %$% coefficients %>% data.frame %>% filter(`Pr...t..` < 0.05)\n\n                            Estimate  Std..Error    t.value     Pr...t..\n(Intercept)               61013.8327 3547.587273  17.198684 8.550317e-63\neducation_months            135.8542    8.918884  15.232193 3.346444e-50\nregionCentral Asia        -9950.6108 2219.350223  -4.483569 7.666478e-06\nregionEastern Europe      -8868.9906 1957.126882  -4.531638 6.123784e-06\nregionMicronesia          -9862.9659 2590.008578  -3.808082 1.433663e-04\nregionNorthern America    14003.2817 2999.687867   4.668246 3.195797e-06\nregionSouthern Europe      4555.1337 1903.800748   2.392653 1.679935e-02\nregionSub-Saharan Africa -20719.8283 2066.605062 -10.026022 3.148593e-23\nregionWestern Europe       6625.7095 1922.203143   3.446935 5.762064e-04\njob_typeUnskilled         -8074.6311  803.987070 -10.043235 2.662334e-23\ngenderM                    9715.1966  665.656089  14.594919 2.169990e-46\n\n\nMonths of education, region, job type, and gender are predictors of annual income. Each month of education begets about 136 dollars, unskilled labor is lower by 8075 dollars than skilled labor, and Males have annual incomes about 9715 dollars higher. A number of regions have higher and lower average annual incomes, also.\n\nDetermine the overall fit of the model.\n\nThe model accounts for almost 80 percent of the variation in annual incomes and the model \\(F\\) statistic is enormous.\n\nDo some simple analysis on the residuals of the model to determine if the model is safe to interpret.\n\n\ngvlma::gvlma(Mod1)\n\n\nCall:\nlm(formula = annual_income_ppp ~ ., data = .)\n\nCoefficients:\n                          (Intercept)                         average_wk_hrs  \n                             61013.83                                 -94.38  \n                     education_months                     regionCentral Asia  \n                               135.85                               -9950.61  \n                   regionEastern Asia                   regionEastern Europe  \n                               -11.12                               -8868.99  \nregionLatin America and the Caribbean                        regionMelanesia  \n                              1520.96                               -4341.57  \n                     regionMicronesia                  regionNorthern Africa  \n                             -9862.97                                -571.36  \n               regionNorthern America                  regionNorthern Europe  \n                             14003.28                                -295.49  \n                      regionPolynesia               regionSouth-eastern Asia  \n                             -1463.55                               -2932.50  \n                  regionSouthern Asia                  regionSouthern Europe  \n                             -3410.36                                4555.13  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                            -20719.83                                2658.15  \n                 regionWestern Europe                      job_typeUnskilled  \n                              6625.71                               -8074.63  \n                              genderM  \n                              9715.20  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod1) \n\n                      Value    p-value                   Decision\nGlobal Stat        517.2979 0.00000000 Assumptions NOT satisfied!\nSkewness             3.9341 0.04731624 Assumptions NOT satisfied!\nKurtosis           497.9156 0.00000000 Assumptions NOT satisfied!\nLink Function       15.1844 0.00009751 Assumptions NOT satisfied!\nHeteroscedasticity   0.2639 0.60748142    Assumptions acceptable.\n\n\nProbably not. The middle 50 percent of residuals are reasonably well balanced but they have a very long left tail in addition to failing the diagnostics above.\n\nExperiment with improving the model fit through possible interaction terms or non-linear extensions.\n\n\nMod2 <- soc_data %>% mutate(ln_income = log(annual_income_ppp)) %>% dplyr::select(-c(work_distance, languages, family_size,annual_income_ppp))  %>% lm(ln_income ~ ., data=.)\nsummary(Mod2)\n\n\nCall:\nlm(formula = ln_income ~ ., data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.11453 -0.06136  0.00394  0.07564  0.59898 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(>|t|)\n(Intercept)                           10.9156109  0.0706493 154.504  < 2e-16\naverage_wk_hrs                        -0.0009693  0.0009881  -0.981  0.32669\neducation_months                       0.0017640  0.0001776   9.932  < 2e-16\nregionCentral Asia                    -0.0984659  0.0441978  -2.228  0.02598\nregionEastern Asia                     0.0088410  0.0459306   0.192  0.84738\nregionEastern Europe                  -0.0797522  0.0389757  -2.046  0.04084\nregionLatin America and the Caribbean  0.0379392  0.0393263   0.965  0.33477\nregionMelanesia                       -0.0067090  0.0456176  -0.147  0.88309\nregionMicronesia                      -0.0895268  0.0515794  -1.736  0.08274\nregionNorthern Africa                  0.0145632  0.0437901   0.333  0.73949\nregionNorthern America                 0.1609234  0.0597380   2.694  0.00711\nregionNorthern Europe                  0.0063751  0.0371079   0.172  0.86361\nregionPolynesia                        0.0045840  0.0505800   0.091  0.92779\nregionSouth-eastern Asia              -0.0141714  0.0419505  -0.338  0.73553\nregionSouthern Asia                   -0.0089686  0.0437221  -0.205  0.83749\nregionSouthern Europe                  0.0698175  0.0379137   1.841  0.06567\nregionSub-Saharan Africa              -0.3306967  0.0411559  -8.035 1.42e-15\nregionWestern Asia                     0.0571853  0.0397429   1.439  0.15031\nregionWestern Europe                   0.0833153  0.0382802   2.176  0.02961\njob_typeUnskilled                     -0.0846780  0.0160112  -5.289 1.34e-07\ngenderM                                0.1962831  0.0132564  14.807  < 2e-16\n                                         \n(Intercept)                           ***\naverage_wk_hrs                           \neducation_months                      ***\nregionCentral Asia                    *  \nregionEastern Asia                       \nregionEastern Europe                  *  \nregionLatin America and the Caribbean    \nregionMelanesia                          \nregionMicronesia                      .  \nregionNorthern Africa                    \nregionNorthern America                ** \nregionNorthern Europe                    \nregionPolynesia                          \nregionSouth-eastern Asia                 \nregionSouthern Asia                      \nregionSouthern Europe                 .  \nregionSub-Saharan Africa              ***\nregionWestern Asia                       \nregionWestern Europe                  *  \njob_typeUnskilled                     ***\ngenderM                               ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1873 on 2539 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.7041,    Adjusted R-squared:  0.7018 \nF-statistic: 302.1 on 20 and 2539 DF,  p-value: < 2.2e-16\n\ngvlma::gvlma(Mod2)\n\n\nCall:\nlm(formula = ln_income ~ ., data = .)\n\nCoefficients:\n                          (Intercept)                         average_wk_hrs  \n                           10.9156109                             -0.0009693  \n                     education_months                     regionCentral Asia  \n                            0.0017640                             -0.0984659  \n                   regionEastern Asia                   regionEastern Europe  \n                            0.0088410                             -0.0797522  \nregionLatin America and the Caribbean                        regionMelanesia  \n                            0.0379392                             -0.0067090  \n                     regionMicronesia                  regionNorthern Africa  \n                           -0.0895268                              0.0145632  \n               regionNorthern America                  regionNorthern Europe  \n                            0.1609234                              0.0063751  \n                      regionPolynesia               regionSouth-eastern Asia  \n                            0.0045840                             -0.0141714  \n                  regionSouthern Asia                  regionSouthern Europe  \n                           -0.0089686                              0.0698175  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                           -0.3306967                              0.0571853  \n                 regionWestern Europe                      job_typeUnskilled  \n                            0.0833153                             -0.0846780  \n                              genderM  \n                            0.1962831  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod2) \n\n                        Value  p-value                   Decision\nGlobal Stat        143804.115 0.000000 Assumptions NOT satisfied!\nSkewness             3716.416 0.000000 Assumptions NOT satisfied!\nKurtosis           140075.937 0.000000 Assumptions NOT satisfied!\nLink Function           2.550 0.110312    Assumptions acceptable.\nHeteroscedasticity      9.212 0.002404 Assumptions NOT satisfied!\n\n\n\nMod2 <- soc_data %>%  dplyr::select(-c(work_distance, languages, family_size))  %>% lm(annual_income_ppp ~ region + job_type*average_wk_hrs+education_months+region+gender*education_months, data=.)\nsummary(Mod2)\n\n\nCall:\nlm(formula = annual_income_ppp ~ region + job_type * average_wk_hrs + \n    education_months + region + gender * education_months, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-65530  -5157      3   5146  33350 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                            54829.60    4376.12  12.529  < 2e-16 ***\nregionCentral Asia                     -3609.73    2274.42  -1.587 0.112616    \nregionEastern Asia                      4834.25    2346.28   2.060 0.039464 *  \nregionEastern Europe                   -4394.43    1977.73  -2.222 0.026374 *  \nregionLatin America and the Caribbean   6933.59    2030.08   3.415 0.000647 ***\nregionMelanesia                         1897.75    2351.66   0.807 0.419752    \nregionMicronesia                       -3031.98    2685.54  -1.129 0.259005    \nregionNorthern Africa                   4816.64    2245.49   2.145 0.032046 *  \nregionNorthern America                 16160.99    2956.92   5.465 5.07e-08 ***\nregionNorthern Europe                   1849.26    1843.39   1.003 0.315869    \nregionPolynesia                         3128.26    2567.06   1.219 0.223103    \nregionSouth-eastern Asia                2998.16    2149.16   1.395 0.163126    \nregionSouthern Asia                     3517.06    2247.88   1.565 0.117798    \nregionSouthern Europe                   8416.08    1913.55   4.398 1.14e-05 ***\nregionSub-Saharan Africa              -14561.47    2112.30  -6.894 6.84e-12 ***\nregionWestern Asia                      8247.65    2063.91   3.996 6.62e-05 ***\nregionWestern Europe                    9742.39    1919.92   5.074 4.17e-07 ***\njob_typeUnskilled                       5374.35    4251.07   1.264 0.206262    \naverage_wk_hrs                           188.67      88.89   2.123 0.033883 *  \neducation_months                          44.78      12.15   3.685 0.000233 ***\ngenderM                               -18683.40    2797.28  -6.679 2.94e-11 ***\njob_typeUnskilled:average_wk_hrs        -305.25     101.63  -3.004 0.002695 ** \neducation_months:genderM                 179.74      17.29  10.398  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9190 on 2537 degrees of freedom\n  (58 observations deleted due to missingness)\nMultiple R-squared:  0.8056,    Adjusted R-squared:  0.8039 \nF-statistic:   478 on 22 and 2537 DF,  p-value: < 2.2e-16\n\n\n\ngvlma::gvlma(Mod2)\n\n\nCall:\nlm(formula = annual_income_ppp ~ region + job_type * average_wk_hrs + \n    education_months + region + gender * education_months, data = .)\n\nCoefficients:\n                          (Intercept)                     regionCentral Asia  \n                             54829.60                               -3609.73  \n                   regionEastern Asia                   regionEastern Europe  \n                              4834.25                               -4394.43  \nregionLatin America and the Caribbean                        regionMelanesia  \n                              6933.59                                1897.75  \n                     regionMicronesia                  regionNorthern Africa  \n                             -3031.98                                4816.64  \n               regionNorthern America                  regionNorthern Europe  \n                             16160.99                                1849.26  \n                      regionPolynesia               regionSouth-eastern Asia  \n                              3128.26                                2998.16  \n                  regionSouthern Asia                  regionSouthern Europe  \n                              3517.06                                8416.08  \n             regionSub-Saharan Africa                     regionWestern Asia  \n                            -14561.47                                8247.65  \n                 regionWestern Europe                      job_typeUnskilled  \n                              9742.39                                5374.35  \n                       average_wk_hrs                       education_months  \n                               188.67                                  44.78  \n                              genderM       job_typeUnskilled:average_wk_hrs  \n                            -18683.40                                -305.25  \n             education_months:genderM  \n                               179.74  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = Mod2) \n\n                     Value     p-value                   Decision\nGlobal Stat        471.098 0.000000000 Assumptions NOT satisfied!\nSkewness            11.605 0.000657878 Assumptions NOT satisfied!\nKurtosis           435.190 0.000000000 Assumptions NOT satisfied!\nLink Function       24.150 0.000000891 Assumptions NOT satisfied!\nHeteroscedasticity   0.153 0.695654693    Assumptions acceptable.\n\n\nMaybe I am missing something but I cannot really make this work.\n\nComment on your results. Did anything in the results surprise you? If so, what might be possible explanations for this.\n\nOriginally, the negative sign on Males but, when thought of in the context of the interaction term for education_months, it does not take all that many months to make up that difference. That the education premium as so large for males is discouraging but not surprising.\n\nExplain why you would or would not be comfortable using a model like this in a predictive setting—for example to help employers determine the right pay for employees.\n\nI would not. The reason largely stems from the need for an actual job description which, at least to me, is a far more important predictor of the salary/pay band than simple skilled/unskilled and education."
  },
  {
    "objectID": "posts/chapter-6/index.html",
    "href": "posts/chapter-6/index.html",
    "title": "Chapter 6",
    "section": "",
    "text": "Use the same health_insurance data set from this chapter to answer these questions.\n\nurl <- \"http://peopleanalytics-regression-book.org/data/health_insurance.csv\"\nhealth_insurance <- read.csv(url)\n\n\nComplete the full stratified approach to modeling the three product choices that was started in Section 6.2. Calculate the coefficients, odds ratios and p-values in each case.\n\n\nlibrary(fastDummies)\nhealth_insurance <- fastDummies::dummy_cols(health_insurance, \"product\")\nB_model <- glm(\n  formula = product_B ~ age + gender + household + \n    position_level + absent, \n  data = health_insurance, \n  family = \"binomial\"\n)\n# summary\nsummary(B_model)\n\n\nCall:\nglm(formula = product_B ~ age + gender + household + position_level + \n    absent, family = \"binomial\", data = health_insurance)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3382  -0.5026  -0.1412   0.4718   2.6610  \n\nCoefficients:\n                  Estimate Std. Error z value  Pr(>|z|)    \n(Intercept)       0.459135   0.318257   1.443     0.149    \nage               0.062359   0.006525   9.557   < 2e-16 ***\ngenderMale       -2.294869   0.197119 -11.642   < 2e-16 ***\ngenderNon-binary  0.746624   1.107231   0.674     0.500    \nhousehold        -0.987292   0.060711 -16.262   < 2e-16 ***\nposition_level   -0.286715   0.072781  -3.939 0.0000817 ***\nabsent            0.008888   0.010418   0.853     0.394    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1812.59  on 1452  degrees of freedom\nResidual deviance:  989.22  on 1446  degrees of freedom\nAIC: 1003.2\n\nNumber of Fisher Scoring iterations: 6\n\nexp(summary(B_model)$coefficients[,1])\n\n     (Intercept)              age       genderMale genderNon-binary \n       1.5827043        1.0643445        0.1007746        2.1098642 \n       household   position_level           absent \n       0.3725844        0.7507259        1.0089276 \n\nC_model <- glm(\n  formula = product_C ~ age + gender + household + \n    position_level + absent, \n  data = health_insurance, \n  family = \"binomial\"\n)\n# summary\nsummary(C_model)\n\n\nCall:\nglm(formula = product_C ~ age + gender + household + position_level + \n    absent, family = \"binomial\", data = health_insurance)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1755  -0.6413  -0.2498   0.5673   2.5783  \n\nCoefficients:\n                    Estimate  Std. Error z value Pr(>|z|)    \n(Intercept)      -7.93481599  0.45366891 -17.490  < 2e-16 ***\nage               0.11226048  0.00680073  16.507  < 2e-16 ***\ngenderMale        1.11641253  0.15610586   7.152 8.57e-13 ***\ngenderNon-binary -0.19990911  1.58470291  -0.126    0.900    \nhousehold         0.58450808  0.04039208  14.471  < 2e-16 ***\nposition_level   -0.03776099  0.06493862  -0.581    0.561    \nabsent           -0.00005825  0.00954273  -0.006    0.995    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1869.4  on 1452  degrees of freedom\nResidual deviance: 1179.3  on 1446  degrees of freedom\nAIC: 1193.3\n\nNumber of Fisher Scoring iterations: 5\n\nexp(summary(C_model)$coefficients[,1])\n\n     (Intercept)              age       genderMale genderNon-binary \n    0.0003580579     1.1188042519     3.0538788369     0.8188051735 \n       household   position_level           absent \n    1.7941082143     0.9629430626     0.9999417505 \n\n\n\nCarefully write down your interpretation of the odds ratios from the previous question.\n\nThe relative odds of B increase by 6.4% for each additional year of age. The relative odds of B decrease by almost 90% for males. The relative odds of B increase by 110% for Non-binary subjects. The relative odds of B decrease by 63% for each member of a household. The relative odds of B decrease by 25% for each position level and the relative odds of B increase by just under one percent for each day absent.\nThe relative odds of C increase by 11.8% for each additional year of age. The relative odds of C increase by over 200% for males. The relative odds of C decrease by 19% for Non-binary subjects. The relative odds of C increase by 79% for each member of a household. The relative odds of C decrease by 4% for each position level and the relative odds of C decrease by 0.006 percent for each day absent.\n\nRun a multinomial logistic regression model on the product outcome using Product B as reference. Calculate the coefficients, ratios and p-values in each case.\n\n\nlibrary(nnet)\nhealth_insurance$product <- relevel(as.factor(health_insurance$product), ref=\"B\")\nmod.MNL <- nnet::multinom(product ~ age+household+position_level+gender+absent, data=health_insurance)\n\n# weights:  24 (14 variable)\ninitial  value 1596.283655 \niter  10 value 980.134002\niter  20 value 744.965846\nfinal  value 744.682378 \nconverged\n\nsummary(mod.MNL)\n\nCall:\nnnet::multinom(formula = product ~ age + household + position_level + \n    gender + absent, data = health_insurance)\n\nCoefficients:\n  (Intercept)         age household position_level genderMale genderNon-binary\nA    4.601226 -0.24367214 0.9677148      0.4153550   2.382584       -0.2532295\nC   -5.625154  0.02614886 1.1720732      0.2017425   2.479328       -1.5239331\n        absent\nA -0.011678127\nC -0.008413771\n\nStd. Errors:\n  (Intercept)         age  household position_level genderMale genderNon-binary\nA   0.5105615 0.015431776 0.06943100     0.08916873  0.2324285         1.226256\nC   0.5116098 0.008644891 0.07117376     0.08482208  0.2253558         2.000928\n      absent\nA 0.01298151\nC 0.01213475\n\nResidual Deviance: 1489.365 \nAIC: 1517.365 \n\n# calculate z-statistics of coefficients\nz_stats <- summary(mod.MNL)$coefficients/\n  summary(mod.MNL)$standard.errors\nz_stats\n\n  (Intercept)        age household position_level genderMale genderNon-binary\nA    9.012089 -15.790285  13.93779        4.65808   10.25082       -0.2065062\nC  -10.995007   3.024776  16.46777        2.37842   11.00184       -0.7616133\n      absent\nA -0.8995969\nC -0.6933616\n\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\ndata.frame(t(p_values))\n\n                              A           C\n(Intercept)      0.000000000000 0.000000000\nage              0.000000000000 0.002488176\nhousehold        0.000000000000 0.000000000\nposition_level   0.000003191726 0.017387008\ngenderMale       0.000000000000 0.000000000\ngenderNon-binary 0.836395524437 0.446290854\nabsent           0.368334803234 0.488082628\n\nodds_ratios <- exp(summary(mod.MNL)$coefficients)\ndata.frame(t(odds_ratios))\n\n                          A            C\n(Intercept)      99.6063487  0.003606009\nage               0.7837446  1.026493737\nhousehold         2.6319231  3.228679260\nposition_level    1.5149085  1.223532956\ngenderMale       10.8328575 11.933240577\ngenderNon-binary  0.7762897  0.217853354\nabsent            0.9883898  0.991621526\n\n\n\nVerify that the coefficients for Product C against reference Product B matches those calculated in Section 6.3.3.\n\nThey do.\n\nCarefully write down your interpretation of the odds ratios calculated in the previous question.\n\nFor each unit of age, the relative odds of A decrease by 22% and the relative odds of C increase by 2.6%. For each member of the household, the relative odds of A increase by 163% and the relative odds of C increase by 223%. For each unit of position level, the relative odds of A increase by 51.5% and increase for C by 22.4%. Males have relative odds 983% higher for A and 1093% higher for C. Non-binary has 22.4% lower relative odds for A and 78.2% lower relative odds for C. Each day of absence decreases relative odds of A by 1.2% and C by .84%.\n\nUse the process described in Section 6.4.1 to simplify the multinomial model in Question 3.\n\n\nmod.MNL <- nnet::multinom(product ~ age+household+position_level+gender, data=health_insurance)\n\n# weights:  21 (12 variable)\ninitial  value 1596.283655 \niter  10 value 873.188793\niter  20 value 745.137511\nfinal  value 745.124043 \nconverged\n\nsummary(mod.MNL)\n\nCall:\nnnet::multinom(formula = product ~ age + household + position_level + \n    gender, data = health_insurance)\n\nCoefficients:\n  (Intercept)         age household position_level genderMale genderNon-binary\nA    4.500997 -0.24338609 0.9641998      0.3911706   2.377054       -0.1716652\nC   -5.691713  0.02637775 1.1692938      0.1820893   2.475113       -1.4676958\n\nStd. Errors:\n  (Intercept)         age  household position_level genderMale genderNon-binary\nA   0.4976653 0.015428446 0.06916521     0.08507585  0.2323558         1.221831\nC   0.5022372 0.008632684 0.07095526     0.07976710  0.2252566         1.993456\n\nResidual Deviance: 1490.248 \nAIC: 1514.248 \n\n\nDropping absent is justified following this procedure as the text demonstrates. Next would be position level or gender and neither are justified."
  },
  {
    "objectID": "posts/chapter-7/index.html",
    "href": "posts/chapter-7/index.html",
    "title": "Chapter 7",
    "section": "",
    "text": "Load the managers data set via the peopleanalyticsdata package or download it from the internet. It is a set of information of 571 managers in a sales organization and consists of the following fields:\n\nemployee_id for each manager\nperformance_group of each manager in a recent performance review: Bottom performer, Middle performer, Top performer\nyrs_employed: total length of time employed in years\nmanager_hire: whether or not the individual was hired directly to be a manager (Y) or promoted to manager (N)\ntest_score: score on a test given to all managers\ngroup_size: the number of employees in the group they are responsible for\nconcern_flag: whether or not the individual has been the subject of a complaint by a member of their group\nmobile_flag: whether or not the individual works mobile (Y) or in the office (N)\ncustomers: the number of customer accounts the manager is responsible for\nhigh_hours_flag: whether or not the manager has entered unusually high hours into their timesheet in the past year\ntransfers: the number of transfer requests coming from the manager’s group while they have been a manager\nreduced_schedule: whether the manager works part time (Y) or full time (N)\ncity: the current office of the manager.\n\nConstruct a model to determine how the data provided may help explain the performance_group of a manager by following these steps:\n\nmanagers <- read.csv(\"http://peopleanalytics-regression-book.org/data/managers.csv\")\n\n\nConvert the outcome variable to an ordered factor of increasing performance.\n\n\nmanagers$performance_group <- ordered(managers$performance_group, levels = c(\"Bottom\", \"Middle\", \"Top\"))\n\n\nConvert input variables to categorical factors as appropriate.\n\n\nsummary(managers)\n\n employee_id        performance_group  yrs_employed   manager_hire      \n Length:571         Bottom:129        Min.   :2.000   Length:571        \n Class :character   Middle:376        1st Qu.:4.300   Class :character  \n Mode  :character   Top   : 66        Median :4.600   Mode  :character  \n                                      Mean   :4.596                     \n                                      3rd Qu.:5.000                     \n                                      Max.   :6.000                     \n   test_score      group_size    concern_flag       mobile_flag       \n Min.   :  0.0   Min.   : 5.00   Length:571         Length:571        \n 1st Qu.:182.0   1st Qu.:10.00   Class :character   Class :character  \n Median :235.0   Median :11.00   Mode  :character   Mode  :character  \n Mean   :240.2   Mean   :11.82                                        \n 3rd Qu.:295.0   3rd Qu.:13.00                                        \n Max.   :500.0   Max.   :25.00                                        \n   customers     high_hours_flag      transfers      reduced_schedule  \n Min.   :10.00   Length:571         Min.   :0.0000   Length:571        \n 1st Qu.:18.00   Class :character   1st Qu.:0.0000   Class :character  \n Median :20.00   Mode  :character   Median :0.0000   Mode  :character  \n Mean   :21.06                      Mean   :0.7968                     \n 3rd Qu.:24.00                      3rd Qu.:2.0000                     \n Max.   :40.00                      Max.   :5.0000                     \n     city          \n Length:571        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\nPerform any exploratory data analysis that you wish to do.\n\nI’ll stick with a summary.\n\nRun a proportional odds logistic regression model against all relevant input variables.\n\n\nlibrary(MASS)\nmod.ORD <- polr(performance_group~yrs_employed+manager_hire+test_score+group_size+concern_flag+mobile_flag+customers+high_hours_flag+transfers+reduced_schedule+city, data=managers)\nsummary(mod.ORD)\n\nCall:\npolr(formula = performance_group ~ yrs_employed + manager_hire + \n    test_score + group_size + concern_flag + mobile_flag + customers + \n    high_hours_flag + transfers + reduced_schedule + city, data = managers)\n\nCoefficients:\n                      Value Std. Error  t value\nyrs_employed      -1.200549    0.21182 -5.66767\nmanager_hireY     -1.529848    0.49180 -3.11070\ntest_score         0.003533    0.00118  2.99463\ngroup_size         0.098344    0.03499  2.81033\nconcern_flagY     -0.094360    0.31017 -0.30422\nmobile_flagY      -0.105275    0.22208 -0.47403\ncustomers         -0.006245    0.02140 -0.29181\nhigh_hours_flagY   0.564096    0.20349  2.77214\ntransfers         -0.239006    0.08420 -2.83851\nreduced_scheduleY  0.191819    0.35987  0.53302\ncityHouston        0.024754    0.53748  0.04605\ncityNew York       0.316408    0.35429  0.89306\ncityOrlando        0.137964    0.53700  0.25692\ncitySan Francisco -0.286250    0.44627 -0.64143\ncityToronto        0.303623    0.33817  0.89784\n\nIntercepts:\n              Value   Std. Error t value\nBottom|Middle -4.8776  1.1191    -4.3584\nMiddle|Top    -1.1883  1.0947    -1.0855\n\nResidual Deviance: 901.0013 \nAIC: 935.0013 \n\n\n\nConstruct p-values for the coefficients and consider how to simplify the model to remove variables that do not impact the outcome.\n\n\n# get coefficients (it's in matrix form)\ncoefficients <- summary(mod.ORD)$coefficients\n# calculate p-values\np_value <- (1 - pnorm(abs(coefficients[ ,\"t value\"]), 0, 1))*2\n# bind back to coefficients\n(coefficients <- cbind(coefficients, p_value))\n\n                         Value  Std. Error     t value          p_value\nyrs_employed      -1.200549054 0.211823948 -5.66767388 0.00000001447491\nmanager_hireY     -1.529848463 0.491802054 -3.11069962 0.00186644694687\ntest_score         0.003532813 0.001179718  2.99462596 0.00274781577732\ngroup_size         0.098344428 0.034993894  2.81033111 0.00494905551015\nconcern_flagY     -0.094360424 0.310169136 -0.30422248 0.76095839840268\nmobile_flagY      -0.105275156 0.222083505 -0.47403411 0.63547558470810\ncustomers         -0.006245482 0.021402706 -0.29180805 0.77043339213884\nhigh_hours_flagY   0.564095583 0.203487608  2.77213727 0.00556895469976\ntransfers         -0.239006244 0.084201412 -2.83850637 0.00453252150893\nreduced_scheduleY  0.191819056 0.359873357  0.53301822 0.59402096782304\ncityHouston        0.024753812 0.537484942  0.04605489 0.96326649740558\ncityNew York       0.316407528 0.354294345  0.89306401 0.37182289551346\ncityOrlando        0.137964146 0.536996783  0.25691801 0.79724206568822\ncitySan Francisco -0.286249831 0.446269016 -0.64142887 0.52124408026741\ncityToronto        0.303623166 0.338172321  0.89783565 0.36927317450871\nBottom|Middle     -4.877642364 1.119127112 -4.35843463 0.00001309960345\nMiddle|Top        -1.188320988 1.094688871 -1.08553309 0.27768561844106\n\n\n\nCalculate the odds ratios for your simplified model and write an interpretation of them.\n\n\nmod.ORD.S <- polr(performance_group~yrs_employed+manager_hire+test_score+group_size+high_hours_flag+transfers, data=managers)\nsummary(mod.ORD.S)\n\nCall:\npolr(formula = performance_group ~ yrs_employed + manager_hire + \n    test_score + group_size + high_hours_flag + transfers, data = managers)\n\nCoefficients:\n                    Value Std. Error t value\nyrs_employed     -1.25502   0.201131  -6.240\nmanager_hireY    -1.56948   0.480757  -3.265\ntest_score        0.00348   0.001162   2.995\ngroup_size        0.10243   0.032464   3.155\nhigh_hours_flagY  0.54965   0.190832   2.880\ntransfers        -0.24533   0.081103  -3.025\n\nIntercepts:\n              Value   Std. Error t value\nBottom|Middle -5.1835  0.9858    -5.2584\nMiddle|Top    -1.5099  0.9549    -1.5811\n\nResidual Deviance: 904.1867 \nAIC: 920.1867 \n\nexp(summary(mod.ORD.S)$coefficients[,1])\n\n    yrs_employed    manager_hireY       test_score       group_size \n      0.28507068       0.20815421       1.00348649       1.10786191 \nhigh_hours_flagY        transfers    Bottom|Middle       Middle|Top \n      1.73264719       0.78244568       0.00560822       0.22093960 \n\n\n\nFor each year employed, the relative odds of a higher performance group decline by 71.5%.\nFor manager hires, the relative odds of a higher performance group decline by 79.2%.\nFor each point of test score, the relative odds of a higher performance rating increase by .34%.\nFor each increment of group size, the relative odds of a higher performance rating increase by 10.8%.\nFor those flagged with high hours, the relative odds of a higher performance rating increase by 73.3%.\nFor each transfer request, the relative odds of a higher performance rating decrease by 21.8%.\n\n\nEstimate the fit of the simplified model using a variety of metrics and perform tests to determine if the model is a good fit for the data.\n\n\nDescTools::PseudoR2(\n  mod.ORD.S, \n  which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\", \"AIC\")\n)\n\n    McFadden     CoxSnell   Nagelkerke          AIC \n  0.07999042   0.12862163   0.15663647 920.18671319 \n\ngeneralhoslem::lipsitz.test(mod.ORD.S)\n\n\n    Lipsitz goodness of fit test for ordinal response models\n\ndata:  formula:  performance_group ~ yrs_employed + manager_hire + test_score + formula:      group_size + high_hours_flag + transfers\nLR statistic = 9.7813, df = 9, p-value = 0.3685\n\ngeneralhoslem::pulkrob.chisq(mod.ORD.S, c(\"manager_hire\",\"high_hours_flag\"))\n\n\n    Pulkstenis-Robinson chi-squared test\n\ndata:  formula:  performance_group ~ yrs_employed + manager_hire + test_score + formula:      group_size + high_hours_flag + transfers\nX-squared = 21.082, df = 11, p-value = 0.03253\n\n\nFor the Hosmer-Lemeshow test, the null hypothesis of a good model fit is reasonable; the Pulkstenis-Robinson test offers evidence to the contrary and suggests lack of fit.\n\nConstruct new outcome variables and use a stratified binomial approach to determine if the proportional odds assumption holds for your simplified model. Are there any input variables for which you may be concerned that the assumption is violated? What would you consider doing in this case?\n\nI refuse to do this for this purpose. The proportional odds assumption is necessary for a cumulative ordered response model. An alternative model, perhaps, but there is no such thing as a cumulative ordered regression model without it.\nThat said, there is actually a large literature, mostly in epidemiology involving Stephen R. Cole about something called data expansion as an approach to these problems. Here is what it would look like.\nmanagers$Not.Bottom <- (managers$performance_group!=\"Bottom\")\nmanagers$Top.Performers <- (managers$performance_group==\"Top\")\nmod.bin.NB <- glm(Not.Bottom~yrs_employed+manager_hire+test_score+group_size+high_hours_flag+transfers, family=binomial(link=\"logit\"), data=managers)\nmod.bin.TP <- glm(Top.Performers~yrs_employed+manager_hire+test_score+group_size+high_hours_flag+transfers, family=binomial(link=\"logit\"), data=managers)\nlibrary(stargazer)\nstargazer(mod.bin.NB,mod.bin.TP, type=\"html\")\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nNot.Bottom\n\n\nTop.Performers\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nyrs_employed\n\n\n-1.170***\n\n\n-1.226***\n\n\n\n\n\n\n(0.235)\n\n\n(0.305)\n\n\n\n\n\n\n\n\n\n\n\n\nmanager_hireY\n\n\n-1.679***\n\n\n-0.984\n\n\n\n\n\n\n(0.512)\n\n\n(0.693)\n\n\n\n\n\n\n\n\n\n\n\n\ntest_score\n\n\n0.004**\n\n\n0.004**\n\n\n\n\n\n\n(0.001)\n\n\n(0.002)\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_size\n\n\n0.098**\n\n\n0.124***\n\n\n\n\n\n\n(0.040)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\nhigh_hours_flagY\n\n\n0.332\n\n\n0.888***\n\n\n\n\n\n\n(0.226)\n\n\n(0.285)\n\n\n\n\n\n\n\n\n\n\n\n\ntransfers\n\n\n-0.225**\n\n\n-0.338**\n\n\n\n\n\n\n(0.093)\n\n\n(0.142)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n4.875***\n\n\n0.900\n\n\n\n\n\n\n(1.125)\n\n\n(1.428)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n571\n\n\n571\n\n\n\n\nLog Likelihood\n\n\n-280.889\n\n\n-180.851\n\n\n\n\nAkaike Inf. Crit.\n\n\n575.777\n\n\n375.702\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\nUse the Brant-Wald test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\nlibrary(brant)\nbrant::brant(mod.ORD.S)\n\n---------------------------------------------------- \nTest for        X2  df  probability \n---------------------------------------------------- \nOmnibus         4.87    6   0.56\nyrs_employed        0.02    1   0.88\nmanager_hireY       0.79    1   0.37\ntest_score      0   1   0.95\ngroup_size      0.21    1   0.65\nhigh_hours_flagY    2.71    1   0.1\ntransfers       0.51    1   0.47\n---------------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n\n\nSeems fine despite the caveats above.\n\nWrite a full report on your model intended for an audience of people with limited knowledge of statistics.\n\nTLDR: As the number of years employed increases, performance ratings decrease. Those hired to be managers are less likely to be low performers though it does not well differentiate between middle and top performers. Higher test scores are associated with better performance. Managers of larger groups get higher performers. Those working high hours are most likely to be top performers. Finally, transfers are associated with lower performance ratings of the managers that they are departing; voting with one’s feet is a thing. Number of customers, city of employment, full or part time, concern flags and in office/mobile work have no obvious impact."
  },
  {
    "objectID": "posts/chapter-8/index.html",
    "href": "posts/chapter-8/index.html",
    "title": "Chapter 8",
    "section": "",
    "text": "8.3.2 Data exercises\nFor Exercises 1–4, use the speed_dating set used earlier in this chapter.\n\nspeed_dating <- read.csv(\"http://peopleanalytics-regression-book.org/data/speed_dating.csv\")\nemployee_survey <- read.csv(\"http://peopleanalytics-regression-book.org/data/employee_survey.csv\")\n\nThe codebook for the data can be found here.\n\nSplit the data into two sets according to the gender of the participant. Run standard binomial logistic regression models on each set to determine the relationship between the dec decision outcome and the input variables samerace, agediff, attr, intel and prob.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(kableExtra)\nnames(speed_dating)\n\n [1] \"iid\"      \"gender\"   \"match\"    \"samerace\" \"race\"     \"goal\"    \n [7] \"dec\"      \"attr\"     \"intel\"    \"prob\"     \"agediff\" \n\n# 1 is male, 0 is female\nSDM <- speed_dating %>% filter(gender==1)\nSDF <- speed_dating %>% filter(gender==0)\nspeed_dating %>% group_by(gender) %>% skim(dec, samerace, agediff, attr, intel, prob) %>% kable() %>% scroll_box()\n\n\n\n \n  \n    skim_type \n    skim_variable \n    gender \n    n_missing \n    complete_rate \n    numeric.mean \n    numeric.sd \n    numeric.p0 \n    numeric.p25 \n    numeric.p50 \n    numeric.p75 \n    numeric.p100 \n    numeric.hist \n  \n \n\n  \n    numeric \n    dec \n    0 \n    0 \n    1.0000000 \n    0.3654398 \n    0.4816108 \n    0 \n    0 \n    0 \n    1 \n    1 \n    ▇▁▁▁▅ \n  \n  \n    numeric \n    dec \n    1 \n    0 \n    1.0000000 \n    0.4742489 \n    0.4993960 \n    0 \n    0 \n    0 \n    1 \n    1 \n    ▇▁▁▁▇ \n  \n  \n    numeric \n    samerace \n    0 \n    0 \n    1.0000000 \n    0.3962715 \n    0.4891805 \n    0 \n    0 \n    0 \n    1 \n    1 \n    ▇▁▁▁▅ \n  \n  \n    numeric \n    samerace \n    1 \n    0 \n    1.0000000 \n    0.3953267 \n    0.4889790 \n    0 \n    0 \n    0 \n    1 \n    1 \n    ▇▁▁▁▅ \n  \n  \n    numeric \n    agediff \n    0 \n    94 \n    0.9775335 \n    3.6584352 \n    3.0612015 \n    0 \n    1 \n    3 \n    5 \n    32 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    agediff \n    1 \n    104 \n    0.9752027 \n    3.6584352 \n    3.0612015 \n    0 \n    1 \n    3 \n    5 \n    32 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    attr \n    0 \n    101 \n    0.9758604 \n    5.9192995 \n    2.0017544 \n    0 \n    5 \n    6 \n    7 \n    10 \n    ▂▃▇▇▂ \n  \n  \n    numeric \n    attr \n    1 \n    101 \n    0.9759180 \n    6.4600293 \n    1.8586750 \n    0 \n    5 \n    7 \n    8 \n    10 \n    ▁▂▇▇▃ \n  \n  \n    numeric \n    intel \n    0 \n    147 \n    0.9648662 \n    7.4473619 \n    1.6098729 \n    0 \n    7 \n    8 \n    8 \n    10 \n    ▁▁▃▇▃ \n  \n  \n    numeric \n    intel \n    1 \n    149 \n    0.9644731 \n    7.2899876 \n    1.4848264 \n    0 \n    6 \n    7 \n    8 \n    10 \n    ▁▁▃▇▃ \n  \n  \n    numeric \n    prob \n    0 \n    164 \n    0.9608031 \n    5.2156716 \n    2.1431138 \n    0 \n    4 \n    5 \n    7 \n    10 \n    ▂▃▇▅▁ \n  \n  \n    numeric \n    prob \n    1 \n    145 \n    0.9654268 \n    5.1994320 \n    2.1162607 \n    0 \n    4 \n    5 \n    7 \n    10 \n    ▂▅▇▅▁ \n  \n\n\n\n\n\n\nModel Estimates for the Two Groups\nModel.F <- glm(dec~samerace+agediff+attr+intel+prob, data=SDF, family=binomial(link=\"logit\"))\nModel.M <- glm(dec~samerace+agediff+attr+intel+prob, data=SDM, family=binomial(link=\"logit\"))\nlibrary(stargazer)\nstargazer(Model.F, Model.M, type = \"html\", column.labels = c(\"Female\",\"Male\"))\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ndec\n\n\n\n\n\n\nFemale\n\n\nMale\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nsamerace\n\n\n-0.053\n\n\n-0.137*\n\n\n\n\n\n\n(0.078)\n\n\n(0.080)\n\n\n\n\n\n\n\n\n\n\n\n\nagediff\n\n\n-0.002\n\n\n-0.019\n\n\n\n\n\n\n(0.012)\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\nattr\n\n\n0.547***\n\n\n0.778***\n\n\n\n\n\n\n(0.025)\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\nintel\n\n\n0.091***\n\n\n-0.079**\n\n\n\n\n\n\n(0.029)\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\nprob\n\n\n0.228***\n\n\n0.325***\n\n\n\n\n\n\n(0.020)\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-5.788***\n\n\n-6.113***\n\n\n\n\n\n\n(0.259)\n\n\n(0.272)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n3,890\n\n\n3,899\n\n\n\n\nLog Likelihood\n\n\n-2,045.016\n\n\n-1,954.047\n\n\n\n\nAkaike Inf. Crit.\n\n\n4,102.033\n\n\n3,920.095\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\nsamerace has no clear relationship to the decision for females but leads to less likelihood for wishing to see the person again for males.\nagediff is not clearly related to the decision for either males or females.\nattr attraction is positively related to the decision though the effect is stronger for males than females. I will say more about this below.\nintel intelligence is positively related to yes for females but negatively related to yes for males.\nprob the probability that the other person will say yes on a 1 to 10 scale is positively related to yes for both males and females.\n\nPersonally, it makes more sense to me to estimate this as a common but stratified model because it allows me to identify where things differ. There are two ways to assess that. I will use anova and a formal model \\(\\chi^2\\) but we could also just use the p-values for the interaction terms. Let’s have a look at the result for the combined model and then confirm it with individual anova results.\n\nModel.All <- glm(dec~gender*samerace+gender*agediff+gender*attr+gender*intel+gender*prob, data=speed_dating, family=binomial(link=\"logit\"))\nsummary(Model.All)\n\n\nCall:\nglm(formula = dec ~ gender * samerace + gender * agediff + gender * \n    attr + gender * intel + gender * prob, family = binomial(link = \"logit\"), \n    data = speed_dating)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.0544  -0.8357  -0.3466   0.8712   2.9297  \n\nCoefficients:\n                Estimate Std. Error z value      Pr(>|z|)    \n(Intercept)     -5.78827    0.25864 -22.380       < 2e-16 ***\ngender          -0.32426    0.37564  -0.863       0.38801    \nsamerace        -0.05279    0.07835  -0.674       0.50047    \nagediff         -0.00166    0.01248  -0.133       0.89418    \nattr             0.54728    0.02525  21.671       < 2e-16 ***\nintel            0.09061    0.02915   3.109       0.00188 ** \nprob             0.22789    0.02011  11.332       < 2e-16 ***\ngender:samerace -0.08444    0.11221  -0.753       0.45175    \ngender:agediff  -0.01701    0.01816  -0.937       0.34898    \ngender:attr      0.23041    0.03963   5.814 0.00000000609 ***\ngender:intel    -0.16932    0.04231  -4.002 0.00006292444 ***\ngender:prob      0.09668    0.02944   3.284       0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10647.3  on 7788  degrees of freedom\nResidual deviance:  7998.1  on 7777  degrees of freedom\n  (589 observations deleted due to missingness)\nAIC: 8022.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nThis evidence suggests that attraction, intelligence, and the probability of a yes from the partner all differ in their effects on males and females. Partners of the same race and the age difference do not differ among males and females. To confirm this, let’s look at the the anova results. They tell us the same thing though the p-values differ slightly.\n\nMA1 <- glm(dec~samerace+gender*agediff+gender*attr+gender*intel+gender*prob, data=speed_dating, family=binomial(link=\"logit\"))\nanova(MA1, Model.All, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: dec ~ samerace + gender * agediff + gender * attr + gender * \n    intel + gender * prob\nModel 2: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + gender * prob\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      7778     7998.7                     \n2      7777     7998.1  1  0.56613   0.4518\n\nMA2 <- glm(dec~gender*samerace+agediff+gender*attr+gender*intel+gender*prob, data=speed_dating, family=binomial(link=\"logit\"))\nanova(MA2, Model.All, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: dec ~ gender * samerace + agediff + gender * attr + gender * \n    intel + gender * prob\nModel 2: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + gender * prob\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      7778     7999.0                     \n2      7777     7998.1  1  0.87545   0.3495\n\nMA3 <- glm(dec~gender*samerace+gender*agediff+attr+gender*intel+gender*prob, data=speed_dating, family=binomial(link=\"logit\"))\nanova(MA3, Model.All, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: dec ~ gender * samerace + gender * agediff + attr + gender * \n    intel + gender * prob\nModel 2: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + gender * prob\n  Resid. Df Resid. Dev Df Deviance       Pr(>Chi)    \n1      7778     8032.5                               \n2      7777     7998.1  1   34.332 0.000000004648 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMA4 <- glm(dec~gender*samerace+gender*agediff+gender*attr+intel+gender*prob, data=speed_dating, family=binomial(link=\"logit\"))\nanova(MA4, Model.All, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: dec ~ gender * samerace + gender * agediff + gender * attr + \n    intel + gender * prob\nModel 2: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + gender * prob\n  Resid. Df Resid. Dev Df Deviance   Pr(>Chi)    \n1      7778     8014.2                           \n2      7777     7998.1  1   16.099 0.00006013 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMA5 <- glm(dec~gender*samerace+gender*agediff+gender*attr+gender*intel+prob, data=speed_dating, family=binomial(link=\"logit\"))\nanova(MA5, Model.All, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + prob\nModel 2: dec ~ gender * samerace + gender * agediff + gender * attr + \n    gender * intel + gender * prob\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)   \n1      7778     8008.9                        \n2      7777     7998.1  1    10.82 0.001004 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nRun similar mixed models on these sets with a random intercept for iid.\n\n\nlibrary(lme4)\nModel.F.Mixed <- glmer(dec~samerace+agediff+attr+intel+prob + (1 | iid), data=SDF, family=binomial(link=\"logit\"))\nModel.M.Mixed <- glmer(dec~samerace+agediff+attr+intel+prob + (1 | iid), data=SDM, family=binomial(link=\"logit\"))\nsummary(Model.F.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ samerace + agediff + attr + intel + prob + (1 | iid)\n   Data: SDF\n\n     AIC      BIC   logLik deviance df.resid \n  3209.8   3253.6  -1597.9   3195.8     3883 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-22.0221  -0.3654  -0.0874   0.3501  21.7704 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n iid    (Intercept) 5.806    2.41    \nNumber of obs: 3890, groups:  iid, 268\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -13.40398    0.61283 -21.872  < 2e-16 ***\nsamerace      0.54951    0.11991   4.583 4.59e-06 ***\nagediff      -0.03507    0.01971  -1.779   0.0752 .  \nattr          0.97520    0.04464  21.846  < 2e-16 ***\nintel         0.40788    0.05013   8.136 4.08e-16 ***\nprob          0.62907    0.04229  14.874  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) samerc agedff attr   intel \nsamerace -0.153                            \nagediff  -0.092 -0.049                     \nattr     -0.620  0.047 -0.020              \nintel    -0.666  0.058 -0.008  0.074       \nprob     -0.510  0.043 -0.016  0.264 -0.006\n\nsummary(Model.M.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ samerace + agediff + attr + intel + prob + (1 | iid)\n   Data: SDM\n\n     AIC      BIC   logLik deviance df.resid \n  3180.4   3224.3  -1583.2   3166.4     3892 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-23.8209  -0.3503  -0.0220   0.3691  26.7441 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n iid    (Intercept) 4.541    2.131   \nNumber of obs: 3899, groups:  iid, 273\n\nFixed effects:\n             Estimate Std. Error z value   Pr(>|z|)    \n(Intercept) -12.60865    0.58896 -21.408    < 2e-16 ***\nsamerace     -0.09398    0.11258  -0.835     0.4038    \nagediff      -0.03503    0.02005  -1.748     0.0805 .  \nattr          1.19470    0.05052  23.647    < 2e-16 ***\nintel         0.22500    0.04870   4.620 0.00000383 ***\nprob          0.61915    0.03960  15.637    < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) samerc agedff attr   intel \nsamerace -0.059                            \nagediff  -0.107 -0.046                     \nattr     -0.673 -0.027  0.023              \nintel    -0.608  0.052 -0.047  0.019       \nprob     -0.495 -0.086  0.010  0.268 -0.012\n\n\nThe saturated model.\n\nModel.All.Mixed <- glmer(dec~gender*samerace+gender*agediff+gender*attr+gender*intel+gender*prob + (1 | iid), data=speed_dating, family=binomial(link=\"logit\"), control= glmerControl(optimizer = \"bobyqa\"), nAGQ=20)\nsummary(Model.All.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Adaptive\n  Gauss-Hermite Quadrature, nAGQ = 20) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ gender * samerace + gender * agediff + gender * attr +  \n    gender * intel + gender * prob + (1 | iid)\n   Data: speed_dating\nControl: glmerControl(optimizer = \"bobyqa\")\n\n     AIC      BIC   logLik deviance df.resid \n  6379.7   6470.2  -3176.8   6353.7     7776 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-25.3849  -0.3585  -0.0617   0.3601  28.1651 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n iid    (Intercept) 5.237    2.288   \nNumber of obs: 7789, groups:  iid, 541\n\nFixed effects:\n                  Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     -13.132720   0.566641 -23.176  < 2e-16 ***\ngender            0.240669   0.742928   0.324 0.745978    \nsamerace          0.533202   0.118149   4.513 6.39e-06 ***\nagediff          -0.033792   0.019477  -1.735 0.082742 .  \nattr              0.958233   0.042302  22.652  < 2e-16 ***\nintel             0.398145   0.048981   8.128 4.35e-16 ***\nprob              0.614830   0.040263  15.270  < 2e-16 ***\ngender:samerace  -0.628438   0.164008  -3.832 0.000127 ***\ngender:agediff   -0.002149   0.028100  -0.076 0.939031    \ngender:attr       0.255398   0.061909   4.125 3.70e-05 ***\ngender:intel     -0.160369   0.068051  -2.357 0.018443 *  \ngender:prob       0.017481   0.054014   0.324 0.746211    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gender samerc agedff attr   intel  prob   gndr:s gndr:g\ngender      -0.661                                                        \nsamerace    -0.126  0.068                                                 \nagediff     -0.116  0.102 -0.045                                          \nattr        -0.579  0.360  0.018 -0.007                                   \nintel       -0.662  0.461  0.043 -0.001  0.028                            \nprob        -0.464  0.279  0.016 -0.003  0.204 -0.050                     \ngender:smrc  0.092 -0.081 -0.721  0.032 -0.014 -0.031 -0.012              \ngender:gdff  0.087 -0.143  0.029 -0.692 -0.001 -0.002 -0.003 -0.044       \ngender:attr  0.310 -0.564  0.012 -0.007 -0.613  0.018 -0.075 -0.024  0.027\ngender:intl  0.432 -0.618 -0.019 -0.005  0.016 -0.701  0.069  0.039 -0.017\ngender:prob  0.278 -0.400  0.007 -0.007 -0.097  0.067 -0.695 -0.049  0.018\n            gndr:t gndr:n\ngender                   \nsamerace                 \nagediff                  \nattr                     \nintel                    \nprob                     \ngender:smrc              \ngender:gdff              \ngender:attr              \ngender:intl -0.053       \ngender:prob  0.140 -0.102\n\n\n\nWhat different conclusions can you make in comparing the mixed models with the standard models?\n\nThe model comparisons should not differ in ways that depend on using the saturated or the separate models. First, there is evidence of random effects by ID. Comparing the AIC values, the mixed effects models fit better in both cases. Second, in the mixed model, females seem to prefer samerace partners [the result is positive and different from zero]; males do not. Without mixed effects, samerace was negative for males but has no effect with mixed effects. agediff is marginally different from zero and negative for both groups. Attraction is positive for both groups though more important for males. Intelligence is positive for both groups though stronger for females. The probability the partner will say yes is positively related and similar for both groups. Let’s show them side by side.\nstargazer(Model.M, Model.M.Mixed, Model.F, Model.F.Mixed, column.labels = c(\"Male\", \"Male:RE\", \"Female\", \"Female.RE\"), type=\"html\")\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ndec\n\n\n\n\n\n\nlogistic\n\n\ngeneralized linear\n\n\nlogistic\n\n\ngeneralized linear\n\n\n\n\n\n\n\n\n\nmixed-effects\n\n\n\n\n\nmixed-effects\n\n\n\n\n\n\nMale\n\n\nMale:RE\n\n\nFemale\n\n\nFemale.RE\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n\n\n\n\n\n\nsamerace\n\n\n-0.137*\n\n\n-0.094\n\n\n-0.053\n\n\n0.550***\n\n\n\n\n\n\n(0.080)\n\n\n(0.113)\n\n\n(0.078)\n\n\n(0.120)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nagediff\n\n\n-0.019\n\n\n-0.035*\n\n\n-0.002\n\n\n-0.035*\n\n\n\n\n\n\n(0.013)\n\n\n(0.020)\n\n\n(0.012)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nattr\n\n\n0.778***\n\n\n1.195***\n\n\n0.547***\n\n\n0.975***\n\n\n\n\n\n\n(0.031)\n\n\n(0.051)\n\n\n(0.025)\n\n\n(0.045)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nintel\n\n\n-0.079**\n\n\n0.225***\n\n\n0.091***\n\n\n0.408***\n\n\n\n\n\n\n(0.031)\n\n\n(0.049)\n\n\n(0.029)\n\n\n(0.050)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprob\n\n\n0.325***\n\n\n0.619***\n\n\n0.228***\n\n\n0.629***\n\n\n\n\n\n\n(0.021)\n\n\n(0.040)\n\n\n(0.020)\n\n\n(0.042)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-6.113***\n\n\n-12.609***\n\n\n-5.788***\n\n\n-13.404***\n\n\n\n\n\n\n(0.272)\n\n\n(0.589)\n\n\n(0.259)\n\n\n(0.613)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n3,899\n\n\n3,899\n\n\n3,890\n\n\n3,890\n\n\n\n\nLog Likelihood\n\n\n-1,954.047\n\n\n-1,583.221\n\n\n-2,045.016\n\n\n-1,597.882\n\n\n\n\nAkaike Inf. Crit.\n\n\n3,920.095\n\n\n3,180.442\n\n\n4,102.033\n\n\n3,209.765\n\n\n\n\nBayesian Inf. Crit.\n\n\n\n\n3,224.321\n\n\n\n\n3,253.628\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\nExperiment with some random slope effects to see if they reveal anything new about the input variables.\n\nI will examine attraction.\n\n\nFemale\n\nModel.F.Mixed <- glmer(dec~samerace+agediff+attr+intel+prob + (1 + attr | iid), data=SDF, family=binomial(link=\"logit\"))\nsummary(Model.F.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ samerace + agediff + attr + intel + prob + (1 + attr |      iid)\n   Data: SDF\n\n     AIC      BIC   logLik deviance df.resid \n  3180.9   3237.3  -1581.5   3162.9     3881 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.8317 -0.3363 -0.0679  0.3176  9.9176 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n iid    (Intercept) 19.4694  4.4124        \n        attr         0.2036  0.4512   -0.84\nNumber of obs: 3890, groups:  iid, 268\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -14.91109    0.76990 -19.367  < 2e-16 ***\nsamerace      0.53325    0.12521   4.259 2.06e-05 ***\nagediff      -0.02976    0.02046  -1.455    0.146    \nattr          1.13721    0.06704  16.964  < 2e-16 ***\nintel         0.42566    0.05286   8.053 8.09e-16 ***\nprob          0.66138    0.04540  14.568  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) samerc agedff attr   intel \nsamerace -0.132                            \nagediff  -0.088 -0.044                     \nattr     -0.752  0.040  0.000              \nintel    -0.597  0.060 -0.004  0.098       \nprob     -0.510  0.049 -0.017  0.283  0.029\noptimizer (Nelder_Mead) convergence code: 4 (failure to converge in 10000 evaluations)\nModel failed to converge with max|grad| = 0.0696188 (tol = 0.002, component 1)\nfailure to converge in 10000 evaluations\n\n\nAs it stands, the model for Female does not converge. Notice the warning/convergence status. I will let the optimizer evaluate the function up to 100,000 times; this will usually be sufficient unless the model is poorly behaved. This was also required for the fully saturated set of interactions with gender though I used more evaluation points for numerical integration in that case because we only had one set of random effects.\n\nModel.F.Mixed <- glmer(dec~samerace+agediff+attr+intel+prob + (1 + attr | iid), data=SDF, family=binomial(link=\"logit\"), control=glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=100000)))\nsummary(Model.F.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ samerace + agediff + attr + intel + prob + (1 + attr |      iid)\n   Data: SDF\nControl: glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 100000))\n\n     AIC      BIC   logLik deviance df.resid \n  3180.9   3237.3  -1581.5   3162.9     3881 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.8240 -0.3363 -0.0680  0.3175  9.9117 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n iid    (Intercept) 19.458   4.4111        \n        attr         0.204   0.4516   -0.84\nNumber of obs: 3890, groups:  iid, 268\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -14.90921    0.76961 -19.372  < 2e-16 ***\nsamerace      0.53502    0.12523   4.272 1.94e-05 ***\nagediff      -0.02988    0.02046  -1.460    0.144    \nattr          1.13743    0.06704  16.968  < 2e-16 ***\nintel         0.42532    0.05285   8.047 8.47e-16 ***\nprob          0.66114    0.04539  14.565  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) samerc agedff attr   intel \nsamerace -0.133                            \nagediff  -0.088 -0.044                     \nattr     -0.752  0.040  0.000              \nintel    -0.597  0.060 -0.004  0.098       \nprob     -0.510  0.049 -0.017  0.283  0.028\n\n\n\n\nMales\nThe same will happen with the Male model. I will go ahead and increase the set of function evaluations to allow convergence.\n\nModel.M.Mixed <- glmer(dec~samerace+agediff+attr+intel+prob + (1 + attr | iid), data=SDM, family=binomial(link=\"logit\"), control=glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=100000)))\nsummary(Model.M.Mixed)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ samerace + agediff + attr + intel + prob + (1 + attr |      iid)\n   Data: SDM\nControl: glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 100000))\n\n     AIC      BIC   logLik deviance df.resid \n  3141.0   3197.4  -1561.5   3123.0     3890 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-7.1362 -0.3164 -0.0157  0.3299  8.2443 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n iid    (Intercept) 21.597   4.6473        \n        attr         0.401   0.6333   -0.88\nNumber of obs: 3899, groups:  iid, 273\n\nFixed effects:\n             Estimate Std. Error z value   Pr(>|z|)    \n(Intercept) -14.24697    0.76058 -18.732    < 2e-16 ***\nsamerace     -0.08803    0.11854  -0.743     0.4577    \nagediff      -0.03799    0.02094  -1.814     0.0697 .  \nattr          1.39953    0.08007  17.478    < 2e-16 ***\nintel         0.24653    0.05193   4.747 0.00000206 ***\nprob          0.65876    0.04302  15.313    < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) samerc agedff attr   intel \nsamerace -0.051                            \nagediff  -0.075 -0.045                     \nattr     -0.790 -0.012  0.005              \nintel    -0.536  0.051 -0.048  0.056       \nprob     -0.477 -0.088  0.001  0.261  0.008\n\n\nFor exercises 5–10, load the employee_survey data set via the peopleanalyticsdata package or download it from the internet. This data set contains the results of an engagement survey of employees of a technology company. Each row represents the responses of an individual to the survey and each column represents a specific survey question, with responses on a Likert scale of 1 to 4, with 1 indicating strongly negative sentiment and 4 indicating strongly positive sentiment. Subject matter experts have grouped the items into hypothesized latent factors as follows:\nHappiness is an overall measure of the employees current sentiment about their job.\n\nItems beginning with Ben relate to employment benefits.\nItems beginning with Work relate to the general work environment.\nItems beginning with Man relate to perceptions of management.\nItems beginning with Car relate to perceptions of career prospects.\n\n\nWrite out the proposed measurement model, defining the latent factors in terms of the measured items.\n\n\\[(Ben1, Ben2, Ben3) = \\alpha + \\beta_{k}\\textrm{Benefits} + \\epsilon\\] \\[(Man1, Man2, Man3) = \\alpha + \\beta_{k}\\textrm{Managers} + \\epsilon\\] \\[(Work1, Work2, Work3) = \\alpha + \\beta_{k}\\textrm{Workplace} + \\epsilon\\] \\[(Car1, Car2, Car3, Car4) = \\alpha + \\beta_{k}\\textrm{Career} + \\epsilon\\]\n\nRun a confirmatory factor analysis on the proposed measurement model. Examine the fit and the factor loadings.\n\n\nmeas_mod <- \"\nBenefits =~ Ben1 + Ben2 + Ben3\nCareer =~ Car1 + Car2 + Car3 + Car4\nManager =~ Man1 + Man2 + Man3\nWorkplace =~ Work1 + Work2 + Work3\n\"\nlibrary(lavaan)\ncfa_meas_mod <- lavaan::cfa(model = meas_mod, data = employee_survey, ordered = TRUE)\nlavaan::summary(cfa_meas_mod, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-12 ended normally after 33 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        58\n\n  Number of observations                          2833\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               659.749    1009.185\n  Degrees of freedom                                59          59\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.661\n  Shift parameter                                           10.787\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                             50647.719   26156.692\n  Degrees of freedom                                78          78\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.939\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.988       0.964\n  Tucker-Lewis Index (TLI)                       0.984       0.952\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.060       0.075\n  90 Percent confidence interval - lower         0.056       0.071\n  90 Percent confidence interval - upper         0.064       0.080\n  P-value RMSEA <= 0.05                          0.000       0.000\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.053       0.053\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits =~                                                           \n    Ben1              1.000                               0.896    0.896\n    Ben2              0.855    0.025   33.977    0.000    0.766    0.766\n    Ben3              0.626    0.028   22.306    0.000    0.562    0.562\n  Career =~                                                             \n    Car1              1.000                               0.717    0.717\n    Car2              1.203    0.032   37.173    0.000    0.863    0.863\n    Car3              1.180    0.033   35.684    0.000    0.846    0.846\n    Car4              1.062    0.032   33.206    0.000    0.761    0.761\n  Manager =~                                                            \n    Man1              1.000                               0.784    0.784\n    Man2              1.084    0.028   39.048    0.000    0.849    0.849\n    Man3              0.938    0.026   35.816    0.000    0.735    0.735\n  Workplace =~                                                          \n    Work1             1.000                               0.795    0.795\n    Work2             1.147    0.018   63.041    0.000    0.912    0.912\n    Work3             1.062    0.016   67.076    0.000    0.845    0.845\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits ~~                                                           \n    Career            0.447    0.018   25.217    0.000    0.696    0.696\n    Manager           0.390    0.017   22.419    0.000    0.556    0.556\n    Workplace         0.333    0.016   20.603    0.000    0.467    0.467\n  Career ~~                                                             \n    Manager           0.336    0.016   20.614    0.000    0.598    0.598\n    Workplace         0.245    0.014   17.155    0.000    0.429    0.429\n  Manager ~~                                                            \n    Workplace         0.281    0.014   19.635    0.000    0.451    0.451\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.000                               0.000    0.000\n   .Ben2              0.000                               0.000    0.000\n   .Ben3              0.000                               0.000    0.000\n   .Car1              0.000                               0.000    0.000\n   .Car2              0.000                               0.000    0.000\n   .Car3              0.000                               0.000    0.000\n   .Car4              0.000                               0.000    0.000\n   .Man1              0.000                               0.000    0.000\n   .Man2              0.000                               0.000    0.000\n   .Man3              0.000                               0.000    0.000\n   .Work1             0.000                               0.000    0.000\n   .Work2             0.000                               0.000    0.000\n   .Work3             0.000                               0.000    0.000\n    Benefits          0.000                               0.000    0.000\n    Career            0.000                               0.000    0.000\n    Manager           0.000                               0.000    0.000\n    Workplace         0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1|t1          -2.404    0.076  -31.650    0.000   -2.404   -2.404\n    Ben1|t2          -1.501    0.036  -41.409    0.000   -1.501   -1.501\n    Ben1|t3          -0.303    0.024  -12.660    0.000   -0.303   -0.303\n    Ben2|t1          -2.580    0.092  -28.016    0.000   -2.580   -2.580\n    Ben2|t2          -1.576    0.038  -41.510    0.000   -1.576   -1.576\n    Ben2|t3          -0.407    0.024  -16.763    0.000   -0.407   -0.407\n    Ben3|t1          -2.694    0.105  -25.601    0.000   -2.694   -2.694\n    Ben3|t2          -1.865    0.047  -40.073    0.000   -1.865   -1.865\n    Ben3|t3          -0.618    0.025  -24.467    0.000   -0.618   -0.618\n    Car1|t1          -2.986    0.153  -19.543    0.000   -2.986   -2.986\n    Car1|t2          -1.817    0.045  -40.499    0.000   -1.817   -1.817\n    Car1|t3          -0.794    0.026  -30.014    0.000   -0.794   -0.794\n    Car2|t1          -2.662    0.101  -26.278    0.000   -2.662   -2.662\n    Car2|t2          -1.651    0.040  -41.408    0.000   -1.651   -1.651\n    Car2|t3          -0.627    0.025  -24.758    0.000   -0.627   -0.627\n    Car3|t1          -2.512    0.085  -29.435    0.000   -2.512   -2.512\n    Car3|t2          -1.456    0.035  -41.248    0.000   -1.456   -1.456\n    Car3|t3          -0.336    0.024  -13.968    0.000   -0.336   -0.336\n    Car4|t1          -2.156    0.060  -36.210    0.000   -2.156   -2.156\n    Car4|t2          -1.217    0.031  -39.091    0.000   -1.217   -1.217\n    Car4|t3          -0.209    0.024   -8.804    0.000   -0.209   -0.209\n    Man1|t1          -2.204    0.062  -35.403    0.000   -2.204   -2.204\n    Man1|t2          -0.878    0.027  -32.326    0.000   -0.878   -0.878\n    Man1|t3           0.368    0.024   15.236    0.000    0.368    0.368\n    Man2|t1          -2.437    0.079  -30.985    0.000   -2.437   -2.437\n    Man2|t2          -1.328    0.033  -40.369    0.000   -1.328   -1.328\n    Man2|t3          -0.287    0.024  -11.987    0.000   -0.287   -0.287\n    Man3|t1          -2.492    0.083  -29.854    0.000   -2.492   -2.492\n    Man3|t2          -1.372    0.034  -40.742    0.000   -1.372   -1.372\n    Man3|t3          -0.248    0.024  -10.415    0.000   -0.248   -0.248\n    Work1|t1         -1.773    0.043  -40.828    0.000   -1.773   -1.773\n    Work1|t2         -0.520    0.025  -21.023    0.000   -0.520   -0.520\n    Work1|t3          0.803    0.027   30.258    0.000    0.803    0.803\n    Work2|t1         -1.448    0.035  -41.214    0.000   -1.448   -1.448\n    Work2|t2         -0.090    0.024   -3.813    0.000   -0.090   -0.090\n    Work2|t3          1.124    0.030   37.657    0.000    1.124    1.124\n    Work3|t1         -1.647    0.040  -41.417    0.000   -1.647   -1.647\n    Work3|t2         -0.342    0.024  -14.229    0.000   -0.342   -0.342\n    Work3|t3          0.893    0.027   32.698    0.000    0.893    0.893\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.196                               0.196    0.196\n   .Ben2              0.413                               0.413    0.413\n   .Ben3              0.685                               0.685    0.685\n   .Car1              0.486                               0.486    0.486\n   .Car2              0.256                               0.256    0.256\n   .Car3              0.285                               0.285    0.285\n   .Car4              0.420                               0.420    0.420\n   .Man1              0.386                               0.386    0.386\n   .Man2              0.279                               0.279    0.279\n   .Man3              0.459                               0.459    0.459\n   .Work1             0.367                               0.367    0.367\n   .Work2             0.168                               0.168    0.168\n   .Work3             0.286                               0.286    0.286\n    Benefits          0.804    0.028   28.382    0.000    1.000    1.000\n    Career            0.514    0.026   19.711    0.000    1.000    1.000\n    Manager           0.614    0.023   27.130    0.000    1.000    1.000\n    Workplace         0.633    0.016   39.493    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1              1.000                               1.000    1.000\n    Ben2              1.000                               1.000    1.000\n    Ben3              1.000                               1.000    1.000\n    Car1              1.000                               1.000    1.000\n    Car2              1.000                               1.000    1.000\n    Car3              1.000                               1.000    1.000\n    Car4              1.000                               1.000    1.000\n    Man1              1.000                               1.000    1.000\n    Man2              1.000                               1.000    1.000\n    Man3              1.000                               1.000    1.000\n    Work1             1.000                               1.000    1.000\n    Work2             1.000                               1.000    1.000\n    Work3             1.000                               1.000    1.000\n\n\n\nExperiment with the removal of measured items from the measurement model in order to improve the overall fit.\n\n\nmeas_mod.2 <- \"\nBenefits =~ Ben1 + Ben2\nCareer =~ Car1 + Car2 + Car3 + Car4\nManager =~ Man1 + Man2 + Man3\nWorkplace =~ Work1 + Work2 + Work3\n\"\nlibrary(lavaan)\ncfa_meas_mod.2 <- lavaan::cfa(model = meas_mod.2, data = employee_survey, ordered=TRUE)\nlavaan::summary(cfa_meas_mod.2, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-12 ended normally after 33 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        54\n\n  Number of observations                          2833\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               495.920     782.349\n  Degrees of freedom                                48          48\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.641\n  Shift parameter                                            8.882\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                             48450.076   25208.233\n  Degrees of freedom                                66          66\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.924\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.991       0.971\n  Tucker-Lewis Index (TLI)                       0.987       0.960\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.057       0.073\n  90 Percent confidence interval - lower         0.053       0.069\n  90 Percent confidence interval - upper         0.062       0.078\n  P-value RMSEA <= 0.05                          0.004       0.000\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.049       0.049\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits =~                                                           \n    Ben1              1.000                               0.887    0.887\n    Ben2              0.791    0.027   29.809    0.000    0.702    0.702\n  Career =~                                                             \n    Car1              1.000                               0.714    0.714\n    Car2              1.209    0.032   37.228    0.000    0.864    0.864\n    Car3              1.188    0.033   35.902    0.000    0.849    0.849\n    Car4              1.061    0.032   33.350    0.000    0.757    0.757\n  Manager =~                                                            \n    Man1              1.000                               0.785    0.785\n    Man2              1.081    0.028   38.989    0.000    0.849    0.849\n    Man3              0.937    0.026   35.838    0.000    0.735    0.735\n  Workplace =~                                                          \n    Work1             1.000                               0.794    0.794\n    Work2             1.151    0.018   63.354    0.000    0.913    0.913\n    Work3             1.064    0.016   67.766    0.000    0.845    0.845\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits ~~                                                           \n    Career            0.471    0.018   26.061    0.000    0.743    0.743\n    Manager           0.406    0.018   22.916    0.000    0.583    0.583\n    Workplace         0.349    0.016   21.222    0.000    0.496    0.496\n  Career ~~                                                             \n    Manager           0.335    0.016   20.621    0.000    0.598    0.598\n    Workplace         0.243    0.014   17.134    0.000    0.429    0.429\n  Manager ~~                                                            \n    Workplace         0.281    0.014   19.634    0.000    0.451    0.451\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.000                               0.000    0.000\n   .Ben2              0.000                               0.000    0.000\n   .Car1              0.000                               0.000    0.000\n   .Car2              0.000                               0.000    0.000\n   .Car3              0.000                               0.000    0.000\n   .Car4              0.000                               0.000    0.000\n   .Man1              0.000                               0.000    0.000\n   .Man2              0.000                               0.000    0.000\n   .Man3              0.000                               0.000    0.000\n   .Work1             0.000                               0.000    0.000\n   .Work2             0.000                               0.000    0.000\n   .Work3             0.000                               0.000    0.000\n    Benefits          0.000                               0.000    0.000\n    Career            0.000                               0.000    0.000\n    Manager           0.000                               0.000    0.000\n    Workplace         0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1|t1          -2.404    0.076  -31.650    0.000   -2.404   -2.404\n    Ben1|t2          -1.501    0.036  -41.409    0.000   -1.501   -1.501\n    Ben1|t3          -0.303    0.024  -12.660    0.000   -0.303   -0.303\n    Ben2|t1          -2.580    0.092  -28.016    0.000   -2.580   -2.580\n    Ben2|t2          -1.576    0.038  -41.510    0.000   -1.576   -1.576\n    Ben2|t3          -0.407    0.024  -16.763    0.000   -0.407   -0.407\n    Car1|t1          -2.986    0.153  -19.543    0.000   -2.986   -2.986\n    Car1|t2          -1.817    0.045  -40.499    0.000   -1.817   -1.817\n    Car1|t3          -0.794    0.026  -30.014    0.000   -0.794   -0.794\n    Car2|t1          -2.662    0.101  -26.278    0.000   -2.662   -2.662\n    Car2|t2          -1.651    0.040  -41.408    0.000   -1.651   -1.651\n    Car2|t3          -0.627    0.025  -24.758    0.000   -0.627   -0.627\n    Car3|t1          -2.512    0.085  -29.435    0.000   -2.512   -2.512\n    Car3|t2          -1.456    0.035  -41.248    0.000   -1.456   -1.456\n    Car3|t3          -0.336    0.024  -13.968    0.000   -0.336   -0.336\n    Car4|t1          -2.156    0.060  -36.210    0.000   -2.156   -2.156\n    Car4|t2          -1.217    0.031  -39.091    0.000   -1.217   -1.217\n    Car4|t3          -0.209    0.024   -8.804    0.000   -0.209   -0.209\n    Man1|t1          -2.204    0.062  -35.403    0.000   -2.204   -2.204\n    Man1|t2          -0.878    0.027  -32.326    0.000   -0.878   -0.878\n    Man1|t3           0.368    0.024   15.236    0.000    0.368    0.368\n    Man2|t1          -2.437    0.079  -30.985    0.000   -2.437   -2.437\n    Man2|t2          -1.328    0.033  -40.369    0.000   -1.328   -1.328\n    Man2|t3          -0.287    0.024  -11.987    0.000   -0.287   -0.287\n    Man3|t1          -2.492    0.083  -29.854    0.000   -2.492   -2.492\n    Man3|t2          -1.372    0.034  -40.742    0.000   -1.372   -1.372\n    Man3|t3          -0.248    0.024  -10.415    0.000   -0.248   -0.248\n    Work1|t1         -1.773    0.043  -40.828    0.000   -1.773   -1.773\n    Work1|t2         -0.520    0.025  -21.023    0.000   -0.520   -0.520\n    Work1|t3          0.803    0.027   30.258    0.000    0.803    0.803\n    Work2|t1         -1.448    0.035  -41.214    0.000   -1.448   -1.448\n    Work2|t2         -0.090    0.024   -3.813    0.000   -0.090   -0.090\n    Work2|t3          1.124    0.030   37.657    0.000    1.124    1.124\n    Work3|t1         -1.647    0.040  -41.417    0.000   -1.647   -1.647\n    Work3|t2         -0.342    0.024  -14.229    0.000   -0.342   -0.342\n    Work3|t3          0.893    0.027   32.698    0.000    0.893    0.893\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.212                               0.212    0.212\n   .Ben2              0.507                               0.507    0.507\n   .Car1              0.490                               0.490    0.490\n   .Car2              0.254                               0.254    0.254\n   .Car3              0.280                               0.280    0.280\n   .Car4              0.427                               0.427    0.427\n   .Man1              0.384                               0.384    0.384\n   .Man2              0.280                               0.280    0.280\n   .Man3              0.459                               0.459    0.459\n   .Work1             0.370                               0.370    0.370\n   .Work2             0.166                               0.166    0.166\n   .Work3             0.287                               0.287    0.287\n    Benefits          0.788    0.029   26.847    0.000    1.000    1.000\n    Career            0.510    0.026   19.703    0.000    1.000    1.000\n    Manager           0.616    0.023   27.166    0.000    1.000    1.000\n    Workplace         0.630    0.016   39.570    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1              1.000                               1.000    1.000\n    Ben2              1.000                               1.000    1.000\n    Car1              1.000                               1.000    1.000\n    Car2              1.000                               1.000    1.000\n    Car3              1.000                               1.000    1.000\n    Car4              1.000                               1.000    1.000\n    Man1              1.000                               1.000    1.000\n    Man2              1.000                               1.000    1.000\n    Man3              1.000                               1.000    1.000\n    Work1             1.000                               1.000    1.000\n    Work2             1.000                               1.000    1.000\n    Work3             1.000                               1.000    1.000\n\n\n\nOnce satisfied with the fit of the measurement model, run a full structural equation model on the data.\n\n\nstruc_mod <- \"\nBenefits =~ Ben1 + Ben2\nCareer =~ Car1 + Car2 + Car3 + Car4\nManager =~ Man1 + Man2 + Man3\nWorkplace =~ Work1 + Work2 + Work3\nHappiness ~ Benefits + Career + Manager + Workplace\n\"\nlibrary(lavaan)\nlibrary(performance)\nsem_model <- lavaan::sem(model = struc_mod, data = employee_survey, ordered=TRUE)\nlavaan::summary(sem_model, fit.measures = TRUE, standardized = TRUE, rsquare=TRUE)\n\nlavaan 0.6-12 ended normally after 40 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        61\n\n  Number of observations                          2833\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               548.394     901.273\n  Degrees of freedom                                56          56\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.616\n  Shift parameter                                           10.675\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                             56428.657   27563.973\n  Degrees of freedom                                78          78\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  2.050\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.991       0.969\n  Tucker-Lewis Index (TLI)                       0.988       0.957\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.056       0.073\n  90 Percent confidence interval - lower         0.052       0.069\n  90 Percent confidence interval - upper         0.060       0.077\n  P-value RMSEA <= 0.05                          0.013       0.000\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.046       0.046\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits =~                                                           \n    Ben1              1.000                               0.890    0.890\n    Ben2              0.786    0.025   31.618    0.000    0.700    0.700\n  Career =~                                                             \n    Car1              1.000                               0.712    0.712\n    Car2              1.211    0.033   36.479    0.000    0.863    0.863\n    Car3              1.187    0.034   35.266    0.000    0.846    0.846\n    Car4              1.073    0.033   32.836    0.000    0.764    0.764\n  Manager =~                                                            \n    Man1              1.000                               0.794    0.794\n    Man2              1.066    0.027   39.161    0.000    0.846    0.846\n    Man3              0.919    0.026   35.147    0.000    0.729    0.729\n  Workplace =~                                                          \n    Work1             1.000                               0.809    0.809\n    Work2             1.117    0.017   65.975    0.000    0.904    0.904\n    Work3             1.042    0.015   67.975    0.000    0.844    0.844\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Happiness ~                                                           \n    Benefits          0.403    0.048    8.416    0.000    0.359    0.359\n    Career            0.228    0.053    4.297    0.000    0.162    0.162\n    Manager           0.190    0.033    5.701    0.000    0.150    0.150\n    Workplace         0.292    0.026   11.375    0.000    0.236    0.236\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Benefits ~~                                                           \n    Career            0.470    0.018   25.889    0.000    0.742    0.742\n    Manager           0.411    0.018   23.155    0.000    0.582    0.582\n    Workplace         0.357    0.017   21.522    0.000    0.495    0.495\n  Career ~~                                                             \n    Manager           0.338    0.016   20.611    0.000    0.597    0.597\n    Workplace         0.247    0.014   17.181    0.000    0.429    0.429\n  Manager ~~                                                            \n    Workplace         0.289    0.015   19.928    0.000    0.450    0.450\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.000                               0.000    0.000\n   .Ben2              0.000                               0.000    0.000\n   .Car1              0.000                               0.000    0.000\n   .Car2              0.000                               0.000    0.000\n   .Car3              0.000                               0.000    0.000\n   .Car4              0.000                               0.000    0.000\n   .Man1              0.000                               0.000    0.000\n   .Man2              0.000                               0.000    0.000\n   .Man3              0.000                               0.000    0.000\n   .Work1             0.000                               0.000    0.000\n   .Work2             0.000                               0.000    0.000\n   .Work3             0.000                               0.000    0.000\n   .Happiness         0.000                               0.000    0.000\n    Benefits          0.000                               0.000    0.000\n    Career            0.000                               0.000    0.000\n    Manager           0.000                               0.000    0.000\n    Workplace         0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1|t1          -2.404    0.076  -31.650    0.000   -2.404   -2.404\n    Ben1|t2          -1.501    0.036  -41.409    0.000   -1.501   -1.501\n    Ben1|t3          -0.303    0.024  -12.660    0.000   -0.303   -0.303\n    Ben2|t1          -2.580    0.092  -28.016    0.000   -2.580   -2.580\n    Ben2|t2          -1.576    0.038  -41.510    0.000   -1.576   -1.576\n    Ben2|t3          -0.407    0.024  -16.763    0.000   -0.407   -0.407\n    Car1|t1          -2.986    0.153  -19.543    0.000   -2.986   -2.986\n    Car1|t2          -1.817    0.045  -40.499    0.000   -1.817   -1.817\n    Car1|t3          -0.794    0.026  -30.014    0.000   -0.794   -0.794\n    Car2|t1          -2.662    0.101  -26.278    0.000   -2.662   -2.662\n    Car2|t2          -1.651    0.040  -41.408    0.000   -1.651   -1.651\n    Car2|t3          -0.627    0.025  -24.758    0.000   -0.627   -0.627\n    Car3|t1          -2.512    0.085  -29.435    0.000   -2.512   -2.512\n    Car3|t2          -1.456    0.035  -41.248    0.000   -1.456   -1.456\n    Car3|t3          -0.336    0.024  -13.968    0.000   -0.336   -0.336\n    Car4|t1          -2.156    0.060  -36.210    0.000   -2.156   -2.156\n    Car4|t2          -1.217    0.031  -39.091    0.000   -1.217   -1.217\n    Car4|t3          -0.209    0.024   -8.804    0.000   -0.209   -0.209\n    Man1|t1          -2.204    0.062  -35.403    0.000   -2.204   -2.204\n    Man1|t2          -0.878    0.027  -32.326    0.000   -0.878   -0.878\n    Man1|t3           0.368    0.024   15.236    0.000    0.368    0.368\n    Man2|t1          -2.437    0.079  -30.985    0.000   -2.437   -2.437\n    Man2|t2          -1.328    0.033  -40.369    0.000   -1.328   -1.328\n    Man2|t3          -0.287    0.024  -11.987    0.000   -0.287   -0.287\n    Man3|t1          -2.492    0.083  -29.854    0.000   -2.492   -2.492\n    Man3|t2          -1.372    0.034  -40.742    0.000   -1.372   -1.372\n    Man3|t3          -0.248    0.024  -10.415    0.000   -0.248   -0.248\n    Work1|t1         -1.773    0.043  -40.828    0.000   -1.773   -1.773\n    Work1|t2         -0.520    0.025  -21.023    0.000   -0.520   -0.520\n    Work1|t3          0.803    0.027   30.258    0.000    0.803    0.803\n    Work2|t1         -1.448    0.035  -41.214    0.000   -1.448   -1.448\n    Work2|t2         -0.090    0.024   -3.813    0.000   -0.090   -0.090\n    Work2|t3          1.124    0.030   37.657    0.000    1.124    1.124\n    Work3|t1         -1.647    0.040  -41.417    0.000   -1.647   -1.647\n    Work3|t2         -0.342    0.024  -14.229    0.000   -0.342   -0.342\n    Work3|t3          0.893    0.027   32.698    0.000    0.893    0.893\n    Happiness|t1     -2.729    0.110  -24.861    0.000   -2.729   -2.729\n    Happiness|t2     -1.477    0.036  -41.332    0.000   -1.477   -1.477\n    Happiness|t3     -0.281    0.024  -11.763    0.000   -0.281   -0.281\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .Ben1              0.208                               0.208    0.208\n   .Ben2              0.510                               0.510    0.510\n   .Car1              0.492                               0.492    0.492\n   .Car2              0.255                               0.255    0.255\n   .Car3              0.285                               0.285    0.285\n   .Car4              0.416                               0.416    0.416\n   .Man1              0.370                               0.370    0.370\n   .Man2              0.284                               0.284    0.284\n   .Man3              0.468                               0.468    0.468\n   .Work1             0.345                               0.345    0.345\n   .Work2             0.182                               0.182    0.182\n   .Work3             0.288                               0.288    0.288\n   .Happiness         0.440                               0.440    0.440\n    Benefits          0.792    0.028   28.497    0.000    1.000    1.000\n    Career            0.508    0.026   19.309    0.000    1.000    1.000\n    Manager           0.630    0.023   27.338    0.000    1.000    1.000\n    Workplace         0.655    0.016   41.085    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    Ben1              1.000                               1.000    1.000\n    Ben2              1.000                               1.000    1.000\n    Car1              1.000                               1.000    1.000\n    Car2              1.000                               1.000    1.000\n    Car3              1.000                               1.000    1.000\n    Car4              1.000                               1.000    1.000\n    Man1              1.000                               1.000    1.000\n    Man2              1.000                               1.000    1.000\n    Man3              1.000                               1.000    1.000\n    Work1             1.000                               1.000    1.000\n    Work2             1.000                               1.000    1.000\n    Work3             1.000                               1.000    1.000\n    Happiness         1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    Ben1              0.792\n    Ben2              0.490\n    Car1              0.508\n    Car2              0.745\n    Car3              0.715\n    Car4              0.584\n    Man1              0.630\n    Man2              0.716\n    Man3              0.532\n    Work1             0.655\n    Work2             0.818\n    Work3             0.712\n    Happiness         0.560\n\n\n\nInterpret the results of the structural model. Which factors appear most related to overall employee sentiment? Approximately what proportion of the variance in overall sentiment does the model explain?\n\nOne can get an approximate \\(R^2\\) value from the summary; in this case, it is approximately 0.56.\n\nIf you dropped measured items from your measurement model, experiment with assigning them to other factors to see if this improves the fit of the model. What statistics would you use to compare different measurement models?"
  }
]